{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet('transactions_train.parquet')\n",
    "customers = pd.read_parquet('customers.parquet')\n",
    "articles = pd.read_parquet('articles.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Calculate the next week number after the current maximum week in the data\n",
    "test_week = transactions.week.max() + 1\n",
    "\n",
    "# Filter the transactions to include only those from the last 10 weeks\n",
    "transactions = transactions[transactions.week > transactions.week.max() - 10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent buyers: 39460\n",
      "merged: \n",
      "             t_dat           customer_id  article_id     price  \\\n",
      "0      2020-07-15       272412481300040   778064028  0.008458   \n",
      "1      2020-07-15       272412481300040   816592008  0.016932   \n",
      "2      2020-07-15       272412481300040   621381021  0.033881   \n",
      "3      2020-07-15       272412481300040   817477003  0.025407   \n",
      "4      2020-07-15       272412481300040   899088002  0.025407   \n",
      "...           ...                   ...         ...       ...   \n",
      "949985 2020-09-22  18421675981536870956   749699002  0.025407   \n",
      "949986 2020-09-22  18426621781275797575   572998013  0.042356   \n",
      "949987 2020-09-22  18426621781275797575   788575004  0.042356   \n",
      "949988 2020-09-22  18426621781275797575   914441003  0.033881   \n",
      "949989 2020-09-22  18426621781275797575   896848001  0.030492   \n",
      "\n",
      "        sales_channel_id  week  frequent_buyer  product_group_name  \\\n",
      "0                      1    95            True                   0   \n",
      "1                      1    95            True                   0   \n",
      "2                      1    95            True                   1   \n",
      "3                      1    95            True                   1   \n",
      "4                      1    95            True                   1   \n",
      "...                  ...   ...             ...                 ...   \n",
      "949985                 2   104            True                   0   \n",
      "949986                 2   104            True                   1   \n",
      "949987                 2   104            True                   1   \n",
      "949988                 2   104            True                   1   \n",
      "949989                 2   104            True                   2   \n",
      "\n",
      "        product_type_name  colour_group_name  \n",
      "0                       3                 11  \n",
      "1                       3                  2  \n",
      "2                       0                  8  \n",
      "3                       7                 10  \n",
      "4                      11                  0  \n",
      "...                   ...                ...  \n",
      "949985                  9                 11  \n",
      "949986                  0                  6  \n",
      "949987                  0                  1  \n",
      "949988                  0                  6  \n",
      "949989                 23                  0  \n",
      "\n",
      "[949990 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Counting transactions for each customer_id\n",
    "transaction_counts = transactions['customer_id'].value_counts()\n",
    "\n",
    "# Calculating the 80th quantile as the threshold\n",
    "threshold = transaction_counts.quantile(0.90)\n",
    "\n",
    "# Labeling frequent buyers in the transactions DataFrame\n",
    "transactions['frequent_buyer'] = transactions['customer_id'].map(lambda x: transaction_counts[x] > threshold)\n",
    "\n",
    "# Counting unique frequent buyers\n",
    "num_frequent_buyers = transactions[transactions['frequent_buyer']]['customer_id'].nunique()\n",
    "print(f\"Number of frequent buyers: {num_frequent_buyers}\")\n",
    "\n",
    "# Filtering transactions for frequent buyers\n",
    "frequent_buyer_transactions = transactions[transactions['frequent_buyer']]\n",
    "\n",
    "# Merging with articles data\n",
    "frequent_transactions = frequent_buyer_transactions.merge(articles[['article_id', 'product_group_name', 'product_type_name', 'colour_group_name']], on='article_id', how='left')\n",
    "\n",
    "print(\"merged: \\n\", frequent_transactions)\n",
    "\n",
    "# Extract unique frequent buyer IDs\n",
    "unique_frequent_buyers = list(frequent_buyer_transactions['customer_id'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            t_dat           customer_id  article_id     price  \\\n",
      "596    2020-07-15    867806996788384472   773471010  0.125847   \n",
      "723    2020-07-15   1002684848125350632   851993001  0.101678   \n",
      "724    2020-07-15   1002684848125350632   851993001  0.101678   \n",
      "1124   2020-07-15   1485995793756406162   859874001  0.122017   \n",
      "1287   2020-07-15   1632437192178381894   707075008  0.101678   \n",
      "...           ...                   ...         ...       ...   \n",
      "949785 2020-09-22  18063942235003628498   887464003  0.101678   \n",
      "949787 2020-09-22  18063942235003628498   887464002  0.101678   \n",
      "949788 2020-09-22  18063942235003628498   887464002  0.101678   \n",
      "949789 2020-09-22  18063942235003628498   887464002  0.101678   \n",
      "949966 2020-09-22  18394381115614748074   901318001  0.101678   \n",
      "\n",
      "        sales_channel_id  week  frequent_buyer  product_group_name  \\\n",
      "596                    2    95            True                   1   \n",
      "723                    2    95            True                   2   \n",
      "724                    2    95            True                   2   \n",
      "1124                   2    95            True                   2   \n",
      "1287                   2    95            True                   2   \n",
      "...                  ...   ...             ...                 ...   \n",
      "949785                 2   104            True                   3   \n",
      "949787                 2   104            True                   3   \n",
      "949788                 2   104            True                   3   \n",
      "949789                 2   104            True                   3   \n",
      "949966                 2   104            True                   5   \n",
      "\n",
      "        product_type_name  colour_group_name  \n",
      "596                     0                 26  \n",
      "723                     1                  0  \n",
      "724                     1                  0  \n",
      "1124                    1                  2  \n",
      "1287                    1                 32  \n",
      "...                   ...                ...  \n",
      "949785                 28                 39  \n",
      "949787                 28                 12  \n",
      "949788                 28                 12  \n",
      "949789                 28                 12  \n",
      "949966                 27                  0  \n",
      "\n",
      "[9912 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assume 'price' column exists in your DataFrame\n",
    "Q1 = frequent_transactions['price'].quantile(0.20)\n",
    "Q3 = frequent_transactions['price'].quantile(0.80)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_price_candidates = frequent_transactions[(frequent_transactions['price'] < lower_bound) | (frequent_transactions['price'] > upper_bound)]\n",
    "\n",
    "print(outlier_price_candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Calculate the least common product group, product type and color for each customer\n",
    "least_common_categories = frequent_transactions.groupby('customer_id')['product_group_name'].apply(lambda x: x.value_counts().nsmallest(1).index.tolist())\n",
    "# Calculate the 4 least common product types for each customer\n",
    "least_common_product_types = frequent_transactions.groupby('customer_id')['product_type_name'].apply(lambda x: x.value_counts().nsmallest(1).index.tolist())\n",
    "# Calculate the 4 least common colors for each customer\n",
    "least_common_colors = frequent_transactions.groupby('customer_id')['colour_group_name'].apply(lambda x: x.value_counts().nsmallest(1).index.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming 'articles' is your DataFrame with article details\n",
    "# Convert categorical attributes to one-hot encoded vectors\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(articles[['product_group_name', 'product_type_name', 'colour_group_name']])\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(encoded_features)\n",
    "\n",
    "# Convert similarity matrix to DataFrame for easier handling\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=articles['article_id'], columns=articles['article_id'])\n",
    "\n",
    "def find_outlier_like_items(customer_id, transactions, similarity_df, threshold=0.5):\n",
    "    # Get items interacted with by the customer\n",
    "    interacted_items = transactions[transactions['customer_id'] == customer_id]['article_id'].unique()\n",
    "\n",
    "    # Dictionary to hold potential outlier-like items\n",
    "    outlier_like_items = {}\n",
    "\n",
    "    for item in interacted_items:\n",
    "        # Get similarity scores for the item with all other items\n",
    "        sim_scores = similarity_df[item]\n",
    "\n",
    "        # Filter items based on threshold and exclude items already interacted with\n",
    "        similar_items = sim_scores[(sim_scores > threshold) & (sim_scores < 1.0) & (~sim_scores.index.isin(interacted_items))].index.tolist()\n",
    "\n",
    "        outlier_like_items[item] = similar_items\n",
    "\n",
    "    return outlier_like_items\n",
    "\n",
    "# Example usage\n",
    "customer_id = 867806996788384472\n",
    "outlier_like_items = find_outlier_like_items(customer_id, transactions, similarity_df)\n",
    "\n",
    "print(outlier_like_items)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n    For each customer, we now have several articles which we would consider to be an outlier for them\\n\\n    Now we would like to find transactions in the big transaction database. Ideally transactions made from that customer, otherwise other transaction from another customer. Just take the latest and maybe set the week to test week?\\n\\n'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_candidate_ids = {}\n",
    "\n",
    "for customer in unique_frequent_buyers:\n",
    "    # Initialize an empty set for the customer\n",
    "    article_candidate_ids[customer] = set()\n",
    "\n",
    "    for category in least_common_categories[customer]:\n",
    "        for color in least_common_colors[customer]:\n",
    "            for product_type in least_common_product_types[customer]:\n",
    "\n",
    "                # Filter the articles dataframe for each combination of two criteria\n",
    "                matching_articles_category_color = articles[\n",
    "                    (articles['product_group_name'] == category) &\n",
    "                    (articles['colour_group_name'] == color)\n",
    "                ]\n",
    "\n",
    "                matching_articles_category_type = articles[\n",
    "                    (articles['product_group_name'] == category) &\n",
    "                    (articles['product_type_name'] == product_type)\n",
    "                ]\n",
    "\n",
    "                matching_articles_color_type = articles[\n",
    "                    (articles['colour_group_name'] == color) &\n",
    "                    (articles['product_type_name'] == product_type)\n",
    "                ]\n",
    "\n",
    "                # Combine the results and add the found article IDs to the set for this customer\n",
    "                combined_articles = pd.concat([\n",
    "                    matching_articles_category_color,\n",
    "                    matching_articles_category_type,\n",
    "                    matching_articles_color_type\n",
    "                ]).drop_duplicates('article_id')\n",
    "\n",
    "                article_candidate_ids[customer].update(combined_articles['article_id'].unique())\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame after the merge\n",
    "# This will remove rows where the combination of 'customer_id' and 'article_id' is duplicated\n",
    "#print(article_candidate_ids)\n",
    "\n",
    "\n",
    "'''\n",
    "    For each customer, we now have several articles which we would consider to be an outlier for them\n",
    "\n",
    "    Now we would like to find transactions in the big transaction database. Ideally transactions made from that customer, otherwise other transaction from another customer. Just take the latest and maybe set the week to test week?\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming 'transactions' is your larger transaction database\n",
    "# and 'test_week' is the week number you want to set for these transactions\n",
    "\n",
    "outlier_transactions = pd.DataFrame()\n",
    "\n",
    "for customer, articles in article_candidate_ids.items():\n",
    "    customer_transactions = transactions[transactions['customer_id'] == customer]\n",
    "    other_transactions = transactions[transactions['customer_id'] != customer]\n",
    "\n",
    "    for article_id in articles:\n",
    "        # Check if the customer has transactions for this article\n",
    "        customer_trans = customer_transactions[customer_transactions['article_id'] == article_id]\n",
    "\n",
    "        if not customer_trans.empty:\n",
    "            outlier_transactions = pd.concat([outlier_transactions, customer_trans])\n",
    "        else:\n",
    "            # If not, find the latest transaction by any other customer for this article\n",
    "            other_trans = other_transactions[other_transactions['article_id'] == article_id].nlargest(1, 't_dat')\n",
    "            outlier_transactions = pd.concat([outlier_transactions, other_trans])\n",
    "\n",
    "# Set the week to test week\n",
    "outlier_transactions['week'] = test_week\n",
    "\n",
    "# Display the result\n",
    "print(outlier_transactions.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}