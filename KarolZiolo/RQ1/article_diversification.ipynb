{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/karol/Desktop/Antwerp/ai_project\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.sparse import csr_matrix\n",
    "from data_reader import load_data_mf, matrix_representation, load_customers_articles, customers_diversification, articles_diversification\n",
    "from model import TwoTowerCustomer, TwoTowerFinal\n",
    "from helper import train_two_tower\n",
    "from recommenders import recommender_two_towers_final, recommender_two_towers_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read customers and transactions data\n",
    "customers = pd.read_csv(\"data/preprocessed/customers.csv\") \n",
    "transactions = pd.read_csv(\"data/preprocessed/transactions.csv\")\n",
    "articles = pd.read_csv(\"data/preprocessed/articles.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get seasonal sales information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_season(x):\n",
    "    if x in [12,1,2]:\n",
    "        return 1\n",
    "    elif x in [3,4,5]:\n",
    "        return 2\n",
    "    elif x in [6,7,8]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_sales(a, t):\n",
    "    # get seasons\n",
    "    t[\"t_dat\"] = pd.to_datetime(t[\"t_dat\"])\n",
    "    t[\"month\"] = t[\"t_dat\"].dt.month \n",
    "    # get function to apply seasons\n",
    "    t[\"season\"] = t[\"month\"].apply(assign_season)\n",
    "    grouped = t.groupby([\"article_id\", \"season\"])[\"customer_id\"].count()\n",
    "    # get percentages\n",
    "    percentages = grouped / grouped.groupby(level=0).transform(\"sum\")\n",
    "    # create winter sale var\n",
    "    winter_sale = percentages[percentages.index.get_level_values('season') == 1]\n",
    "    winter_sale = winter_sale.rename(\"winter_sale\")\n",
    "    a = a.merge(winter_sale, how=\"left\", on=\"article_id\")\n",
    "    a[\"winter_sale\"] = a[\"winter_sale\"].fillna(0)\n",
    "    # create spring sale var\n",
    "    spring_sale = percentages[percentages.index.get_level_values('season') == 2]\n",
    "    spring_sale = spring_sale.rename(\"spring_sale\")\n",
    "    a = a.merge(spring_sale, how=\"left\", on=\"article_id\")\n",
    "    a[\"spring_sale\"] = a[\"spring_sale\"].fillna(0)\n",
    "    # create summer sale var\n",
    "    summer_sale = percentages[percentages.index.get_level_values('season') == 3]\n",
    "    summer_sale = summer_sale.rename(\"summer_sale\")\n",
    "    a = a.merge(summer_sale, how=\"left\", on=\"article_id\")\n",
    "    a[\"summer_sale\"] = a[\"summer_sale\"].fillna(0)\n",
    "    # create autumn sale var\n",
    "    autumn_sale = percentages[percentages.index.get_level_values('season') == 4]\n",
    "    autumn_sale = autumn_sale.rename(\"autumn_sale\")\n",
    "    a = a.merge(autumn_sale, how=\"left\", on=\"article_id\")\n",
    "    a[\"autumn_sale\"] = a[\"autumn_sale\"].fillna(0)\n",
    "    return a\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get average prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_price(a, t):\n",
    "    grouped = t.groupby(\"article_id\")[\"price\"].mean()\n",
    "    grouped = grouped.rename(\"avg_price\")\n",
    "    a = a.merge(grouped, how=\"left\", on=\"article_id\")\n",
    "    a[\"avg_price\"] = a[\"avg_price\"].fillna(-1)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yearly seasonal bestsellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_bestseller_ranking(a, t):\n",
    "    # get seasons\n",
    "    t[\"t_dat\"] = pd.to_datetime(t[\"t_dat\"])\n",
    "    t[\"month\"] = t[\"t_dat\"].dt.month \n",
    "    # get function to apply seasons\n",
    "    t[\"season\"] = t[\"month\"].apply(assign_season)\n",
    "    t[\"year\"] = t[\"t_dat\"].dt.year \n",
    "    # Create a new DataFrame with the count of t for each (year, season, article_id) combination\n",
    "    transaction_counts = t.groupby([\"year\", \"season\", \"article_id\"])[\"customer_id\"].count().reset_index()\n",
    "    transaction_counts.rename(columns={\"customer_id\": \"transaction_count\"}, inplace=True)\n",
    "\n",
    "    # Create rankings within each (year, season) group based on transaction counts\n",
    "    transaction_counts['article_rank'] = transaction_counts.groupby([\"year\", \"season\"])['transaction_count'].rank(ascending=True, method='dense')\n",
    "    for year in transaction_counts.year.unique():\n",
    "        for season in transaction_counts[transaction_counts.year==year].season.unique():\n",
    "            t = transaction_counts[(transaction_counts.year==year) & (transaction_counts.season==season)]\n",
    "            a = a.merge(t[[\"article_id\",\"article_rank\"]], how=\"left\", on=\"article_id\")\n",
    "            a[\"article_rank\"] = a[\"article_rank\"].fillna(0)\n",
    "            new_name = {\"article_rank\":\"rank_\"+str(season)+\"_\"+str(year)}\n",
    "            a = a.rename(columns=new_name)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Articles preferences based on the customers age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_articles_preference(a,t,c):\n",
    "    bins = [0,25,40,55,float(\"inf\")]\n",
    "    labels = [\"young_preference\",\"adult_preferences\",\"middle_aged_preference\",\"senior_preference\"]\n",
    "    c[\"age_group\"] = pd.cut(c[\"age\"], bins=bins, labels=labels, right=False)\n",
    "    print(\"AGE GROUP DISTRIBUTION\\n\")\n",
    "    print(c[\"age_group\"].value_counts())\n",
    "    t = t.merge(c[[\"customer_id\",\"age_group\"]], how=\"left\", on=\"customer_id\")\n",
    "    grouped = t.groupby([\"article_id\", \"age_group\"])[\"customer_id\"].count()\n",
    "    percentages = grouped / grouped.groupby(level=0).transform(\"sum\")\n",
    "    for label in labels:\n",
    "    # merge young\n",
    "        preference = percentages[percentages.index.get_level_values('age_group') == label]\n",
    "        preference = preference.rename(label)\n",
    "        a = a.merge(preference, how=\"left\", on=\"article_id\")\n",
    "        a[label] = a[label].fillna(0)\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Articles preference depending on the sales channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def articles_sales_channel(a,t):\n",
    "    grouped = t.groupby([\"article_id\", \"sales_channel_id\"])[\"customer_id\"].count()\n",
    "    percentages = grouped / grouped.groupby(level=0).transform(\"sum\")\n",
    "    for channel in t[\"sales_channel_id\"].unique():\n",
    "        preference = percentages[percentages.index.get_level_values('sales_channel_id') == channel]\n",
    "        name = \"sales_channel_\"+str(channel)\n",
    "        preference = preference.rename(name)\n",
    "        a = a.merge(preference, how=\"left\", on=\"article_id\")\n",
    "        a[name] = a[name].fillna(0)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE GROUP DISTRIBUTION\n",
      "\n",
      "age_group\n",
      "adult_preferences         492701\n",
      "young_preference          357169\n",
      "middle_aged_preference    339444\n",
      "senior_preference         182666\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lh/cqh_8gcn57d810dp36x50d5h0000gn/T/ipykernel_6172/2002395096.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = t.groupby([\"article_id\", \"age_group\"])[\"customer_id\"].count()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>perceived_colour_master_name</th>\n",
       "      <th>department_name</th>\n",
       "      <th>index_name</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>winter_sale</th>\n",
       "      <th>spring_sale</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_1_2020</th>\n",
       "      <th>rank_2_2020</th>\n",
       "      <th>rank_3_2020</th>\n",
       "      <th>rank_4_2020</th>\n",
       "      <th>young_preference</th>\n",
       "      <th>adult_preferences</th>\n",
       "      <th>middle_aged_preference</th>\n",
       "      <th>senior_preference</th>\n",
       "      <th>sales_channel_2</th>\n",
       "      <th>sales_channel_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.366756</td>\n",
       "      <td>0.258094</td>\n",
       "      <td>...</td>\n",
       "      <td>936.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>0.181902</td>\n",
       "      <td>0.528826</td>\n",
       "      <td>0.218153</td>\n",
       "      <td>0.071119</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>0.229222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256966</td>\n",
       "      <td>0.420552</td>\n",
       "      <td>...</td>\n",
       "      <td>909.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.168690</td>\n",
       "      <td>0.484690</td>\n",
       "      <td>0.244138</td>\n",
       "      <td>0.102483</td>\n",
       "      <td>0.710207</td>\n",
       "      <td>0.289793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>...</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>0.158140</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.190698</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.995349</td>\n",
       "      <td>0.004651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.125479</td>\n",
       "      <td>...</td>\n",
       "      <td>926.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>0.136015</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.375479</td>\n",
       "      <td>0.624521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543599</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>...</td>\n",
       "      <td>940.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>0.152134</td>\n",
       "      <td>0.319109</td>\n",
       "      <td>0.419295</td>\n",
       "      <td>0.109462</td>\n",
       "      <td>0.654917</td>\n",
       "      <td>0.345083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105537</th>\n",
       "      <td>105537</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105538</th>\n",
       "      <td>105538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105539</th>\n",
       "      <td>105539</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105540</th>\n",
       "      <td>105540</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105541</th>\n",
       "      <td>105541</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>105541.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105542 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id  product_type_name  graphical_appearance_name  \\\n",
       "0                0                  0                          0   \n",
       "1                1                  0                          0   \n",
       "2                2                  0                          1   \n",
       "3                3                  1                          0   \n",
       "4                4                  1                          0   \n",
       "...            ...                ...                        ...   \n",
       "105537      105537                  3                         18   \n",
       "105538      105538                  0                          0   \n",
       "105539      105539                 25                          0   \n",
       "105540      105540                  8                          0   \n",
       "105541      105541                 25                          0   \n",
       "\n",
       "        perceived_colour_master_name  department_name  index_name  \\\n",
       "0                                  0                0           0   \n",
       "1                                  1                0           0   \n",
       "2                                  1                0           0   \n",
       "3                                  0                1           1   \n",
       "4                                  1                1           1   \n",
       "...                              ...              ...         ...   \n",
       "105537                             0               60           3   \n",
       "105538                             0                5           0   \n",
       "105539                             0                5           0   \n",
       "105540                             0               30           7   \n",
       "105541                             1                5           0   \n",
       "\n",
       "        section_name  garment_group_name  winter_sale  spring_sale  ...  \\\n",
       "0                  0                   0     0.366756     0.258094  ...   \n",
       "1                  0                   0     0.256966     0.420552  ...   \n",
       "2                  0                   0     0.027907     0.004651  ...   \n",
       "3                  1                   1     0.252874     0.125479  ...   \n",
       "4                  1                   1     0.543599     0.081633  ...   \n",
       "...              ...                 ...          ...          ...  ...   \n",
       "105537             4                   2     0.000000     0.000000  ...   \n",
       "105538            24                   3     0.000000     0.000000  ...   \n",
       "105539            28                   3     0.000000     0.000000  ...   \n",
       "105540            13                   4     0.000000     0.000000  ...   \n",
       "105541            28                   3     0.000000     0.000000  ...   \n",
       "\n",
       "        rank_1_2020  rank_2_2020  rank_3_2020  rank_4_2020  young_preference  \\\n",
       "0             936.0       1409.0       1467.0     105541.0          0.181902   \n",
       "1             909.0       1286.0       1329.0        603.0          0.168690   \n",
       "2          105541.0     105541.0     105541.0     105541.0          0.158140   \n",
       "3             926.0       1422.0       1458.0     105541.0          0.136015   \n",
       "4             940.0       1422.0       1464.0     105541.0          0.152134   \n",
       "...             ...          ...          ...          ...               ...   \n",
       "105537     105541.0     105541.0     105541.0        596.0          0.117647   \n",
       "105538     105541.0     105541.0     105541.0        578.0          0.114286   \n",
       "105539     105541.0     105541.0     105541.0        592.0          0.095238   \n",
       "105540     105541.0     105541.0     105541.0     105541.0          0.000000   \n",
       "105541     105541.0     105541.0     105541.0     105541.0          0.000000   \n",
       "\n",
       "        adult_preferences  middle_aged_preference  senior_preference  \\\n",
       "0                0.528826                0.218153           0.071119   \n",
       "1                0.484690                0.244138           0.102483   \n",
       "2                0.534884                0.190698           0.116279   \n",
       "3                0.405172                0.363985           0.094828   \n",
       "4                0.319109                0.419295           0.109462   \n",
       "...                   ...                     ...                ...   \n",
       "105537           0.647059                0.176471           0.058824   \n",
       "105538           0.628571                0.200000           0.057143   \n",
       "105539           0.142857                0.285714           0.476190   \n",
       "105540           0.000000                0.000000           0.000000   \n",
       "105541           0.000000                0.000000           0.000000   \n",
       "\n",
       "        sales_channel_2  sales_channel_1  \n",
       "0              0.770778         0.229222  \n",
       "1              0.710207         0.289793  \n",
       "2              0.995349         0.004651  \n",
       "3              0.375479         0.624521  \n",
       "4              0.654917         0.345083  \n",
       "...                 ...              ...  \n",
       "105537         1.000000         0.000000  \n",
       "105538         1.000000         0.000000  \n",
       "105539         1.000000         0.000000  \n",
       "105540         0.000000         0.000000  \n",
       "105541         0.000000         0.000000  \n",
       "\n",
       "[105542 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = seasonal_sales(articles, transactions)\n",
    "articles = get_avg_price(articles, transactions)\n",
    "articles = seasonal_bestseller_ranking(articles, transactions)\n",
    "articles = age_articles_preference(articles, transactions, customers)\n",
    "articles = articles_sales_channel(articles,transactions)\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding \n",
    "articles = articles.set_index(\"article_id\")\n",
    "customers = customers.set_index(\"customer_id\")\n",
    "\n",
    "articles_categorical = [\"product_type_name\",\"graphical_appearance_name\",\n",
    "                        \"perceived_colour_master_name\",\"department_name\",\n",
    "                        \"index_name\",\"section_name\",\"garment_group_name\"]\n",
    "\n",
    "articles_cont = ['winter_sale', 'spring_sale','summer_sale', 'autumn_sale',\n",
    "                'avg_price','rank_3_2020', 'rank_4_2020', 'young_preference', \n",
    "                'adult_preferences', 'middle_aged_preference','senior_preference', \n",
    "                'sales_channel_2', 'sales_channel_1']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), articles_categorical)\n",
    "        ,('cont', 'passthrough', articles_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "\n",
    "articles = csr_matrix(preprocessor.fit_transform(articles))\n",
    "\n",
    "customers_categorical = [\"FN\",'Active',\"club_member_status\", \"fashion_news_frequency\"]\n",
    "customers_cont = [\"age\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), customers_categorical),\n",
    "        ('cont', 'passthrough', customers_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "customers = csr_matrix(preprocessor.fit_transform(customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [14:37<00:00, 63.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] - Train Loss: 0.5242, Validation Loss: 0.4850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [14:44<00:00, 62.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3] - Train Loss: 0.5242, Validation Loss: 0.4850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [14:36<00:00, 63.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3] - Train Loss: 0.5242, Validation Loss: 0.4850\n"
     ]
    }
   ],
   "source": [
    "# deep architecture\n",
    "transactions_negatives = pd.read_csv(\"data/preprocessed/transactions_negatives.csv\")\n",
    "train_dataloader, val_dataloader, test_customers = load_data_mf(transactions_negatives, batch_size=1000)\n",
    "input_article_dim = articles.shape[1]\n",
    "input_customer_dim = customers.shape[1]\n",
    "model = TwoTowerFinal(input_article_dim, input_customer_dim, output_dim=10)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "save_dir = \"AI_project/RQ1/models/TwoTowerArticles.pt\"\n",
    "val_loss_tower = train_two_tower(model, customers, articles, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Customer Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1363/1363 [00:10<00:00, 126.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Articles Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1056/1056 [00:04<00:00, 211.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get recommendations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:27<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0024297322890133527\n",
      "Recall: 0.0014536421017498234\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "TwoTower = torch.load(\"AI_project/RQ1/models/TwoTowerArticles.pt\")\n",
    "matrix_full = matrix_representation(transactions, train_test=False)\n",
    "targets = matrix_full[test_customers]\n",
    "targets[targets>1] = 1\n",
    "# dataloader\n",
    "dataloader_cust, dataloader_art = load_customers_articles(customers, articles, test_customers=test_customers, batch_size=100)\n",
    "# get restrictions\n",
    "last_sold = transactions.groupby(\"article_id\")[\"t_dat\"].max()\n",
    "articles_recently_sold = [last_sold[last_sold > '2020-08-22'].index.tolist()]\n",
    "# generate recommendations\n",
    "recommendations, recall, precision = recommender_two_towers_final(TwoTower, dataloader_cust, dataloader_art, targets, articles_recently_sold, evaluate=True, top_k=12)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add customers features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read customers and transactions data\n",
    "customers = pd.read_csv(\"data/preprocessed/customers.csv\") \n",
    "transactions = pd.read_csv(\"data/preprocessed/transactions.csv\")\n",
    "articles = pd.read_csv(\"data/preprocessed/articles.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE GROUP DISTRIBUTION\n",
      "\n",
      "age_group\n",
      "adult_preferences         492701\n",
      "young_preference          357169\n",
      "middle_aged_preference    339444\n",
      "senior_preference         182666\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karol/Desktop/Antwerp/ai_project/AI_project/RQ1/data_reader.py:609: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = t.groupby([\"article_id\", \"age_group\"])[\"customer_id\"].count()\n"
     ]
    }
   ],
   "source": [
    "customers = customers_diversification(customers, transactions, articles)\n",
    "articles = articles_diversification(articles, transactions, customers)\n",
    "\n",
    "# one hot encoding \n",
    "articles = articles.set_index(\"article_id\")\n",
    "customers = customers.set_index(\"customer_id\")\n",
    "\n",
    "articles_categorical = [\"product_type_name\",\"graphical_appearance_name\",\n",
    "                        \"perceived_colour_master_name\",\"department_name\",\n",
    "                        \"index_name\",\"section_name\",\"garment_group_name\"]\n",
    "\n",
    "articles_cont = ['winter_sale', 'spring_sale','summer_sale', 'autumn_sale',\n",
    "                'avg_price','rank_3_2020', 'rank_4_2020', 'young_preference', \n",
    "                'adult_preferences', 'middle_aged_preference','senior_preference', \n",
    "                'sales_channel_2', 'sales_channel_1']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), articles_categorical)\n",
    "        ,('cont', 'passthrough', articles_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "\n",
    "articles = csr_matrix(preprocessor.fit_transform(articles))\n",
    "\n",
    "customers_categorical = [\"FN\",'Active',\"club_member_status\", \"fashion_news_frequency\", \"favourite_color\", \"preferred_garment\"]\n",
    "customers_cont = [\"age\",\"first_channel\", \"second_channel\", \"avg_price\", \"amount_purchases\",\"manswear\",\"ladieswear\", \"kids\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), customers_categorical),\n",
    "        ('cont', 'passthrough', customers_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "customers = csr_matrix(preprocessor.fit_transform(customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [16:21<00:00, 56.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] - Train Loss: 0.5242, Validation Loss: 0.4850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [16:26<00:00, 56.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3] - Train Loss: 0.5242, Validation Loss: 0.4850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [16:37<00:00, 55.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3] - Train Loss: 0.5242, Validation Loss: 0.4850\n"
     ]
    }
   ],
   "source": [
    "# deep architecture\n",
    "transactions_negatives = pd.read_csv(\"data/preprocessed/transactions_negatives.csv\")\n",
    "train_dataloader, val_dataloader, test_customers = load_data_mf(transactions_negatives, batch_size=1000)\n",
    "input_article_dim = articles.shape[1]\n",
    "input_customer_dim = customers.shape[1]\n",
    "model = TwoTowerCustomer(input_article_dim, input_customer_dim, output_dim=10)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "save_dir = \"AI_project/RQ1/models/TwoTowerArtCust.pt\"\n",
    "val_loss_tower = train_two_tower(model, customers, articles, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Customer Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1363/1363 [00:10<00:00, 126.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Articles Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1056/1056 [00:04<00:00, 224.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get recommendations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:27<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0024297322890133527\n",
      "Recall: 0.0014536421017498234\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "TwoTower = torch.load(\"AI_project/RQ1/models/TwoTowerArtCust.pt\")\n",
    "matrix_full = matrix_representation(transactions, train_test=False)\n",
    "targets = matrix_full[test_customers]\n",
    "targets[targets>1] = 1\n",
    "# dataloader\n",
    "dataloader_cust, dataloader_art = load_customers_articles(customers, articles, test_customers=test_customers, batch_size=100)\n",
    "# get restrictions\n",
    "last_sold = transactions.groupby(\"article_id\")[\"t_dat\"].max()\n",
    "articles_recently_sold = [last_sold[last_sold > '2020-08-22'].index.tolist()]\n",
    "# generate recommendations\n",
    "recommendations, recall, precision = recommender_two_towers_customer(TwoTower, dataloader_cust, dataloader_art, targets, articles_recently_sold, evaluate=True, top_k=12)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE GROUP DISTRIBUTION\n",
      "\n",
      "age_group\n",
      "adult_preferences         492701\n",
      "young_preference          357169\n",
      "middle_aged_preference    339444\n",
      "senior_preference         182666\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karol/Desktop/Antwerp/ai_project/AI_project/RQ1/data_reader.py:609: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = t.groupby([\"article_id\", \"age_group\"])[\"customer_id\"].count()\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding \n",
    "articles = articles.set_index(\"article_id\")\n",
    "customers = customers.set_index(\"customer_id\")\n",
    "\n",
    "articles_categorical = [\"product_type_name\",\"graphical_appearance_name\",\n",
    "                        \"perceived_colour_master_name\",\"department_name\",\n",
    "                        \"index_name\",\"section_name\",\"garment_group_name\"]\n",
    "\n",
    "articles_cont = ['winter_sale', 'spring_sale','summer_sale', 'autumn_sale',\n",
    "                'avg_price', 'young_preference', \n",
    "                'adult_preferences', 'middle_aged_preference','senior_preference', \n",
    "                'sales_channel_2', 'sales_channel_1']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), articles_categorical)\n",
    "        ,('cont', 'passthrough', articles_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "\n",
    "articles = csr_matrix(preprocessor.fit_transform(articles))\n",
    "\n",
    "customers_categorical = [\"FN\",'Active',\"club_member_status\", \"fashion_news_frequency\"]\n",
    "customers_cont = [\"age\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), customers_categorical),\n",
    "        ('cont', 'passthrough', customers_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "customers = csr_matrix(preprocessor.fit_transform(customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [14:19<00:00, 64.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] - Train Loss: 0.1434, Validation Loss: 0.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [15:59<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3] - Train Loss: 0.1402, Validation Loss: 0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [17:14<00:00, 53.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3] - Train Loss: 0.1420, Validation Loss: 0.1382\n"
     ]
    }
   ],
   "source": [
    "# deep architecture\n",
    "transactions_negatives = pd.read_csv(\"data/preprocessed/transactions_negatives.csv\")\n",
    "train_dataloader, val_dataloader, test_customers = load_data_mf(transactions_negatives, batch_size=1000)\n",
    "input_article_dim = articles.shape[1]\n",
    "input_customer_dim = customers.shape[1]\n",
    "model = TwoTowerFinal(input_article_dim, input_customer_dim, output_dim=10)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "save_dir = \"AI_project/RQ1/models/TwoTowerArticlesTest.pt\"\n",
    "val_loss_tower = train_two_tower(model, customers, articles, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Article model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE GROUP DISTRIBUTION\n",
      "\n",
      "age_group\n",
      "adult_preferences         492701\n",
      "young_preference          357169\n",
      "middle_aged_preference    339444\n",
      "senior_preference         182666\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karol/Desktop/Antwerp/ai_project/AI_project/RQ1/data_reader.py:609: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = t.groupby([\"article_id\", \"age_group\"])[\"customer_id\"].count()\n"
     ]
    }
   ],
   "source": [
    "articles = articles_diversification(articles, transactions, customers)\n",
    "\n",
    "# one hot encoding \n",
    "articles = articles.set_index(\"article_id\")\n",
    "customers = customers.set_index(\"customer_id\")\n",
    "\n",
    "articles_categorical = [\"product_type_name\",\"graphical_appearance_name\",\n",
    "                        \"perceived_colour_master_name\",\"department_name\",\n",
    "                        \"index_name\",\"section_name\",\"garment_group_name\"]\n",
    "\n",
    "articles_cont = ['winter_sale', 'spring_sale','summer_sale', 'autumn_sale',\n",
    "                'avg_price','young_preference', 'adult_preferences', \n",
    "                'middle_aged_preference','senior_preference', \n",
    "                'sales_channel_2', 'sales_channel_1']\n",
    "\n",
    "min_max_cols = ['rank_3_2020', 'rank_4_2020']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), articles_categorical),\n",
    "        ('cont', 'passthrough', articles_cont),\n",
    "        (\"min_max\", MinMaxScaler(), min_max_cols)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "\n",
    "articles = csr_matrix(preprocessor.fit_transform(articles))\n",
    "\n",
    "customers_categorical = [\"FN\",'Active',\"club_member_status\", \"fashion_news_frequency\"]\n",
    "customers_cont = [\"age\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), customers_categorical),\n",
    "        ('cont', 'passthrough', customers_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "customers = csr_matrix(preprocessor.fit_transform(customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [14:31<00:00, 63.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] - Train Loss: 0.1449, Validation Loss: 0.1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [14:25<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3] - Train Loss: 0.1429, Validation Loss: 0.1386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55595/55595 [14:23<00:00, 64.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3] - Train Loss: 0.1403, Validation Loss: 0.1381\n"
     ]
    }
   ],
   "source": [
    "# deep architecture\n",
    "transactions_negatives = pd.read_csv(\"data/preprocessed/transactions_negatives.csv\")\n",
    "train_dataloader, val_dataloader, test_customers = load_data_mf(transactions_negatives, batch_size=1000)\n",
    "input_article_dim = articles.shape[1]\n",
    "input_customer_dim = customers.shape[1]\n",
    "model = TwoTowerFinal(input_article_dim, input_customer_dim, output_dim=10)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "save_dir = \"AI_project/RQ1/models/TwoTowerArticles.pt\"\n",
    "val_loss_tower = train_two_tower(model, customers, articles, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Customer Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1363/1363 [00:11<00:00, 118.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Articles Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1056/1056 [00:04<00:00, 224.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get recommendations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:34<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.011841580476012204\n",
      "Recall: 0.007084492398205711\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "TwoTower = torch.load(\"AI_project/RQ1/models/TwoTowerArticles.pt\")\n",
    "matrix_full = matrix_representation(transactions, train_test=False)\n",
    "targets = matrix_full[test_customers]\n",
    "targets[targets>1] = 1\n",
    "# dataloader\n",
    "dataloader_cust, dataloader_art = load_customers_articles(customers, articles, test_customers=test_customers, batch_size=100)\n",
    "# get restrictions\n",
    "last_sold = transactions.groupby(\"article_id\")[\"t_dat\"].max()\n",
    "articles_recently_sold = [last_sold[last_sold > '2020-08-22'].index.tolist()]\n",
    "# generate recommendations\n",
    "recommendations, recall, precision = recommender_two_towers_final(TwoTower, dataloader_cust, dataloader_art, targets, articles_recently_sold, evaluate=True, top_k=12)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
