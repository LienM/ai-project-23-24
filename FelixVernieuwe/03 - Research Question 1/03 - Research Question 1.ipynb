{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignments by Felix Vernieuwe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df4e549c1bebb94d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Assignment 3: Research Question 1\n",
    "#### **QUESTION:** *Quantify the importance of global, contextual and personalised candidates in evaluation and output score*\n",
    "\n",
    "---\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e51aea5d4059b432"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Pratical note:** this notebook reworks the Radek LGBM baseline to better compartmentalize candidate and feature generation, building upon the work of 02 - FE, and further inspired by Noah's template "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e20da666a0ef1117"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from FelixVernieuwe.util import *\n",
    "from scorers import mean_average_precision\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "setup_seaborn()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:33.169238900Z",
     "start_time": "2023-11-20T20:29:32.591242200Z"
    }
   },
   "id": "45b18b37211c1233"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Environment variables\n",
    "DATA_PATH = \"../../data/\"\n",
    "OUTPUT_PATH = \"../../data/submissions/\"\n",
    "\n",
    "# Get OS profile root to get path to /.kaggle/kaggle.json\n",
    "PROFILE_ROOT = os.environ.get(\"HOME\", os.environ.get(\"USERPROFILE\", \"\"))\n",
    "KAGGLE_PATH = pathlib.Path(PROFILE_ROOT, \".kaggle/kaggle.json\").as_posix()\n",
    "print(initialise_kaggle(KAGGLE_PATH))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:33.251708700Z",
     "start_time": "2023-11-20T20:29:33.171237200Z"
    }
   },
   "id": "1b4936d81241885f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Output description\n",
    "SUBMISSION_NAME = \"engineered_7_submission\"\n",
    "DESCRIPTION = \"Retesting baseline with rewrite\"\n",
    "UPLOAD_TO_KAGGLE = True\n",
    "INCLUDE_MISSING_CUSTOMERS = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:33.310643500Z",
     "start_time": "2023-11-20T20:29:33.245706800Z"
    }
   },
   "id": "9c56a3340cac0e0c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load in the datasets\n",
    "articles = pd.read_parquet(DATA_PATH + \"articles.parquet\")\n",
    "all_transactions = pd.read_parquet(DATA_PATH + \"transactions_train.parquet\")\n",
    "customers = pd.read_parquet(DATA_PATH + \"customers.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:34.354418300Z",
     "start_time": "2023-11-20T20:29:33.311640200Z"
    }
   },
   "id": "f83fe8a4f3990dc1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Features to train on\n",
    "base_features = [\n",
    "    'article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "    'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "    'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', \n",
    "    \n",
    "]\n",
    "\n",
    "added_features = [\n",
    "    'has_promotion', 'bestseller_rank', 'all_time_rank', 'price_sensitivity'\n",
    "]\n",
    "\n",
    "all_features = base_features + added_features\n",
    "\n",
    "def join_all_features(transactions, articles, customers):\n",
    "    # Join all features together\n",
    "    transactions = transactions.merge(articles, on=\"article_id\", how=\"left\")\n",
    "    transactions = transactions.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "\n",
    "def filter_feature_data(data):\n",
    "    # Train only on available features in the data, and specified features above \n",
    "    available_features = [feature for feature in all_features if feature in data.columns]\n",
    "    \n",
    "    return data[available_features], available_features\n",
    "\n",
    "\n",
    "def clean_up_transaction_data(data):\n",
    "    # Clean up incoming data\n",
    "    data.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "    data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if \"bought\" not in data:\n",
    "        data[\"bought\"] = 1\n",
    "        \n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:34.426551800Z",
     "start_time": "2023-11-20T20:29:34.359418200Z"
    }
   },
   "id": "863f556c93f6fd66"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Reference week (i.e. the last week of our training data, any week after this can be considered part of the test set)\n",
    "# In the current training set, the last week is 104, if we take this as reference, we will try to make predictions for week 105\n",
    "\n",
    "\n",
    "# Iff AMOUNT_OF_TEST_WEEKS > 0, then the model will be tested on itself, instead of the Kaggle score\n",
    "AMOUNT_OF_TEST_WEEKS = 2\n",
    "\n",
    "# How many weeks to train on\n",
    "TRAINING_INTERVAL = 2\n",
    "\n",
    "\n",
    "REFERENCE_WEEK = all_transactions[\"week\"].max() - AMOUNT_OF_TEST_WEEKS\n",
    "\n",
    "#Output additional graphs and information\n",
    "VERBOSE = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:34.498412600Z",
     "start_time": "2023-11-20T20:29:34.427551200Z"
    }
   },
   "id": "ae1177052203ea9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Feature Engineering\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c7552cca43892cd"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from features import *\n",
    "from candidates import *\n",
    "from data import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:34.573237100Z",
     "start_time": "2023-11-20T20:29:34.500412300Z"
    }
   },
   "id": "134a8eb66466499b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Filter out all transactions that are outside of the training interval\n",
    "transactions = all_transactions[all_transactions[\"week\"] >= REFERENCE_WEEK - TRAINING_INTERVAL]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:34.691124600Z",
     "start_time": "2023-11-20T20:29:34.575244500Z"
    }
   },
   "id": "d87c3ccb606786e1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "# DISCLAIMER: this concept was copied from Noah's ExperimentTemplate notebook (test_data is used for offline evaluation)\n",
    "train_data, test_data = split_dataframe(transactions, transactions[\"week\"] <= REFERENCE_WEEK)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:34.796363900Z",
     "start_time": "2023-11-20T20:29:34.693126100Z"
    }
   },
   "id": "52bf4931de9a69dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### General feature data\n",
    "(does not get added to the training data, but is used to generate candidates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fffeae90d45292cf"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "bestsellers_per_week = most_sold_per_week(train_data, REFERENCE_WEEK)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:34.991256500Z",
     "start_time": "2023-11-20T20:29:34.798364200Z"
    }
   },
   "id": "f218c535e89faad7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### General customer candidate data\n",
    "(determines which customers are applicable for candidate generation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f56666bdf7592d00"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "candidate_customers, ref_week_candidate_customers = get_buying_customers_candidates(train_data, REFERENCE_WEEK)\n",
    "candidates = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:35.191783Z",
     "start_time": "2023-11-20T20:29:34.992260900Z"
    }
   },
   "id": "cb94dd7795a79054"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Global Candidates (apply to every person)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8b55d07aaa24a64"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Add weekly bestsellers to each candidate customer as transaction candidates\n",
    "bestseller_candidates = candidate_bestsellers_weekly(candidate_customers, ref_week_candidate_customers, bestsellers_per_week)\n",
    "candidates.append(bestseller_candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:35.519390100Z",
     "start_time": "2023-11-20T20:29:35.192783700Z"
    }
   },
   "id": "8d9930568904415c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Add new arrivals to each candidate customer as transaction candidates\n",
    "# new_arrival_candidates = candidate_new_arrivals(candidate_customers, ref_week_candidate_customers, all_transactions, REFERENCE_WEEK)\n",
    "# candidates.append(new_arrival_candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:35.586503600Z",
     "start_time": "2023-11-20T20:29:35.520394500Z"
    }
   },
   "id": "46de7e520a101205"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Contextual Candidates (apply to groups of people)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efa9a3583cc9d9ad"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:35.654075100Z",
     "start_time": "2023-11-20T20:29:35.589943300Z"
    }
   },
   "id": "6c086a44dc86089c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Personalised Candidates (apply to individuals)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e624bde9c1062c35"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Recall previous purchases of customers (i.e. repeat article in the next week)\n",
    "previous_purchase_candidates = candidate_previous_purchases(train_data, REFERENCE_WEEK)\n",
    "candidates.append(previous_purchase_candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:56.399551500Z",
     "start_time": "2023-11-20T20:29:35.656076Z"
    }
   },
   "id": "4643dae944866b57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine Candidates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d2b250f99136a6c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felix\\AppData\\Local\\Temp\\ipykernel_22096\\4214799693.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[\"bought\"] = 1\n"
     ]
    }
   ],
   "source": [
    "train_data[\"bought\"] = 1\n",
    "\n",
    "# Add all candidates together with the training data\n",
    "train_data = pd.concat([train_data] + candidates, ignore_index=True)\n",
    "train_data.fillna(0, inplace=True)\n",
    "\n",
    "# Drop duplicate candidates and transactions\n",
    "train_data.drop_duplicates([\"customer_id\", \"article_id\", \"week\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:57.393634500Z",
     "start_time": "2023-11-20T20:29:56.401556200Z"
    }
   },
   "id": "cbf6b0d8ea97ac11"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec04bd0881a2cc7a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Weekly Bestseller feature\n",
    "train_data = weekly_bestseller_feature(train_data, bestsellers_per_week)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:57.786805Z",
     "start_time": "2023-11-20T20:29:57.394645500Z"
    }
   },
   "id": "4e4717b322b793f9"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# All time Bestseller feature\n",
    "# train_data = overal_bestseller_feature(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:57.851177500Z",
     "start_time": "2023-11-20T20:29:57.786805Z"
    }
   },
   "id": "7f3ea25b1edee6d8"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Price sensitivity feature\n",
    "# train_data = price_sensitivity_feature(train_data, customers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:57.915667500Z",
     "start_time": "2023-11-20T20:29:57.852175800Z"
    }
   },
   "id": "aefbdc3a16ea5010"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# New arrivals feature\n",
    "# train_data = product_age_feature(all_transactions, train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:57.980789300Z",
     "start_time": "2023-11-20T20:29:57.916664600Z"
    }
   },
   "id": "eca37c56d71c96ab"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Promotion feature\n",
    "# train_data = discount_feature(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:58.051133400Z",
     "start_time": "2023-11-20T20:29:57.981785Z"
    }
   },
   "id": "803b7c8737fd6f04"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Final clean-up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "674bb07fc0817b4f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Removes the first week of the training data (since it does not have any data it can base itself on for some features)\n",
    "train_data = train_data[train_data['week'] != train_data['week'].min()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:58.264155Z",
     "start_time": "2023-11-20T20:29:58.048133400Z"
    }
   },
   "id": "398840c716069c9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Model Training\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fce01ac06aa7334d"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Data clean-up\n",
    "train_data = clean_up_transaction_data(train_data)\n",
    "\n",
    "# Split training data into two sets\n",
    "train_data, test_candidates = split_dataframe(train_data, train_data[\"week\"] < REFERENCE_WEEK)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:29:59.564816900Z",
     "start_time": "2023-11-20T20:29:58.266158700Z"
    }
   },
   "id": "21c9072a56bf255"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Join all features together\n",
    "train_data = join_all_features(train_data, articles, customers)\n",
    "\n",
    "# Gives amount of items purchased per customer per week (used for training the ranking)\n",
    "train_bins = train_data.groupby([\"week\", \"customer_id\"])[\"article_id\"].count().values\n",
    "\n",
    "# Train only on specified features\n",
    "train_X, available_features = filter_feature_data(train_data)\n",
    "train_y = train_data[\"bought\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:00.192877500Z",
     "start_time": "2023-11-20T20:29:59.567818Z"
    }
   },
   "id": "fdde95a01fd543fe"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "ranker = LGBMRanker(\n",
    "    force_row_wise=True,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10 if VERBOSE else 0,\n",
    ")\n",
    "\n",
    "ranker = ranker.fit(train_X, train_y, group=train_bins)\n",
    "\n",
    "# Get the relative importance of the feature according to the ranker\n",
    "feature_importance = feature_importance_df(ranker, available_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:00.737308200Z",
     "start_time": "2023-11-20T20:30:00.195390800Z"
    }
   },
   "id": "e6826505dc802c94"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Graph importances on bar chart\n",
    "if VERBOSE:\n",
    "    graph_feature_importance(feature_importance)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:00.806627600Z",
     "start_time": "2023-11-20T20:30:00.739310600Z"
    }
   },
   "id": "16c656a79d660e85"
  },
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a27279504ea99c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Prediction generation\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8fc354c95884c4e"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "test_candidates = test_candidates.drop_duplicates([\"customer_id\", \"article_id\", \"sales_channel_id\"]).copy()\n",
    "test_candidates = join_all_features(test_candidates, articles, customers)\n",
    "test_X, available_features = filter_feature_data(test_candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:02.166811100Z",
     "start_time": "2023-11-20T20:30:00.807627500Z"
    }
   },
   "id": "5095b6fc7dc283e1"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def calculate_predictions(candidates, features, ranker, k=12):\n",
    "    \"\"\"\n",
    "    Retrieves dataframe for top 12 candidate articles per customer\n",
    "    NOTE: Partially adapted from Noah's ExperimentTemplate notebook\n",
    "    \n",
    "    :param candidates: Filtered dataframe combining only selected features\n",
    "    :param features: Filtered dataframe combining the features of transactions, articles and customers\n",
    "    :param ranker: Trained ranker model\n",
    "    :param k: Number of articles to predict per customer\n",
    "    :return: Dataframe containing the top k articles per customer\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict on test set\n",
    "    features = features.copy()\n",
    "    features[\"score\"] = ranker.predict(candidates)\n",
    "    features.sort_values([\"customer_id\", \"score\"], ascending=False, inplace=True)\n",
    "    features = features.groupby(\"customer_id\").head(k).reset_index(drop=True)\n",
    "    \n",
    "    return features[[\"article_id\", \"customer_id\", \"score\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:02.233748200Z",
     "start_time": "2023-11-20T20:30:02.168811800Z"
    }
   },
   "id": "6031a242446cf710"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "predicted_candidates = calculate_predictions(test_X, test_candidates, ranker)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:03.734256500Z",
     "start_time": "2023-11-20T20:30:02.233748200Z"
    }
   },
   "id": "41b515cbf29db3f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Model Evaluation / Submission\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a445360f6e3d25cd"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Products that also may prove to be generally interesting (excluding bestsellers)\n",
    "# interesting_products = []\n",
    "# if promoted_articles is not None:\n",
    "#     current_promos = promoted_articles[promoted_articles[\"week\"] == REFERENCE_WEEK - 1]\n",
    "#     bestsellers_df = pd.DataFrame({\"article_id\": bestsellers})\n",
    "#     interesting_products = bestsellers_df.merge(current_promos, on=\"article_id\", how=\"inner\")\n",
    "#     interesting_products = interesting_products[interesting_products[\"has_promotion\"] == True][\"article_id\"].tolist()\n",
    "\n",
    "# Bestselling products in the previous week\n",
    "bestsellers = transactions[transactions[\"week\"] == REFERENCE_WEEK - 1][\"article_id\"].value_counts().head(12).index.tolist()\n",
    "# interesting_products = set(interesting_products)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:03.847837800Z",
     "start_time": "2023-11-20T20:30:03.737257900Z"
    }
   },
   "id": "53718059c6cd0ecc"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "predicted_candidates = predicted_candidates[[\"article_id\", \"customer_id\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:03.933503500Z",
     "start_time": "2023-11-20T20:30:03.848838800Z"
    }
   },
   "id": "a50e78e40d9573d0"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Add extra articles to customers that do not have any predictions\n",
    "missing_customers = pd.DataFrame({\"customer_id\": customers[\"customer_id\"].unique()})\n",
    "missing_customers = missing_customers[~missing_customers[\"customer_id\"].isin(test_candidates[\"customer_id\"].unique())]\n",
    "missing_customers = missing_customers.merge(pd.DataFrame({\"article_id\": bestsellers}), how=\"cross\")\n",
    "\n",
    "# Join the two dataframes together (predicted candidates and missing customers)\n",
    "predicted_candidates = pd.concat([predicted_candidates, missing_customers], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:04.542064300Z",
     "start_time": "2023-11-20T20:30:03.934503200Z"
    }
   },
   "id": "63a9abe4eaa6b7c4"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column average_precision@k",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22096\\1980598755.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;31m# Rename column to match the predicted candidates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mground_truth_purchases\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"article_id\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m\"purchases\"\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0mpredicted_purchases\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"article_id\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;34m\"predictions\"\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m     \u001B[0mtruth_prediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmean_average_precision\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredicted_purchases\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mground_truth_purchases\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m     \u001B[0mtruth_prediction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mA:\\Python\\ai-project-23-24\\FelixVernieuwe\\03 - Research Question 1\\scorers.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(predictions, truth, k)\u001B[0m\n\u001B[0;32m     26\u001B[0m     \"\"\"\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[1;31m# Join the predictions and ground truth on customer_id\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m     \u001B[0mtruth_prediction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtruth\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmerge\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mon\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"customer_id\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhow\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"inner\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m     \u001B[0mtruth_prediction\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"average_precision@k\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtruth_prediction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maverage_precision_score\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[1;31m# Return the mean average precision over all customers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtruth_prediction\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"average_precision@k\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtruth\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mA:\\Programs\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4080\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_setitem_frame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4081\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mSeries\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIndex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4082\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_setitem_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4083\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4084\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_set_item_frame_value\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4085\u001B[0m         elif (\n\u001B[0;32m   4086\u001B[0m             \u001B[0mis_list_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4087\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_unique\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mA:\\Programs\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   4238\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4239\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misetitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlocs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4240\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4241\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4242\u001B[1;33m             raise ValueError(\n\u001B[0m\u001B[0;32m   4243\u001B[0m                 \u001B[1;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4244\u001B[0m                 \u001B[1;34mf\"column {key}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4245\u001B[0m             )\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot set a DataFrame with multiple columns to the single column average_precision@k"
     ]
    }
   ],
   "source": [
    "# DISCLAIMER: Evaluate test set/leaderboard concept copied from Noah's ExperimentTemplate notebook\n",
    "\n",
    "# Evaluate on the test set (known data)\n",
    "if test_data.empty is False:\n",
    "    # Filter test_data to only the reference week\n",
    "    ground_truth_purchases = test_data[test_data[\"week\"] == REFERENCE_WEEK]\n",
    "    \n",
    "    # Get dataframe of customers and their bought articles, grouped by customer and as set, for convenient comparison operations\n",
    "    ground_truth_purchases = ground_truth_purchases.groupby(\"customer_id\")[\"article_id\"].apply(set).reset_index()\n",
    "    predicted_purchases = predicted_candidates.groupby(\"customer_id\")[\"article_id\"].apply(list).reset_index()\n",
    "\n",
    "    # Rename column to match the predicted candidates\n",
    "    ground_truth_purchases.rename(columns={\"article_id\": \"purchases\"}, inplace=True)\n",
    "    predicted_purchases.rename(columns={\"article_id\": \"predictions\"}, inplace=True)\n",
    "    \n",
    "    truth_prediction = mean_average_precision(predicted_purchases, ground_truth_purchases)\n",
    "    truth_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:30:32.914750300Z",
     "start_time": "2023-11-20T20:30:04.544067400Z"
    }
   },
   "id": "f18d963e43199c74"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [purchases, customer_id, predictions]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>purchases</th>\n      <th>customer_id</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_prediction = ground_truth_purchases.merge(predicted_purchases, on=\"customer_id\", how=\"inner\")\n",
    "truth_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:31:05.979060400Z",
     "start_time": "2023-11-20T20:31:05.860853200Z"
    }
   },
   "id": "c7d2b009d08eeb3b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "              t_dat           customer_id  article_id     price  \\\n31317806 2020-09-09      4920151714340210   564358058  0.033881   \n31317807 2020-09-09      4920151714340210   568601044  0.050831   \n31317808 2020-09-09      4920151714340210   779781013  0.042356   \n31317809 2020-09-09      4920151714340210   843465004  0.050831   \n31317810 2020-09-09      4920151714340210   715828013  0.033881   \n...             ...                   ...         ...       ...   \n31774722 2020-09-22  18439937050817258297   891591003  0.084729   \n31774723 2020-09-22  18439937050817258297   869706005  0.084729   \n31779097 2020-09-22  18440902715633436014   918894002  0.016932   \n31779098 2020-09-22  18440902715633436014   761269001  0.016932   \n31780475 2020-09-22  18443633011701112574   914868002  0.033881   \n\n          sales_channel_id  week  \n31317806                 1   103  \n31317807                 1   103  \n31317808                 1   103  \n31317809                 1   103  \n31317810                 1   103  \n...                    ...   ...  \n31774722                 2   104  \n31774723                 2   104  \n31779097                 1   104  \n31779098                 1   104  \n31780475                 1   104  \n\n[495552 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31317806</th>\n      <td>2020-09-09</td>\n      <td>4920151714340210</td>\n      <td>564358058</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>31317807</th>\n      <td>2020-09-09</td>\n      <td>4920151714340210</td>\n      <td>568601044</td>\n      <td>0.050831</td>\n      <td>1</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>31317808</th>\n      <td>2020-09-09</td>\n      <td>4920151714340210</td>\n      <td>779781013</td>\n      <td>0.042356</td>\n      <td>1</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>31317809</th>\n      <td>2020-09-09</td>\n      <td>4920151714340210</td>\n      <td>843465004</td>\n      <td>0.050831</td>\n      <td>1</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>31317810</th>\n      <td>2020-09-09</td>\n      <td>4920151714340210</td>\n      <td>715828013</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>103</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31774722</th>\n      <td>2020-09-22</td>\n      <td>18439937050817258297</td>\n      <td>891591003</td>\n      <td>0.084729</td>\n      <td>2</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>31774723</th>\n      <td>2020-09-22</td>\n      <td>18439937050817258297</td>\n      <td>869706005</td>\n      <td>0.084729</td>\n      <td>2</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>31779097</th>\n      <td>2020-09-22</td>\n      <td>18440902715633436014</td>\n      <td>918894002</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>31779098</th>\n      <td>2020-09-22</td>\n      <td>18440902715633436014</td>\n      <td>761269001</td>\n      <td>0.016932</td>\n      <td>1</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>31780475</th>\n      <td>2020-09-22</td>\n      <td>18443633011701112574</td>\n      <td>914868002</td>\n      <td>0.033881</td>\n      <td>1</td>\n      <td>104</td>\n    </tr>\n  </tbody>\n</table>\n<p>495552 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:31:17.038389800Z",
     "start_time": "2023-11-20T20:31:16.962980700Z"
    }
   },
   "id": "71e092b64080275d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate on leaderboard set (unknown data)\n",
    "if test_data.empty is True:  \n",
    "    # Read in sample submission (customer_id, prediction)\n",
    "    submission = pd.read_csv(DATA_PATH + \"sample_submission.csv\")\n",
    "    \n",
    "    # Convert to a dictionary and replaces the sample submission predictions with our own\n",
    "    predictions = generate_submission_df(submission, predicted_candidates)\n",
    "       \n",
    "    # Write submission to zipped csv\n",
    "    predictions.to_csv(OUTPUT_PATH + f\"{SUBMISSION_NAME}.csv.gz\", index=False)\n",
    "    \n",
    "    # Upload to kaggle\n",
    "    if UPLOAD_TO_KAGGLE:\n",
    "        result = upload_to_kaggle(OUTPUT_PATH + f\"{SUBMISSION_NAME}.csv.gz\", DESCRIPTION)\n",
    "        # Pretty print result\n",
    "        print(json.dumps(result, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:00:05.651984600Z",
     "start_time": "2023-11-20T20:00:05.650983200Z"
    }
   },
   "id": "65f6556427b5faa9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d3b55ce74f95df8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
