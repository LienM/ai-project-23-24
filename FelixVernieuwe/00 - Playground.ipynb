{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ceba5aed859aa4a",
   "metadata": {},
   "source": [
    "# Convert csv to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d276fa39a705a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:44:35.983521100Z",
     "start_time": "2023-11-07T23:44:35.826847800Z"
    }
   },
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6384547f1797c1bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:44:35.999703100Z",
     "start_time": "2023-11-07T23:44:35.985521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all csv files to parquet or vice versa\n",
    "# files = os.listdir('../data')\n",
    "# for file in files:\n",
    "#     if not 'trans' in file: continue\n",
    "#     \n",
    "#     if file.endswith('.csv'):\n",
    "#         convert_csv_to_parquet('../data/' + file)\n",
    "#     elif file.endswith('.parquet'):\n",
    "#         convert_parquet_to_csv('../data/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb30c2551c0c5b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transactions = pd.read_parquet('../data/transactions_train.parquet')\n",
    "\n",
    "# Get all transactions after week\n",
    "reference_week = transactions['week'].max()\n",
    "transactions = transactions[transactions['week'] >= reference_week - 10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T00:23:49.033120800Z",
     "start_time": "2023-11-08T00:23:47.770070900Z"
    }
   },
   "id": "7d19a6586b7b37d9"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "bestseller, recalled_transactions, most_sold_products_per_week_ranked, all_candidate_best_sellers = bestseller_rank_feature(transactions, reference_week)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T00:27:32.449135400Z",
     "start_time": "2023-11-08T00:26:11.371293600Z"
    }
   },
   "id": "11c871b55d807458"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T00:29:42.884305800Z",
     "start_time": "2023-11-08T00:29:38.026839Z"
    }
   },
   "id": "c84d8539e6d36c1b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def bestseller_rank_feature(transactions: pd.DataFrame, reference_week):\n",
    "    recalled_transactions = recall_previous_purchases(transactions, reference_week)\n",
    "    most_sold_products_per_week_ranked = most_sold_per_week(transactions, reference_week)\n",
    "    all_candidate_best_sellers = bestseller_candidates(transactions, reference_week, most_sold_products_per_week_ranked)\n",
    "\n",
    "    # Mark all current transactions as bought\n",
    "    output = transactions.copy()\n",
    "    output['bought'] = 1\n",
    "\n",
    "    # Add all candidates as negative examples of data\n",
    "    output = pd.concat([output, data_shifted, all_candidate_best_sellers])\n",
    "    output.fillna(0, inplace=True)\n",
    "\n",
    "    # Remove accidental duplicates and merge with most sold products per week (to get the bestseller rank)\n",
    "    output.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "    output = pd.merge(output, most_sold_products_per_week_ranked[['week', 'article_id', 'bestseller_rank']], on=['week', 'article_id'], how='left')\n",
    "\n",
    "\n",
    "    # Remove the oldest data\n",
    "    first_week = output['week'].min()\n",
    "    output = output[output['week'] != first_week]\n",
    "\n",
    "    # Fill in all missing bestseller ranks with 999\n",
    "    output['bestseller_rank'].fillna(999, inplace=True)\n",
    "    \n",
    "    return output, recalled_transactions, most_sold_products_per_week_ranked, all_candidate_best_sellers\n",
    "\n",
    "\n",
    "def recall_previous_purchases(transactions: pd.DataFrame, reference_week):\n",
    "    \"\"\"Recall the previous week's purchases as potential candidates for the customer\"\"\"\n",
    "    # Gets the weeks when the customers have bought a product\n",
    "    customer_weekly_purchase_activity = transactions.groupby('customer_id')['week'].unique()\n",
    "\n",
    "    # Get a shift table for the weeks\n",
    "    customer_weekly_purchase_activity_shifted = {}\n",
    "    for customer, weeks in customer_weekly_purchase_activity.items():\n",
    "        customer_weekly_purchase_activity_shifted[customer] = {}\n",
    "        for week in range(weeks.shape[0] - 1):\n",
    "            customer_weekly_purchase_activity_shifted[customer][weeks[week]] = weeks[week + 1]\n",
    "        customer_weekly_purchase_activity_shifted[customer][weeks[-1]] = reference_week\n",
    "\n",
    "    # Shift the transactions data\n",
    "    data_shifted = transactions.copy()\n",
    "    data_shifted['week'] = data_shifted.apply(\n",
    "        lambda row: customer_weekly_purchase_activity_shifted[row['customer_id']][row['week']], axis=1)\n",
    "    data_shifted['cat'] = \"shift\"\n",
    "    return data_shifted\n",
    "\n",
    "def most_sold_per_week(transactions: pd.DataFrame, reference_week):\n",
    "    \"\"\"For every week, add the most sold products as candidates\"\"\"\n",
    "\n",
    "\n",
    "    # Get the mean price per week per product\n",
    "    mean_product_price_per_week = transactions.groupby(['week', 'article_id'])['price'].mean()\n",
    "\n",
    "    # Get the most frequently sold products per week and rank them\n",
    "    most_sold_products_per_week = transactions.groupby('week')['article_id'].value_counts()\n",
    "    most_sold_products_per_week_ranked = most_sold_products_per_week \\\n",
    "        .groupby('week').rank(ascending=False, method='dense') \\\n",
    "        .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "\n",
    "    # Merge most sold products with mean price of the next week\n",
    "    most_sold_products_per_week_ranked = pd.merge(most_sold_products_per_week_ranked, mean_product_price_per_week,\n",
    "                                                  on=['week', 'article_id']).reset_index()\n",
    "    most_sold_products_per_week_ranked['week'] += 1\n",
    "\n",
    "    most_sold_products_per_week_ranked['cat'] = \"most_sold\"\n",
    "\n",
    "    return most_sold_products_per_week_ranked\n",
    "\n",
    "\n",
    "def bestseller_candidates(transactions: pd.DataFrame, reference_week, most_sold_products_per_week_ranked):\n",
    "    # Get all the transactions occurring in week 95 (first week of the dataset)\n",
    "    unique_transactions = transactions.groupby(['week', 'customer_id']).head(1).drop(\n",
    "        columns=['article_id', 'price']).copy()\n",
    "\n",
    "    # Drop all transactions where the customer has bought multiple products in the same week\n",
    "    # ISSUE: This is never assigned in the original code (now commented)\n",
    "    # transactions.drop_duplicates(['week', 'customer_id'])\n",
    "\n",
    "    # Gets the candidate bestsellers for the reference week\n",
    "    candidate_best_sellers = pd.merge(unique_transactions, most_sold_products_per_week_ranked, on='week')\n",
    "\n",
    "    # Gets the transactions for the reference week\n",
    "    reference_week_transactions = unique_transactions.drop_duplicates(subset=['customer_id']).reset_index(drop=True)\n",
    "    reference_week_transactions['week'] = reference_week\n",
    "\n",
    "    # Gets the candidate bestsellers for the reference week\n",
    "    candidate_best_sellers_reference_week = pd.merge(reference_week_transactions, most_sold_products_per_week_ranked, on='week')\n",
    "\n",
    "    # Gets all the candidate bestsellers\n",
    "    all_candidate_best_sellers = pd.concat([candidate_best_sellers, candidate_best_sellers_reference_week])\n",
    "    all_candidate_best_sellers.drop(columns=['bestseller_rank'], inplace=True)\n",
    "    \n",
    "    all_candidate_best_sellers['cat'] = \"candidate\"\n",
    "\n",
    "    return all_candidate_best_sellers\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T00:25:58.539372300Z",
     "start_time": "2023-11-08T00:25:58.518378500Z"
    }
   },
   "id": "ea75684b96d5f1e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
