{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fd8e85-e6e1-4033-9fde-48249fb1755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make external scripts auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd011469-040b-46ae-b0c7-ca57c682a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "\n",
    "from experiment_template import *\n",
    "from candidate_generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba89dec-cb25-4243-b9d7-a857d770e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../../../data/'\n",
    "DATA_PATH = BASE_PATH + 'sample_0.05/'\n",
    "# DATA_PATH = BASE_PATH + 'parquet/'\n",
    "\n",
    "# make sure the same data preprocessing as in the radek notebook have been performed\n",
    "# (see 02 FE/DataProcessingRadek.ipynb)\n",
    "transactions = pd.read_parquet(DATA_PATH + 'transactions_train.parquet')\n",
    "customers = pd.read_parquet(DATA_PATH + 'customers.parquet')\n",
    "articles = pd.read_parquet(DATA_PATH + 'articles.parquet')\n",
    "sample_submission = pd.read_csv(BASE_PATH + 'original/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062a8d0-344b-44ad-9db3-42e560abeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data(data, test_week):\n",
    "#     # candidates = []\n",
    "\n",
    "#     # ### combine\n",
    "#     # result = data.copy()[['week', 'customer_id', 'article_id']]\n",
    "#     # result['purchased'] = True\n",
    "#     # result = pd.concat([\n",
    "#     #     result, candidates\n",
    "#     # ])\n",
    "#     # result.purchased.fillna(False, inplace=True)\n",
    "#     # result.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "#     # result.sort_values(['week', 'customer_id'], inplace=True)\n",
    "#     # result.reset_index(drop=True, inplace=True)\n",
    "#     # return result\n",
    "\n",
    "#     ### repurchase\n",
    "#     # each week is seen as a basket\n",
    "#     # the items bought in one basket, will be example for the next basket\n",
    "#     # the items bought in the last basket, will be candidates for the test basket\n",
    "#     c2weeks = data.groupby('customer_id')['week'].unique()\n",
    "#     c2weeks2shifted_weeks = {}\n",
    "#     for c_id, weeks in c2weeks.items():\n",
    "#         c2weeks2shifted_weeks[c_id] = {}\n",
    "#         for i in range(weeks.shape[0]-1):\n",
    "#             c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "#         c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week\n",
    "#     candidates_last_purchase = data.copy()\n",
    "#     weeks = []\n",
    "#     for i, (c_id, week) in enumerate(zip(data['customer_id'], data['week'])):\n",
    "#         weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "#     candidates_last_purchase.week=weeks\n",
    "\n",
    "#     ### bestseller\n",
    "#     # if a user bought an item in a given week, the 12 most popular items in the previous week are example for that week\n",
    "#     # the best selling items in the last week are candidates for all users\n",
    "#     mean_price = data \\\n",
    "#         .groupby(['week', 'article_id'])['price'].mean()\n",
    "#     sales = data \\\n",
    "#         .groupby('week')['article_id'].value_counts() \\\n",
    "#         .groupby('week').rank(method='dense', ascending=False) \\\n",
    "#         .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "#     bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "#     bestsellers_previous_week.week += 1\n",
    "#     unique_transactions = data \\\n",
    "#         .groupby(['week', 'customer_id']) \\\n",
    "#         .head(1) \\\n",
    "#         .drop(columns=['article_id', 'price']) \\\n",
    "#         .copy()\n",
    "#     candidates_bestsellers = pd.merge(\n",
    "#         unique_transactions,\n",
    "#         bestsellers_previous_week,\n",
    "#         on='week',\n",
    "#     )\n",
    "#     test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "#     test_set_transactions.week = test_week\n",
    "#     candidates_bestsellers_test_week = pd.merge(\n",
    "#         test_set_transactions,\n",
    "#         bestsellers_previous_week,\n",
    "#         on='week'\n",
    "#     )\n",
    "#     candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "#     candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)\n",
    "\n",
    "#     ### combine\n",
    "#     d = data.copy()\n",
    "#     d['purchased'] = True\n",
    "    \n",
    "#     result = pd.concat([\n",
    "#         d, candidates_last_purchase, candidates_bestsellers\n",
    "#     ])\n",
    "#     result.purchased.fillna(False, inplace=True)\n",
    "#     result.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "#     result.sort_values(['week', 'customer_id'], inplace=True)\n",
    "#     result.reset_index(drop=True, inplace=True)\n",
    "#     return result\n",
    "    \n",
    "\n",
    "\n",
    "# def get_examples(data, test_week):\n",
    "#     data = get_data(data, test_week)\n",
    "#     return data[data.week != test_week]\n",
    "\n",
    "# def get_candidates(data, test_week, c):\n",
    "#     data = get_data(data, test_week)\n",
    "#     return data[data.week == test_week]\n",
    "\n",
    "# def get_examples(data, test_week):\n",
    "#     c =  pd.Series(data.customer_id.unique(), name='customer_id')\n",
    "#     examples_positive = repurchase(data, c)\n",
    "#     examples_positive['purchased'] = True\n",
    "    \n",
    "#     examples_negative = merge_candidates([\n",
    "#         popular_similar_items(data, c, articles, 'prod_name', 20, 6, 2),\n",
    "#         popular_by_feature(data, c, customers, 'postal_code', 15),\n",
    "#         popular_by_feature(data, c, customers, 'age', 15),\n",
    "#     ])\n",
    "#     examples_negative['purchased'] = False\n",
    "\n",
    "#     examples = pd.concat([examples_positive, examples_negative])\n",
    "#     examples.drop_duplicates([\"customer_id\", \"article_id\"], inplace=True)\n",
    "#     examples.sort_values(['customer_id'], inplace=True)\n",
    "#     examples.reset_index(drop=True, inplace=True)\n",
    "#     return examples\n",
    "\n",
    "\n",
    "# def get_examples(data, test_week):\n",
    "#     c = pd.Series(data.customer_id.unique(), name='customer_id')\n",
    "#     shifted_data = get_shifted_weeks(data)\n",
    "    \n",
    "#     candidates1 = popular_similar_items_by_week(shifted_data, articles, 'prod_name', k1=20, k2=6, t=1)\n",
    "#     # candidates2 = merge_candidates([\n",
    "#     #     popular_by_feature(data, c, customers, 'postal_code', 5),\n",
    "#     #     popular_by_feature(data, c, customers, 'age', 5)\n",
    "#     # ])\n",
    "#     # candidates2 = pd.merge(\n",
    "#     #     train_data.drop_duplicates(['customer_id', 'week'])[['customer_id', 'week']],\n",
    "#     #     candidates2,\n",
    "#     #     on='customer_id'\n",
    "#     # )\n",
    "\n",
    "#     ### combine\n",
    "#     result = data.copy()[['week', 'customer_id', 'article_id']]\n",
    "#     result['purchased'] = True\n",
    "#     result = pd.concat([\n",
    "#         result, shifted_data, candidates1\n",
    "#     ])\n",
    "#     result.purchased.fillna(False, inplace=True)\n",
    "\n",
    "#     result.pop_rank.fillna(999, inplace=True)\n",
    "#     ranks = result.groupby(['customer_id', 'article_id', 'week']).pop_rank.min()\n",
    "#     result = pd.merge(result.drop(columns='pop_rank'), ranks, how='left', on=['customer_id', 'article_id', 'week'])\n",
    "    \n",
    "#     result.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "#     result.sort_values(['week', 'customer_id'], inplace=True)\n",
    "#     result.reset_index(drop=True, inplace=True)\n",
    "#     return result\n",
    "\n",
    "# def get_candidates(data, test_week, c):\n",
    "#     customer_last_week = (\n",
    "#         data[['customer_id', 'week']]\n",
    "#         .sort_values(['week'], ascending=False)\n",
    "#         .drop_duplicates(['customer_id'])\n",
    "#     )\n",
    "\n",
    "#     d = pd.merge(customer_last_week, data, how='left', on=['customer_id', 'week'])\n",
    "    \n",
    "#     candidates = pd.concat([\n",
    "#         repurchase(d, c),\n",
    "#         popular_similar_items(d, c, articles, 'prod_name', 20, 6, 1),\n",
    "#         # popular_by_feature(d, c, customers, 'postal_code', 15),\n",
    "#         # popular_by_feature(d, c, customers, 'age', 15),\n",
    "#     ])\n",
    "    \n",
    "#     # handle missing pop rank\n",
    "#     candidates.pop_rank.fillna(999, inplace=True)\n",
    "#     ranks = candidates.groupby(['customer_id', 'article_id']).pop_rank.min()\n",
    "#     candidates = pd.merge(candidates.drop(columns='pop_rank'), ranks, how='left', on=['customer_id', 'article_id'])\n",
    "    \n",
    "#     candidates.drop_duplicates([\"customer_id\", \"article_id\"], inplace=True)\n",
    "#     return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e22bfaf-d1dd-4ea8-9afc-6f4332be82f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.201209\n",
      "[LightGBM] [Info] Total Bins 1233\n",
      "[LightGBM] [Info] Number of data points in the train set: 1170880, number of used features: 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "                 article_price 0.2904586982\n",
      "              garment_group_no 0.2375597886\n",
      "               product_type_no 0.2357712120\n",
      "                    section_no 0.0941273233\n",
      "             colour_group_code 0.0579860491\n",
      "                 department_no 0.0372726428\n",
      "               preferred_price 0.0200650552\n",
      "       graphical_appearance_no 0.0187174667\n",
      "                    index_code 0.0080417639\n",
      "                   postal_code 0.0000000000\n",
      "                           age 0.0000000000\n",
      "        fashion_news_frequency 0.0000000000\n",
      "            club_member_status 0.0000000000\n",
      "                        Active 0.0000000000\n",
      "                            FN 0.0000000000\n",
      "                index_group_no 0.0000000000\n",
      "    perceived_colour_master_id 0.0000000000\n",
      "     perceived_colour_value_id 0.0000000000\n",
      "                 buys_for_kids 0.0000000000\n",
      "0.009978301813095457\n"
     ]
    }
   ],
   "source": [
    "### split into training and testing\n",
    "# one week is used for testing\n",
    "# a number of weeks leading up to the test week are used to train the ranker\n",
    "test_week = 104\n",
    "num_training_weeks = 10\n",
    "testing_weeks = np.arange(test_week-num_training_weeks, test_week)\n",
    "train_data = transactions[transactions.week.isin(testing_weeks)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "### generate training examples and testing candidates\n",
    "# optimisation: only generate testing candidates for customers with ground truth data\n",
    "test_customers = None\n",
    "if test_week < transactions.week.max() + 1:\n",
    "    p = get_purchases(transactions[transactions.week == test_week])\n",
    "    test_customers = p.customer_id.values\n",
    "\n",
    "# get the examples and candidates\n",
    "# examples are (customer, week, article, purchased)\n",
    "# candidates are (customer, article)\n",
    "train_examples, test_candidates = get_examples_candidates(train_data, test_week, test_customers, customers, articles)\n",
    "\n",
    "# add features and prepare data for ranker\n",
    "X_train = add_features(train_examples, transactions, customers, articles)\n",
    "X_test = add_features(test_candidates, transactions, customers, articles)\n",
    "Y_train = train_examples['purchased']\n",
    "\n",
    "\n",
    "### fit ranker\n",
    "# training_groups tells LGBM that each (week, customer_id) combination is a seperate basket\n",
    "# !!! it is important that the training_examples are sorted according to week, customer_id for this to work\n",
    "ranker = LGBMRanker(\n",
    "    force_row_wise=True,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")\n",
    "# train_groups = train_examples.groupby(['customer_id'])['article_id'].count().values\n",
    "train_groups = train_examples.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "ranker.fit(X_train, Y_train, group=train_groups)\n",
    "print_importance(ranker, X_train.columns)\n",
    "\n",
    "\n",
    "### evaluate / submit\n",
    "# generate recommendations\n",
    "predictions = get_predictions(test_candidates, X_test, ranker, 12)\n",
    "\n",
    "# fill missing predictions for all customers with popular items in last week\n",
    "popular = transactions[transactions.week == test_week-1].article_id.value_counts().head(12).index.values\n",
    "predictions = fill_missing_predictions(predictions, customers.customer_id, popular)\n",
    "\n",
    "if test_week < transactions.week.max() + 1:\n",
    "    # calculate score\n",
    "    purchases = get_purchases(transactions[transactions.week == test_week])\n",
    "    score = mean_average_precision(predictions, purchases, 12)\n",
    "    print(score)\n",
    "else:\n",
    "    # write submission\n",
    "    sub = create_submission(predictions, sample_submission)\n",
    "    sub.to_csv(BASE_PATH + 'sub1.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a93c7b5f-1f44-48a2-8cb8-4015d22d3950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.35801789401239\n",
      "9.090310485161645\n"
     ]
    }
   ],
   "source": [
    "print(len(train_examples) / len(train_examples.customer_id.unique()))\n",
    "print(len(test_candidates) / len(test_candidates.customer_id.unique()))\n",
    "# Radek: 27/user, 15/user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10520c40-ae8a-49b4-939c-156cb65e0217",
   "metadata": {},
   "source": [
    "+ no besteseller: 0.011969058236222092\n",
    "+ no last week removal: 0.012013546937047771\n",
    "+ new candidates: 0.008312653896431705\n",
    "    + candidate generation should match example generation or ranker gets confused\n",
    "+ no article id: 0.012958022020249708\n",
    "+ new candidates: 0.009308090077886499\n",
    "    + slightly better if you don't include article_id as feature\n",
    "+ new examples, not by week: 0.010802228837859033\n",
    "+ with article id: 0.01146378936774091\n",
    "+ repurchase + popular per index_name (per week): 0.012809616546360366\n",
    "+ with user related candidates: 0.00950611747619205\n",
    "+ 10 estimators, without user related candidates again: 0.01281175309739873\n",
    "+ no article id: 0.011082918911172218\n",
    "+ example generation prod_code instead of index: 0.012408471903703802\n",
    "+ more restricted candidate generation: 0.014533045459703063\n",
    "    +  candidate generation should match example generation as much as possible\n",
    "    +  more candidates than are used as example does not work\n",
    "+ exactly same candidate as example generation: 0.023595130728855555\n",
    "+ added pop_rank: 0.02427475386559533\n",
    "+ 10 estimators: 0.024288773237094562"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
