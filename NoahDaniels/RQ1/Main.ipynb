{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fd8e85-e6e1-4033-9fde-48249fb1755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make external scripts auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd011469-040b-46ae-b0c7-ca57c682a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "\n",
    "from experiment_template import *\n",
    "from candidate_generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ba89dec-cb25-4243-b9d7-a857d770e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../../../data/'\n",
    "# DATA_PATH = BASE_PATH + 'sample_0.05/'\n",
    "DATA_PATH = BASE_PATH + 'parquet/'\n",
    "\n",
    "# make sure the same data preprocessing as in the radek notebook have been performed\n",
    "# (see 02 FE/DataProcessingRadek.ipynb)\n",
    "transactions = pd.read_parquet(DATA_PATH + 'transactions_train.parquet')\n",
    "customers = pd.read_parquet(DATA_PATH + 'customers.parquet')\n",
    "articles = pd.read_parquet(DATA_PATH + 'articles.parquet')\n",
    "sample_submission = pd.read_csv(BASE_PATH + 'original/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d627eb5b-9716-4d74-8d9c-c28571169659",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split into training and testing\n",
    "# one week is used for testing\n",
    "# a number of weeks leading up to the test week are used to train the ranker\n",
    "test_week = 105\n",
    "num_training_weeks = 10\n",
    "transactions = add_relative_week(transactions, test_week)\n",
    "training_weeks = np.arange(test_week-num_training_weeks, test_week)\n",
    "train_data = transactions[transactions.week.isin(training_weeks)].reset_index(drop=True)\n",
    "\n",
    "active_users = train_data.customer_id.unique()\n",
    "cold_users = list(set(customers.customer_id) - set(active_users))\n",
    "\n",
    "### generate training examples and testing candidates\n",
    "# optimisation: only generate testing candidates for customers with ground truth data\n",
    "# not possible for submission week\n",
    "test_customers = None\n",
    "if test_week < transactions.week.max() + 1:\n",
    "    p = get_purchases(transactions[transactions.week == test_week])\n",
    "    test_customers = p.customer_id.values\n",
    "\n",
    "# get the examples and candidates\n",
    "# examples are (customer, week, article, purchased)\n",
    "# candidates are (customer, article)\n",
    "train_examples, test_candidates = get_examples_candidates(train_data, test_week, test_customers, customers, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e22bfaf-d1dd-4ea8-9afc-6f4332be82f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1153\n",
      "[LightGBM] [Info] Number of data points in the train set: 13598824, number of used features: 28\n",
      "        c_af_colour_group_name 0.1676949708\n",
      "                 c_popularity1 0.1610734732\n",
      "          c_af_department_name 0.1594326588\n",
      "                      c_cf_age 0.1522262954\n",
      "                c_af_prod_code 0.1277999610\n",
      "              c_cf_postal_code 0.1041752131\n",
      "                       c_cf_FN 0.0543506745\n",
      "                  c_repurchase 0.0437788219\n",
      "                 c_popularity2 0.0232170143\n",
      "                   postal_code 0.0011987464\n",
      "              garment_group_no 0.0009644397\n",
      "             colour_group_code 0.0007661071\n",
      "               preferred_price 0.0006843258\n",
      "                    section_no 0.0004807633\n",
      "                 article_price 0.0003824342\n",
      "       graphical_appearance_no 0.0003703204\n",
      "                 department_no 0.0003680577\n",
      "               product_type_no 0.0002923639\n",
      "                           age 0.0002413341\n",
      "     perceived_colour_value_id 0.0002291927\n",
      "    perceived_colour_master_id 0.0001617059\n",
      "                    index_code 0.0001069756\n",
      "                index_group_no 0.0000041503\n",
      "                            FN 0.0000000000\n",
      "                        Active 0.0000000000\n",
      "            club_member_status 0.0000000000\n",
      "        fashion_news_frequency 0.0000000000\n",
      "                 buys_for_kids 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "# add features and prepare data for ranker\n",
    "X_train = add_features(train_examples, transactions, customers, articles)\n",
    "X_test = add_features(test_candidates, transactions, customers, articles)\n",
    "Y_train = train_examples['purchased']\n",
    "\n",
    "### fit ranker\n",
    "# training_groups tells LGBM that each (week, customer_id) combination is a seperate basket\n",
    "# !!! it is important that the training_examples are sorted according to week, customer_id for this to work\n",
    "ranker = LGBMRanker(\n",
    "    force_row_wise=True,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=100,\n",
    "    importance_type='gain'\n",
    ")\n",
    "# train_groups = train_examples.groupby(['customer_id'])['article_id'].count().values\n",
    "train_groups = train_examples.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "ranker.fit(X_train, Y_train, group=train_groups)\n",
    "print_importance(ranker, X_train.columns)\n",
    "\n",
    "### evaluate / submit\n",
    "# generate recommendations\n",
    "predictions = get_predictions(test_candidates, X_test, ranker, 12)\n",
    "\n",
    "# cold users\n",
    "bask = baskets(None, 105, cold_users, True)\n",
    "c = pd.concat([\n",
    "    candidates_article_feature(bask, transactions, articles, 'prod_name', 6, 1, 2, 6, True),\n",
    "    candidates_popularity(bask, transactions, 12, 1)\n",
    "]).drop(columns='week').drop_duplicates(['customer_id', 'article_id']).groupby('customer_id').head(12).groupby('customer_id', as_index=False).article_id.apply(list).rename(columns={'article_id':'prediction'})\n",
    "predictions = pd.concat([predictions[predictions.customer_id.isin(active_users)], c])\n",
    "\n",
    "if test_week < transactions.week.max() + 1:\n",
    "    # calculate score\n",
    "    purchases = get_purchases(transactions[transactions.week == test_week])\n",
    "    score = mean_average_precision(predictions, purchases, 12)\n",
    "    print(score)\n",
    "else:\n",
    "    # write submission\n",
    "    sub = create_submission(predictions, sample_submission)\n",
    "    sub.to_csv(BASE_PATH + 'sub05-12f.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff09aa5f-2073-4dc4-b453-1461989d19a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_af_colour_group_name 6116 35020 0.1486775573706729\n",
      "c_af_department_name 5804 35332 0.1410929599377674\n",
      "c_af_prod_code 10909 30227 0.2651935044729677\n",
      "c_cf_FN 14370 26766 0.34932905484247373\n",
      "c_cf_age 2859 38277 0.06950116686114352\n",
      "c_cf_postal_code 4039 37097 0.09818650330610658\n",
      "c_popularity1 19348 21788 0.47034227926876704\n",
      "c_popularity2 9147 31989 0.22235997666277713\n",
      "c_repurchase 8388 32748 0.20390898483080513\n"
     ]
    }
   ],
   "source": [
    "scored_candidates = test_candidates.copy()\n",
    "scored_candidates[\"score\"] = ranker.predict(X_test)\n",
    "a = scored_candidates.sort_values([\"customer_id\", \"score\"], ascending=False).groupby(\"customer_id\").head(12)\n",
    "\n",
    "for c in a.columns:\n",
    "    if c[0:2] == 'c_':\n",
    "        vc = a[c].value_counts()\n",
    "        vct = vc[True]\n",
    "        vcf = vc[False]\n",
    "        print(c, vct, vcf, vct/(vct+vcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0c09dda-6d61-408f-8b32-b444c5e1cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(predictions, test_data):\n",
    "    joined = pd.merge(test_data, predictions, how='inner').drop_duplicates()\n",
    "    relevant_selected = joined.groupby('customer_id').count()\n",
    "    relevant_total = test_data.groupby('customer_id').count()\n",
    "\n",
    "    recall = relevant_selected.divide(relevant_total, fill_value=0)\n",
    "    return recall.mean().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69bb1f6b-c70b-4a37-90ca-afed305f0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = a[['customer_id', 'article_id']].reset_index(drop=True)\n",
    "actual = transactions[transactions.week == test_week][['customer_id', 'article_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b8b4f4c-f54a-4d81-9cb4-86841636ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05676208646027177"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(pred, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7e438-1ca8-46f1-b3a9-0a553230b698",
   "metadata": {},
   "source": [
    "+ 0.021324595079570654 no rank\n",
    "+ 0.021802492909964423 combined rank\n",
    "+ 0.02138256058599553 seperate rank per candidate generation scheme\n",
    "\n",
    "Not using rank\n",
    "\n",
    "+ 0.02234637343056455 customer_id and article_id\n",
    "\n",
    "Candidate can have multiple sources\n",
    "\n",
    "+ 0.025760478853858997 with multiple bools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a814ba2-5271-40d9-9b27-bc0109c432c4",
   "metadata": {},
   "source": [
    "0.05 sample, 10 weeks training data\n",
    "\n",
    "+ 0.026162023628432167\n",
    "+ 0.025892707105825957 article_id, customer_id\n",
    "+ 0.025796035625746828 article_id, customer_id, rank\n",
    "\n",
    "0.05 sample, 20 weeks training data\n",
    "\n",
    "+ 0.027860987873826185\n",
    "\n",
    "0.05 sample, 50 weeks training data\n",
    "\n",
    "+ 0.02644852466659573"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
