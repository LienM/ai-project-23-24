{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-29T13:21:45.984635344Z",
     "start_time": "2023-12-29T13:21:45.453087175Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set the correct backend for DGL\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17cb5de8f410e5a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:21:46.039684251Z",
     "start_time": "2023-12-29T13:21:45.984533972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the 5% sample of the transactions data\n",
    "BASE_PATH = '../data/'\n",
    "\n",
    "transactions = pd.read_parquet(BASE_PATH + 'parquet/transactions_train_sample_0.05.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "DGSR except the data in a certain format the following code will change the data to the correct format so we can run the DGSR code without having to change the DGSR code itself."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d6b057397fe15f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# This are the columns that DGSR expects\n",
    "transactions = transactions.rename(columns={\"article_id\": \"item_id\", \"customer_id\": \"user_id\"})\n",
    "# Need unix timestamp for DGSR\n",
    "transactions['time'] = (transactions['t_dat'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "# Drop the columns that are not needed for DGSR\n",
    "transactions.drop(columns=['t_dat', 'sales_channel_id', 'price', 'week'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:21:46.067104538Z",
     "start_time": "2023-12-29T13:21:46.040118564Z"
    }
   },
   "id": "5f60c05bf16a0ef7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Change the datatype of the columns to the ones expected by DGSR\n",
    "# Label encode the user_id \n",
    "# Easy way to get the user_id to start at 0 and have no gaps between the different user_id\n",
    "le = LabelEncoder()\n",
    "le.fit(transactions['user_id'])\n",
    "transactions['user_id'] = le.transform(transactions['user_id'])\n",
    "\n",
    "# Label encode the item_id \n",
    "# Easy way to get the item_id to start at 0 and have no gaps between the different item_id\n",
    "le = LabelEncoder()\n",
    "le.fit(transactions['item_id'])\n",
    "transactions['item_id'] = le.transform(transactions['item_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:21:46.457888511Z",
     "start_time": "2023-12-29T13:21:46.068467919Z"
    }
   },
   "id": "6b54c3f45e7b359a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "transactions.to_csv(BASE_PATH + 'dgsr/transactions_train.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:21:47.114454479Z",
     "start_time": "2023-12-29T13:21:46.458608885Z"
    }
   },
   "id": "119cf7c78d4cf3e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Important note\n",
    " Make sure the DGSR submodule is pulled from git and the correct requirements are installed\n",
    " \n",
    "# Installation\n",
    "\n",
    "The requirements inside the [requirements](./requirements.txt) file work for me. Depending on the GPU you have and what CUDA versions it\n",
    "supports you might have to install different versions of dgl and pytorch. If you have an AMD GPU you will have to find out what works for you.\n",
    "\n",
    "Version selector for [dgl](https://www.dgl.ai/pages/start.html) and for [pytorch](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "At some point I needed an older version of pytorch to get the correct CUDA versions so it didn't clash with the CUDA versions for DGL, those you can find [here](https://pytorch.org/get-started/previous-versions/)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d26198b75cb57c5c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Move the data into the DGSR submodule\n",
    "!cp -a ../data/dgsr/. ../DGSR/Data/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T13:21:47.849076968Z",
     "start_time": "2023-12-29T13:21:47.732185312Z"
    }
   },
   "id": "327200d912765bfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following might take a while to generate all the graphs and it will take quit a lot of storage space (50+ GB). Expanding the small amount of data results in massive amounts of graph data and is the reason why it is not feasible for me to run this on my own hardware. \n",
    "\n",
    "Their datasets were similar size to our 5% sample which I use, but later on I found out that they have way more compute power than I do. So hence the reason why it is not feasible for me to run this on my own hardware."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c640f99b39c985e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate the dynamic graphs and save them to disk so they don't have to be generated multiple times at runtime\n",
    "!./load_data.sh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21eb4a1049efe86a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Changes to make in the DGSR code\n",
    "Open [this](./DGSR/generate_neg.py) file and change the dataset to \"transactions_train\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d996970d4172509"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate negative samples, those are used for test and validation dataset of the algorithm\n",
    "!./load_neg_data.sh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2edc60c67202e9a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following will take a while to run, I ran it for like 2 or 3 hours and it wasn't even close to finishing. I estimate to take at least 1.5 to 2 days to run on my hardware. I have other courses for which I also need my the GPU compute power so I can't run it for that long. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85e568f9797e9dfb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!./train.sh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d0279eed91542a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
