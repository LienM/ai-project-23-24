{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:06.213459800Z",
     "start_time": "2023-12-28T13:15:03.270343300Z"
    }
   },
   "outputs": [],
   "source": [
    "from Question1 import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BASE_PATH = '../Data/'\n",
    "transactions = pd.read_parquet(BASE_PATH + 'transactions_train.parquet')\n",
    "customers = pd.read_parquet(BASE_PATH + 'customers.parquet')\n",
    "articles = pd.read_parquet(BASE_PATH + 'articles.parquet')\n",
    "sample_submission = pd.read_csv(BASE_PATH + 'sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:08.316057700Z",
     "start_time": "2023-12-28T13:15:06.214457600Z"
    }
   },
   "id": "cf343fc889ff26a5"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Candidate generation of Radek notebook\n",
    "def get_data(data, test_week):\n",
    "    ### repurchase\n",
    "    # each week is seen as a basket\n",
    "    # the items bought in one basket, will be example for the next basket\n",
    "    # the items bought in the last basket, will be candidates for the test basket\n",
    "    candidates_last_purchase = data.copy()\n",
    "    c2weeks = data.groupby('customer_id')['week'].unique()\n",
    "    \n",
    "    c2weeks2shifted_weeks = {}\n",
    "    for c_id, weeks in c2weeks.items():\n",
    "        shifted_weeks = weeks[1:].tolist() + [test_week]\n",
    "        c2weeks2shifted_weeks[c_id] = dict(zip(weeks, shifted_weeks))\n",
    "\n",
    "    candidates_last_purchase['week'] = [\n",
    "        c2weeks2shifted_weeks[c_id][week]\n",
    "        for c_id, week in zip(data['customer_id'], data['week'])\n",
    "    ]\n",
    "\n",
    "    ### bestseller\n",
    "    # if a user bought an item in a given week, the 12 most popular items in the previous week are example for that week\n",
    "    # the best selling items in the last week are candidates for all users\n",
    "    mean_price = data \\\n",
    "        .groupby(['week', 'article_id'])['price'].mean()\n",
    "    sales = data \\\n",
    "        .groupby('week')['article_id'].value_counts() \\\n",
    "        .groupby('week').rank(method='dense', ascending=False) \\\n",
    "        .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "    bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "    bestsellers_previous_week.week += 1\n",
    "    unique_transactions = data \\\n",
    "        .groupby(['week', 'customer_id']) \\\n",
    "        .head(1) \\\n",
    "        .drop(columns=['article_id', 'price']) \\\n",
    "        .copy()\n",
    "    candidates_bestsellers = pd.merge(\n",
    "        unique_transactions,\n",
    "        bestsellers_previous_week,\n",
    "        on='week',\n",
    "    )\n",
    "    test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "    test_set_transactions.week = test_week\n",
    "    candidates_bestsellers_test_week = pd.merge(\n",
    "        test_set_transactions,\n",
    "        bestsellers_previous_week,\n",
    "        on='week'\n",
    "    )\n",
    "    candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "    candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)\n",
    "\n",
    "    ### combine\n",
    "    d = data.copy()\n",
    "    d['purchased'] = True\n",
    "    \n",
    "    result = pd.concat([\n",
    "        d, candidates_last_purchase, candidates_bestsellers\n",
    "    ])\n",
    "    result.purchased.fillna(False, inplace=True)\n",
    "    result.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "\n",
    "    result = pd.merge(\n",
    "        result,\n",
    "        bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "        on=['week', 'article_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    result = result[result.week != result.week.min()]\n",
    "    result.bestseller_rank.fillna(999, inplace=True)\n",
    "\n",
    "    result.sort_values(['week', 'customer_id'], inplace=True)\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "    return result\n",
    "\n",
    "def get_examples(data, test_week):\n",
    "    data = get_data(data, test_week)\n",
    "    return data[data.week != test_week]\n",
    "\n",
    "def get_candidates(data, test_week):\n",
    "    data = get_data(data, test_week)\n",
    "    return data[data.week == test_week]\n",
    "\n",
    "def add_features(data, columns_to_use = None):\n",
    "    if not columns_to_use:\n",
    "        columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id','perceived_colour_master_id', 'department_no', 'index_code','index_group_no', 'section_no', 'garment_group_no','score','price'\n",
    "        ]\n",
    "\n",
    "    result = data\n",
    "    result = pd.merge(result, customers, how='left', on='customer_id')\n",
    "    result = pd.merge(result, articles, how='left', on='article_id')\n",
    "\n",
    "    result['score'] = result.apply(get_score,axis=1).fillna(0)\n",
    "    \n",
    "    return result[columns_to_use]\n",
    "\n",
    "def get_score(entry):\n",
    "    \"\"\"Method that returns the user-item score given a dataframe row containing columns [customer_id,article_id]\"\"\"\n",
    "    try:\n",
    "        return ui_score.loc[entry['customer_id'], entry['article_id']]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def recall(predictions, purchases, k=12):\n",
    "    def calculate_recall(row):\n",
    "        intersect_count = len(set(row['prediction'][:k]).intersection(row['purchases']))\n",
    "        return intersect_count / min(len(row['purchases']), k) if len(row['purchases']) > 0 else 0\n",
    "\n",
    "    result = pd.merge(purchases, predictions, on=\"customer_id\", how=\"inner\")\n",
    "    result['recall'] = result.apply(calculate_recall, axis=1)\n",
    "\n",
    "    return result['recall'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:42:16.108107200Z",
     "start_time": "2023-12-28T18:42:16.107107100Z"
    }
   },
   "id": "67c3982febc4212a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_sim(recmodel,purchase_sparse):\n",
    "    \"\"\"Method to get the dot product of an item similarity matrix with the articles frequency of every user\"\"\"\n",
    "    s2 = cosine_similarity(recmodel.articles_latent_matrix, recmodel.articles_latent_matrix)\n",
    "    return purchase_sparse.dot(s2)\n",
    "\n",
    "def apply_filter(scores, filter_matrix):\n",
    "    \"\"\"Method to apply the filter that prunes already purchased articles for every user. It's done in chunks to be less RAM heavy\"\"\"\n",
    "    chunk_size = 10000\n",
    "    num_rows, num_cols = scores.shape\n",
    "    result = np.zeros((num_rows, num_cols))\n",
    "    \n",
    "    for i in range(0, num_rows, chunk_size):\n",
    "        chunk_end = min(i + chunk_size, num_rows)\n",
    "        ui_chunk = scores.iloc[i:chunk_end].values\n",
    "        filter_chunk = filter_matrix[i:chunk_end]\n",
    "        result[i:chunk_end] = np.multiply(ui_chunk, filter_chunk)\n",
    "    \n",
    "    return pd.DataFrame(result, index=scores.index, columns=scores.columns)\n",
    "\n",
    "\n",
    "def get_useritem_data(recmodel):\n",
    "    \"\"\"Method that returns the user-item interaction matrix with scores\"\"\"\n",
    "    itemcf_transactions['article_id'] = itemcf_transactions['article_id'].astype(int)\n",
    "    purchase_counts = itemcf_transactions.groupby(['customer_id', 'article_id']).size().rename('count').reset_index().sort_values('article_id') # article frequency matrix \n",
    "    \n",
    "    user_to_index = {user_id: index for index, user_id in enumerate(purchase_counts['customer_id'].unique())}\n",
    "    article_to_index = {article_id: index for index, article_id in enumerate(purchase_counts['article_id'].unique())}\n",
    "    \n",
    "    row_indices = purchase_counts['customer_id'].map(user_to_index).values\n",
    "    col_indices = purchase_counts['article_id'].map(article_to_index).values\n",
    "    spdata = purchase_counts['count'].values\n",
    "    \n",
    "    # sparse matrix to preserve RAM\n",
    "    purchase_counts_sparse = csr_matrix((spdata, (row_indices, col_indices)), shape=(len(user_to_index), len(article_to_index)), dtype=int)\n",
    "    \n",
    "    # dataframe of the user-item matrix\n",
    "    result = pd.DataFrame(get_sim(recmodel,purchase_counts_sparse), index=user_to_index.keys(), columns=article_to_index.keys())\n",
    "    \n",
    "    # create a matrix containing 1's for items not bought by the user and 0 for item's that were already purchased\n",
    "    purchase_counts_sparse = csr_matrix((np.ones_like(spdata), (row_indices, col_indices)), shape=(len(user_to_index), len(article_to_index)), dtype=int).toarray()\n",
    "    filter_matrix = 1 - purchase_counts_sparse\n",
    "    del purchase_counts\n",
    "    \n",
    "    return apply_filter(result,filter_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:08.336080600Z",
     "start_time": "2023-12-28T13:15:08.323688200Z"
    }
   },
   "id": "3513f7ed26cd5023"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "### split into training and testing\n",
    "# one week is used for testing\n",
    "# a number of weeks leading up to the test week are used to train the ranker\n",
    "test_week = 104\n",
    "num_training_weeks = 10\n",
    "testing_weeks = np.arange(test_week-num_training_weeks, test_week)\n",
    "train_data = transactions[transactions.week.isin(testing_weeks)].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:08.431143400Z",
     "start_time": "2023-12-28T13:15:08.332082200Z"
    }
   },
   "id": "736503860d62eb20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CF preprocessing\n",
    "We take only the articles bought more than 10 times in the training weeks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fee8963ffe642c9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "             t_dat           customer_id  article_id  purchased\n0       2020-07-08       857913002275398   599580068          1\n1       2020-07-08       857913002275398   776237011          1\n2       2020-07-08       857913002275398   844294001          1\n3       2020-07-08      1658289241058394   877773001          1\n4       2020-07-08      3828854365940846   507883009          1\n...            ...                   ...         ...        ...\n2809228 2020-09-15  18446630855572834764   568601045          1\n2809229 2020-09-15  18446630855572834764   568601045          1\n2809230 2020-09-15  18446630855572834764   898713001          1\n2809231 2020-09-15  18446630855572834764   898713001          1\n2809232 2020-09-15  18446630855572834764   886966002          1\n\n[2745309 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>purchased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-07-08</td>\n      <td>857913002275398</td>\n      <td>599580068</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-07-08</td>\n      <td>857913002275398</td>\n      <td>776237011</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-07-08</td>\n      <td>857913002275398</td>\n      <td>844294001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-07-08</td>\n      <td>1658289241058394</td>\n      <td>877773001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-07-08</td>\n      <td>3828854365940846</td>\n      <td>507883009</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2809228</th>\n      <td>2020-09-15</td>\n      <td>18446630855572834764</td>\n      <td>568601045</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2809229</th>\n      <td>2020-09-15</td>\n      <td>18446630855572834764</td>\n      <td>568601045</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2809230</th>\n      <td>2020-09-15</td>\n      <td>18446630855572834764</td>\n      <td>898713001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2809231</th>\n      <td>2020-09-15</td>\n      <td>18446630855572834764</td>\n      <td>898713001</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2809232</th>\n      <td>2020-09-15</td>\n      <td>18446630855572834764</td>\n      <td>886966002</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2745309 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemcf_transactions = train_data.copy().drop(['sales_channel_id', 'price', 'week'], axis=1)\n",
    "most_bought_articles = itemcf_transactions['article_id'].value_counts()[lambda x: x > 10].index\n",
    "itemcf_transactions = itemcf_transactions[itemcf_transactions['article_id'].isin(most_bought_articles)]\n",
    "itemcf_transactions['purchased'] = 1\n",
    "itemcf_transactions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:08.545333400Z",
     "start_time": "2023-12-28T13:15:08.432144100Z"
    }
   },
   "id": "263b3eb4529214dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate negative candidates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49a9387d5cc61c44"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train CF model using SGD algorithm\n",
    "I've imported a pre-trained model, the same one as in notebook RQ1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42004c65bb7d80ff"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('output/60_1000.pickle','rb') as file:\n",
    "    rec = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T14:34:53.548150800Z",
     "start_time": "2023-12-28T14:34:52.010887400Z"
    }
   },
   "id": "fed5a7ad5eabaaf7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate the user-item interaction matrix by using the data from the CF model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d22ef793f6b8c49"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 14s\n",
      "Wall time: 8min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ui_score = get_useritem_data(rec)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T14:43:39.209719800Z",
     "start_time": "2023-12-28T14:34:53.549151700Z"
    }
   },
   "id": "58bf63bc3642b37b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "           108775044      111565001      111586001      111593001  \\\ncount  437279.000000  437279.000000  437279.000000  437279.000000   \nmean        0.002714      -0.000307       0.001153      -0.010573   \nstd         0.094877       0.093943       0.093916       0.092221   \nmin        -4.041761      -2.336787      -2.266620      -2.672708   \n25%        -0.041688      -0.044187      -0.042833      -0.051062   \n50%         0.001708      -0.000307       0.001084      -0.006233   \n75%         0.046932       0.043255       0.044577       0.034864   \nmax         2.346311       2.598370       4.525209       2.467519   \n\n           111609001      120129001      120129014      123173001  \\\ncount  437279.000000  437279.000000  437279.000000  437279.000000   \nmean       -0.005390      -0.004359       0.008906      -0.000444   \nstd         0.094470       0.093073       0.094876       0.093714   \nmin        -3.181316      -3.203716      -3.051396      -1.850657   \n25%        -0.047232      -0.046882      -0.037306      -0.044035   \n50%        -0.002644      -0.002759       0.004634       0.000028   \n75%         0.039801       0.040188       0.050241       0.043988   \nmax         1.743278       4.603321       2.622148       2.758256   \n\n           126589010      129085001  ...      947168001      947509001  \\\ncount  437279.000000  437279.000000  ...  437279.000000  437279.000000   \nmean       -0.005152       0.005313  ...       0.001483      -0.002138   \nstd         0.092812       0.091845  ...       0.090319       0.091073   \nmin        -3.577077      -1.818405  ...      -1.916890      -2.474271   \n25%        -0.047596      -0.038898  ...      -0.041013      -0.044818   \n50%        -0.003742       0.003415  ...       0.000748      -0.002022   \n75%         0.039108       0.046876  ...       0.043246       0.041077   \nmax         1.375848       3.876800  ...       2.308177       1.567481   \n\n           947934001      949198001      949551001      949551002  \\\ncount  437279.000000  437279.000000  437279.000000  437279.000000   \nmean        0.007459       0.007834       0.003945      -0.002832   \nstd         0.091034       0.093892       0.092851       0.093297   \nmin        -1.313247      -5.925495      -2.478896      -3.269933   \n25%        -0.036344      -0.037021      -0.040220      -0.045832   \n50%         0.005084       0.005189       0.002342      -0.001402   \n75%         0.048694       0.049660       0.045987       0.041485   \nmax         3.755734       3.107385       2.288731       2.717287   \n\n           952267001      953450001      953763001      956217002  \ncount  437279.000000  437279.000000  437279.000000  437279.000000  \nmean        0.000413      -0.008401      -0.011353      -0.008325  \nstd         0.091268       0.093498       0.094684       0.094458  \nmin        -2.090865      -2.854247      -2.344470      -2.678586  \n25%        -0.042934      -0.049267      -0.053492      -0.050177  \n50%        -0.000039      -0.004557      -0.007284      -0.005382  \n75%         0.043731       0.037388       0.035096       0.037598  \nmax         1.894666       2.868778       1.717103       2.326091  \n\n[8 rows x 19600 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>108775044</th>\n      <th>111565001</th>\n      <th>111586001</th>\n      <th>111593001</th>\n      <th>111609001</th>\n      <th>120129001</th>\n      <th>120129014</th>\n      <th>123173001</th>\n      <th>126589010</th>\n      <th>129085001</th>\n      <th>...</th>\n      <th>947168001</th>\n      <th>947509001</th>\n      <th>947934001</th>\n      <th>949198001</th>\n      <th>949551001</th>\n      <th>949551002</th>\n      <th>952267001</th>\n      <th>953450001</th>\n      <th>953763001</th>\n      <th>956217002</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>...</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n      <td>437279.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.002714</td>\n      <td>-0.000307</td>\n      <td>0.001153</td>\n      <td>-0.010573</td>\n      <td>-0.005390</td>\n      <td>-0.004359</td>\n      <td>0.008906</td>\n      <td>-0.000444</td>\n      <td>-0.005152</td>\n      <td>0.005313</td>\n      <td>...</td>\n      <td>0.001483</td>\n      <td>-0.002138</td>\n      <td>0.007459</td>\n      <td>0.007834</td>\n      <td>0.003945</td>\n      <td>-0.002832</td>\n      <td>0.000413</td>\n      <td>-0.008401</td>\n      <td>-0.011353</td>\n      <td>-0.008325</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.094877</td>\n      <td>0.093943</td>\n      <td>0.093916</td>\n      <td>0.092221</td>\n      <td>0.094470</td>\n      <td>0.093073</td>\n      <td>0.094876</td>\n      <td>0.093714</td>\n      <td>0.092812</td>\n      <td>0.091845</td>\n      <td>...</td>\n      <td>0.090319</td>\n      <td>0.091073</td>\n      <td>0.091034</td>\n      <td>0.093892</td>\n      <td>0.092851</td>\n      <td>0.093297</td>\n      <td>0.091268</td>\n      <td>0.093498</td>\n      <td>0.094684</td>\n      <td>0.094458</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-4.041761</td>\n      <td>-2.336787</td>\n      <td>-2.266620</td>\n      <td>-2.672708</td>\n      <td>-3.181316</td>\n      <td>-3.203716</td>\n      <td>-3.051396</td>\n      <td>-1.850657</td>\n      <td>-3.577077</td>\n      <td>-1.818405</td>\n      <td>...</td>\n      <td>-1.916890</td>\n      <td>-2.474271</td>\n      <td>-1.313247</td>\n      <td>-5.925495</td>\n      <td>-2.478896</td>\n      <td>-3.269933</td>\n      <td>-2.090865</td>\n      <td>-2.854247</td>\n      <td>-2.344470</td>\n      <td>-2.678586</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.041688</td>\n      <td>-0.044187</td>\n      <td>-0.042833</td>\n      <td>-0.051062</td>\n      <td>-0.047232</td>\n      <td>-0.046882</td>\n      <td>-0.037306</td>\n      <td>-0.044035</td>\n      <td>-0.047596</td>\n      <td>-0.038898</td>\n      <td>...</td>\n      <td>-0.041013</td>\n      <td>-0.044818</td>\n      <td>-0.036344</td>\n      <td>-0.037021</td>\n      <td>-0.040220</td>\n      <td>-0.045832</td>\n      <td>-0.042934</td>\n      <td>-0.049267</td>\n      <td>-0.053492</td>\n      <td>-0.050177</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.001708</td>\n      <td>-0.000307</td>\n      <td>0.001084</td>\n      <td>-0.006233</td>\n      <td>-0.002644</td>\n      <td>-0.002759</td>\n      <td>0.004634</td>\n      <td>0.000028</td>\n      <td>-0.003742</td>\n      <td>0.003415</td>\n      <td>...</td>\n      <td>0.000748</td>\n      <td>-0.002022</td>\n      <td>0.005084</td>\n      <td>0.005189</td>\n      <td>0.002342</td>\n      <td>-0.001402</td>\n      <td>-0.000039</td>\n      <td>-0.004557</td>\n      <td>-0.007284</td>\n      <td>-0.005382</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.046932</td>\n      <td>0.043255</td>\n      <td>0.044577</td>\n      <td>0.034864</td>\n      <td>0.039801</td>\n      <td>0.040188</td>\n      <td>0.050241</td>\n      <td>0.043988</td>\n      <td>0.039108</td>\n      <td>0.046876</td>\n      <td>...</td>\n      <td>0.043246</td>\n      <td>0.041077</td>\n      <td>0.048694</td>\n      <td>0.049660</td>\n      <td>0.045987</td>\n      <td>0.041485</td>\n      <td>0.043731</td>\n      <td>0.037388</td>\n      <td>0.035096</td>\n      <td>0.037598</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.346311</td>\n      <td>2.598370</td>\n      <td>4.525209</td>\n      <td>2.467519</td>\n      <td>1.743278</td>\n      <td>4.603321</td>\n      <td>2.622148</td>\n      <td>2.758256</td>\n      <td>1.375848</td>\n      <td>3.876800</td>\n      <td>...</td>\n      <td>2.308177</td>\n      <td>1.567481</td>\n      <td>3.755734</td>\n      <td>3.107385</td>\n      <td>2.288731</td>\n      <td>2.717287</td>\n      <td>1.894666</td>\n      <td>2.868778</td>\n      <td>1.717103</td>\n      <td>2.326091</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 19600 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_score.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:29:11.422588Z",
     "start_time": "2023-12-28T14:43:39.236720200Z"
    }
   },
   "id": "3bba41938aa93855"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interesting to see that more than 75% of the articles have a mediocre user-item score, when only a few have a score higher than 1.\n",
    "\n",
    "These scores are also the same for the scores in RQ1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b67a1559d548153"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "720331bcbe91ad29"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "### assemble training data (positive + negative examples)\n",
    "# each example has at least a customer_id, article_id and whether it was purchased or not (positive/negative)\n",
    "# add_features extracts and adds features to the examples\n",
    "train_examples = get_examples(train_data, test_week)\n",
    "\n",
    "columnsCF = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id','perceived_colour_master_id', 'department_no', 'index_code','index_group_no', 'section_no', 'garment_group_no','score','price']\n",
    "X_trainCF = add_features(train_examples,columnsCF)\n",
    "Y_trainCF = train_examples['purchased']\n",
    "\n",
    "columnsPop = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id','perceived_colour_master_id', 'department_no', 'index_code','index_group_no', 'section_no', 'garment_group_no','bestseller_rank','price'\n",
    "        ]\n",
    "X_trainPop = add_features(train_examples,columnsPop)\n",
    "Y_trainPop = train_examples['purchased']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:53:32.896448Z",
     "start_time": "2023-12-28T18:46:17.294683800Z"
    }
   },
   "id": "d7cef38fcd72844c"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.112795\n",
      "[LightGBM] [Info] Total Bins 1297\n",
      "[LightGBM] [Info] Number of data points in the train set: 11557594, number of used features: 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "                         score 0.99563\n",
      "                         price 0.00319\n",
      "                    article_id 0.00049\n",
      "              garment_group_no 0.00028\n",
      "                 department_no 0.00016\n",
      "               product_type_no 0.00015\n",
      "                    section_no 0.00006\n",
      "             colour_group_code 0.00004\n",
      "                index_group_no 0.00000\n",
      "                    index_code 0.00000\n",
      "    perceived_colour_master_id 0.00000\n",
      "     perceived_colour_value_id 0.00000\n",
      "       graphical_appearance_no 0.00000\n"
     ]
    }
   ],
   "source": [
    "### fit collaborative filtering ranker\n",
    "# training_groups tells LGBM that each (week, customer_id) combination is a seperate basket\n",
    "# !!! it is important that the training_examples are sorted according to week, customer_id for this to work\n",
    "rankerCF = LGBMRanker(\n",
    "    force_row_wise=True,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")\n",
    "train_groups = train_examples.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "rankerCF.fit(X_trainCF, Y_trainCF, group=train_groups)\n",
    "print_importance(rankerCF, X_trainCF.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:53:53.034340500Z",
     "start_time": "2023-12-28T18:53:50.988097400Z"
    }
   },
   "id": "927045cf65fa575e"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.090095\n",
      "[LightGBM] [Info] Total Bins 1056\n",
      "[LightGBM] [Info] Number of data points in the train set: 11557594, number of used features: 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "               bestseller_rank 0.97353\n",
      "                         price 0.02543\n",
      "     perceived_colour_value_id 0.00031\n",
      "                    article_id 0.00027\n",
      "       graphical_appearance_no 0.00022\n",
      "              garment_group_no 0.00008\n",
      "                    section_no 0.00008\n",
      "                 department_no 0.00005\n",
      "               product_type_no 0.00004\n",
      "                index_group_no 0.00000\n",
      "                    index_code 0.00000\n",
      "    perceived_colour_master_id 0.00000\n",
      "             colour_group_code 0.00000\n"
     ]
    }
   ],
   "source": [
    "### fit popularity ranker \n",
    "# training_groups tells LGBM that each (week, customer_id) combination is a seperate basket\n",
    "# !!! it is important that the training_examples are sorted according to week, customer_id for this to work\n",
    "rankerPop = LGBMRanker(\n",
    "    force_row_wise=True,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")\n",
    "train_groups = train_examples.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "rankerPop.fit(X_trainPop, Y_trainPop, group=train_groups)\n",
    "print_importance(rankerPop, X_trainPop.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:53:55.074933500Z",
     "start_time": "2023-12-28T18:53:53.032339800Z"
    }
   },
   "id": "50f5fadfbdabcb6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "### test\n",
    "# candidates are generated similarly to the examples, only we don't know whether they are purchased\n",
    "# the same features are extracted and added\n",
    "# each candidate is scored by the ranker and predictions are generated using the highest scoring candidates\n",
    "test_candidates = get_candidates(train_data, test_week)\n",
    "X_test = add_features(test_candidates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adb56daea9ce7515"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def get_predictions_dataframe(scored_candidates,k=12):\n",
    "    \"\"\"Method to get a dataframe with predictions from the ranker.predict() function\"\"\"\n",
    "    return (\n",
    "        scored_candidates.sort_values([\"customer_id\", \"score\"], ascending=False)\n",
    "        .groupby(\"customer_id\")\n",
    "        .head(k)\n",
    "        .groupby(\"customer_id\", as_index=False)\n",
    "        .article_id.apply(list)\n",
    "        .rename(columns={\"article_id\": \"prediction\"})[[\"customer_id\", \"prediction\"]]\n",
    "    )\n",
    "\n",
    "predsCF = rankerCF.predict(X_test)\n",
    "predsPop = rankerPop.predict(X_test)\n",
    "\n",
    "predictions5050 = test_candidates.copy()\n",
    "predictions5050[\"score\"] = predsCF * 0.5 + predsPop * 0.5\n",
    "\n",
    "predictions8020 = test_candidates.copy()\n",
    "predictions8020[\"score\"] = predsCF * 0.8 + predsPop * 0.2\n",
    "\n",
    "predictions2080 = test_candidates.copy()\n",
    "predictions2080[\"score\"] = predsCF * 0.2 + predsPop * 0.8\n",
    "\n",
    "predictions5050 = get_predictions_dataframe(predictions5050)\n",
    "predictions8020 = get_predictions_dataframe(predictions8020)\n",
    "predictions2080 = get_predictions_dataframe(predictions2080)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:13:45.338436700Z",
     "start_time": "2023-12-28T19:13:29.518621800Z"
    }
   },
   "id": "4340b5ef018db2b5"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "### evaluate\n",
    "# get ground truth data for test week\n",
    "purchases = get_purchases(transactions[transactions.week == test_week])\n",
    "\n",
    "# fill missing prediction for customers in test set with popular items in last week\n",
    "# only for customers in test set because only those are evaluated\n",
    "popular = transactions[transactions.week == test_week-1].article_id.value_counts().head(12).index.values\n",
    "\n",
    "predictions5050 = fill_missing_predictions(predictions5050, purchases.customer_id, popular)\n",
    "predictions8020 = fill_missing_predictions(predictions8020, purchases.customer_id, popular)\n",
    "predictions2080 = fill_missing_predictions(predictions2080, purchases.customer_id, popular)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:13:46.087843100Z",
     "start_time": "2023-12-28T19:13:45.338436700Z"
    }
   },
   "id": "9890432b9ee6cb5d"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@12:\n",
      "\t-50/50: 0.025306594568960544\n",
      "\t-80/20: 0.0256529535993688\n",
      "\t-20/80: 0.024910298083689143\n"
     ]
    }
   ],
   "source": [
    "# calculate score\n",
    "score5050 = mean_average_precision(predictions5050, purchases, 12)\n",
    "score8020 = mean_average_precision(predictions8020, purchases, 12)\n",
    "score2080 = mean_average_precision(predictions2080, purchases, 12)\n",
    "print(f\"MAP@12:\\n\\t-50/50: {score5050}\\n\\t-80/20: {score8020}\\n\\t-20/80: {score2080}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:13:52.574528600Z",
     "start_time": "2023-12-28T19:13:46.088979600Z"
    }
   },
   "id": "63dad912b0f386b7"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@12:\n",
      "\t-50/50: 0.051982025779573025\n",
      "\t-80/20: 0.05200284381145161\n",
      "\t-20/80: 0.05195246510515268\n"
     ]
    }
   ],
   "source": [
    " # calculate recall\n",
    "recall5050 = recall(predictions5050, purchases, 12)\n",
    "recall8020 = recall(predictions8020, purchases, 12)\n",
    "recall2080 = recall(predictions2080, purchases, 12)\n",
    "print(f\"recall@12:\\n\\t-50/50: {recall5050}\\n\\t-80/20: {recall8020}\\n\\t-20/80: {recall2080}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:13:53.884076Z",
     "start_time": "2023-12-28T19:13:52.575527700Z"
    }
   },
   "id": "5e3d347040028189"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:11.083276800Z",
     "start_time": "2023-12-28T13:15:11.081278400Z"
    }
   },
   "id": "3314332ee3f9aef5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
