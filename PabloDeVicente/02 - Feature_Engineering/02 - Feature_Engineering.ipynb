{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am revisiting the second assignment, as I didn't fully grasp its goals during my initial attempt, which resulted in an underwhelming outcome.\n",
    "\n",
    "As i am doing this nootebook after class, i allready now that the ranker is basically a \"popularity ranking\", as such, i will try and improve said metric.\n",
    "\n",
    "I would like to acknowledge that I based this notebook on the work of Jakub Niedziela, as he was the one to come up with the solution\n",
    "\n",
    "note: my initial work is in the same folder, named equally to this one but adding \"_old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the cleaned csv files.  \n",
    "They are the same csv data but with some key differences:\n",
    "\n",
    "    Label encoded (takes less memory space)\n",
    "    Normalized\n",
    "    Added weeks to transactions (important!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet('../00 - Data/transactions_train/transactions_train.parquet')\n",
    "customers = pd.read_parquet('../00 - Data/customers/customers.parquet')\n",
    "articles = pd.read_parquet('../00 - Data/articles/articles.parquet')\n",
    "\n",
    "# sample = 0.05\n",
    "# transactions = pd.read_parquet(f'data/transactions_train_sample_{sample}.parquet')\n",
    "# customers = pd.read_parquet(f'data/customers_sample_{sample}.parquet')\n",
    "# articles = pd.read_parquet(f'data/articles_train_sample_{sample}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get last week +1 (we are trying to predict next weeks data)\n",
    "test_week = transactions.week.max() + 1\n",
    "#we filter data from last 10 weeks, as anything previous (summer clothes for example) might not be entirely necessary\n",
    "transactions = transactions[transactions.week > transactions.week.max() - 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>2020-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>2020-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>2020-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>2020-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>2020-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2020-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>2020-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>2020-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            min        max\n",
       "week                      \n",
       "95   2020-07-15 2020-07-21\n",
       "96   2020-07-22 2020-07-28\n",
       "97   2020-07-29 2020-08-04\n",
       "98   2020-08-05 2020-08-11\n",
       "99   2020-08-12 2020-08-18\n",
       "100  2020-08-19 2020-08-25\n",
       "101  2020-08-26 2020-09-01\n",
       "102  2020-09-02 2020-09-08\n",
       "103  2020-09-09 2020-09-15\n",
       "104  2020-09-16 2020-09-22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we get a list of every customer who has bought in each week\n",
    "c2weeks = transactions.groupby('customer_id')['week'].unique()\n",
    "\n",
    "#this shows the limits for each week. It works fine\n",
    "transactions.groupby('week')['t_dat'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shifts weeks one week, so we've got an aditional one\n",
    "c2weeks2shifted_weeks = {}\n",
    "\n",
    "for c_id, weeks in c2weeks.items():\n",
    "    c2weeks2shifted_weeks[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "    c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week\n",
    "\n",
    "#replace shifted weeks\n",
    "\n",
    "candidates_last_purchase = transactions.copy()\n",
    "\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(transactions['customer_id'], transactions['week'])):\n",
    "    weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "    \n",
    "candidates_last_purchase.week=weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestsellers candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>article_id</th>\n",
       "      <th>bestseller_rank</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>760084003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>866731001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>600886001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>706016001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>372860002</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>610776002</td>\n",
       "      <td>6</td>\n",
       "      <td>0.008318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96</td>\n",
       "      <td>877278002</td>\n",
       "      <td>7</td>\n",
       "      <td>0.025036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96</td>\n",
       "      <td>547780003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.024814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>96</td>\n",
       "      <td>817354001</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>96</td>\n",
       "      <td>827968001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.016436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96</td>\n",
       "      <td>866731003</td>\n",
       "      <td>11</td>\n",
       "      <td>0.024893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>96</td>\n",
       "      <td>866383006</td>\n",
       "      <td>12</td>\n",
       "      <td>0.023195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week  article_id  bestseller_rank     price\n",
       "0     96   760084003                1  0.025094\n",
       "1     96   866731001                2  0.024919\n",
       "2     96   600886001                3  0.022980\n",
       "3     96   706016001                4  0.033197\n",
       "4     96   372860002                5  0.013193\n",
       "5     96   610776002                6  0.008318\n",
       "6     96   877278002                7  0.025036\n",
       "7     96   547780003                8  0.024814\n",
       "8     96   817354001                9  0.021913\n",
       "9     96   827968001               10  0.016436\n",
       "10    96   866731003               11  0.024893\n",
       "11    96   866383006               12  0.023195"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean price of each article for each week\n",
    "mean_price = transactions \\\n",
    "    .groupby(['week', 'article_id'])['price'].mean()\n",
    "\n",
    "#\"dense\" will rank equally two items with same values (number of times sold in a week) 1-2-2-3 \n",
    "sales = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "\n",
    "#for each week it gives the top 12 most selled items\n",
    "sales\n",
    "\n",
    "# join sales rank wirh average price on each article - week\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1\n",
    "#we include the price of each of the best selled items\n",
    "bestsellers_previous_week.pipe(lambda df: df[df['week']==96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29030503</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>272412481300040</td>\n",
       "      <td>778064028</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29064059</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>1456826891333599</td>\n",
       "      <td>888294001</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29067103</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2133687643102426</td>\n",
       "      <td>843642001</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29027487</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>6010692573790711</td>\n",
       "      <td>857812010</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29046403</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>6171059100114610</td>\n",
       "      <td>815447007</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31760188</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>18435221511488011015</td>\n",
       "      <td>573085055</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31782234</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>18436859303155335645</td>\n",
       "      <td>801447001</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787251</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>18437941771381362708</td>\n",
       "      <td>907188001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31776022</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>18438270306572912089</td>\n",
       "      <td>751471043</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31779097</th>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>18440902715633436014</td>\n",
       "      <td>918894002</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755710 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              t_dat           customer_id  article_id     price  \\\n",
       "29030503 2020-07-15       272412481300040   778064028  0.008458   \n",
       "29064059 2020-07-15      1456826891333599   888294001  0.013542   \n",
       "29067103 2020-07-15      2133687643102426   843642001  0.042356   \n",
       "29027487 2020-07-15      6010692573790711   857812010  0.039661   \n",
       "29046403 2020-07-15      6171059100114610   815447007  0.006763   \n",
       "...             ...                   ...         ...       ...   \n",
       "31760188 2020-09-22  18435221511488011015   573085055  0.033881   \n",
       "31782234 2020-09-22  18436859303155335645   801447001  0.030492   \n",
       "31787251 2020-09-22  18437941771381362708   907188001  0.050831   \n",
       "31776022 2020-09-22  18438270306572912089   751471043  0.033881   \n",
       "31779097 2020-09-22  18440902715633436014   918894002  0.016932   \n",
       "\n",
       "          sales_channel_id  week  \n",
       "29030503                 1    95  \n",
       "29064059                 1    95  \n",
       "29067103                 2    95  \n",
       "29027487                 1    95  \n",
       "29046403                 2    95  \n",
       "...                    ...   ...  \n",
       "31760188                 1   104  \n",
       "31782234                 1   104  \n",
       "31787251                 2   104  \n",
       "31776022                 1   104  \n",
       "31779097                 1   104  \n",
       "\n",
       "[755710 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_transactions = transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()\n",
    "\n",
    "#just gets the list of customers who made a transaction (duplicates are possible) for each of the weeks\n",
    "unique_transactions\n",
    "\n",
    "#leaves a list of customers per week\n",
    "transactions.drop_duplicates(['week', 'customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join on customer + best articles purchased (rank and price)\n",
    "candidates_bestsellers = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")\n",
    "candidates_bestsellers\n",
    "\n",
    "#get only unique customers\n",
    "test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "test_set_transactions.week = test_week\n",
    "\n",
    "\n",
    "#join on test_set customers + best articles purchased (rank and price)\n",
    "candidates_bestsellers_test_week = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")\n",
    "\n",
    "#data + test data\n",
    "candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining transactions and candidates / negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>week</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31258500</th>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>6162030673331763443</td>\n",
       "      <td>748355003</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584739</th>\n",
       "      <td>2020-09-17</td>\n",
       "      <td>7779277796119032824</td>\n",
       "      <td>895555001</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29159065</th>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>18144024652367926358</td>\n",
       "      <td>739265003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t_dat           customer_id  article_id     price  \\\n",
       "31258500 2020-09-08   6162030673331763443   748355003  0.022017   \n",
       "31584739 2020-09-17   7779277796119032824   895555001  0.042356   \n",
       "29159065 2020-07-17  18144024652367926358   739265003  0.016932   \n",
       "\n",
       "          sales_channel_id  week  purchased  \n",
       "31258500                 2   102          1  \n",
       "31584739                 2   104          1  \n",
       "29159065                 2    95          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29903365</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>12588518229110888803</td>\n",
       "      <td>832473003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29231512</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>1844888445343397008</td>\n",
       "      <td>811368001</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29846279</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>11140663282535151277</td>\n",
       "      <td>823505001</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t_dat           customer_id  article_id     price  \\\n",
       "29903365 2020-08-04  12588518229110888803   832473003  0.016932   \n",
       "29231512 2020-07-20   1844888445343397008   811368001  0.015237   \n",
       "29846279 2020-08-03  11140663282535151277   823505001  0.030492   \n",
       "\n",
       "          sales_channel_id  week  \n",
       "29903365                 1   103  \n",
       "29231512                 2    96  \n",
       "29846279                 2   105  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>week</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7909746</th>\n",
       "      <td>2020-09-20</td>\n",
       "      <td>12707829296586431976</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>809238001</td>\n",
       "      <td>0.041612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167323</th>\n",
       "      <td>2020-08-13</td>\n",
       "      <td>12420156350657910531</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>739144004</td>\n",
       "      <td>0.010689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552663</th>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>16155737450858897096</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>827968001</td>\n",
       "      <td>0.016618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             t_dat           customer_id  sales_channel_id  week  article_id  \\\n",
       "7909746 2020-09-20  12707829296586431976                 2   104   809238001   \n",
       "3167323 2020-08-13  12420156350657910531                 2    99   739144004   \n",
       "2552663 2020-08-08  16155737450858897096                 2    98   827968001   \n",
       "\n",
       "            price  \n",
       "7909746  0.041612  \n",
       "3167323  0.010689  \n",
       "2552663  0.016618  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As all data here is historical, we know for fact that all purchases actually occured\n",
    "assert transactions.week.max() != test_week, 'Test week should not be in historical data'\n",
    "\n",
    "#we will later add some sample data that will have this column set to 0\n",
    "transactions['purchased'] = 1\n",
    "\n",
    "#fill dataframe with negative values, everything that was not bought is a sample now\n",
    "data = pd.concat([transactions, candidates_last_purchase, candidates_bestsellers])\n",
    "data.purchased.fillna(0, inplace=True)\n",
    "\n",
    "#transactions = customer - week grouping with article bought and price\n",
    "display(transactions.sample(3))\n",
    "#shifted weeks in transactions\n",
    "display(candidates_last_purchase.sample(3))\n",
    "#join on customer + best articles purchased price\n",
    "display(candidates_bestsellers.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of things can we do to improve the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most Sold in Last 10 weeks\n",
    "\n",
    "# Increased the score\n",
    "# 0.02046 -> 0.02049\n",
    "bestsellers_last_n_weeks = transactions['article_id'].value_counts()\\\n",
    "    .reset_index()\n",
    "bestsellers_last_n_weeks['bestseller_rank_n_weeks'] = bestsellers_last_n_weeks['count'].rank(method='dense', ascending=False)\n",
    "bestsellers_last_n_weeks.drop(columns='count', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bestsellers_last_n_weeks\n",
    "\n",
    "# Increased the score\n",
    "# 0.02049 -> 0.02051\n",
    "customer_favourite_color = \\\n",
    "    pd.merge(transactions[['customer_id', 'article_id']], articles[['article_id', 'perceived_colour_master_id']], on='article_id')\\\n",
    "    .drop(columns='article_id')\\\n",
    "    .groupby('customer_id')['perceived_colour_master_id'].value_counts()\\\n",
    "    .groupby('customer_id').head(1)\\\n",
    "    .reset_index()\\\n",
    "    .drop(columns='count')\\\n",
    "    .rename(columns={'perceived_colour_master_id': 'fav_perceived_colour_master_id'})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestsellers by postal code\n",
    "\n",
    "# Lower score\n",
    "# 0.02051 -> 0.02042\n",
    "bestsellers_zipcode = \\\n",
    "    pd.merge(transactions[['customer_id', 'article_id']], customers[['customer_id', 'postal_code']], on='customer_id') \\\n",
    "    .drop(columns='customer_id') \\\n",
    "    .groupby('article_id')['postal_code'].value_counts() \\\n",
    "    .groupby('article_id').head(1) \\\n",
    "    .reset_index() \\\n",
    "    .drop(columns='count') \\\n",
    "    .rename(columns={'postal_code': 'most_popular_postal_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customers favourite channel\n",
    "\n",
    "customer_favourite_channel = \\\n",
    "    pd.merge(transactions[['customer_id', 'article_id', 'sales_channel_id']], articles[['article_id']], on='article_id')\\\n",
    "    .drop(columns='article_id')\\\n",
    "    .groupby('customer_id')['sales_channel_id'].value_counts()\\\n",
    "    .groupby('customer_id').head(1)\\\n",
    "    .reset_index()\\\n",
    "    .drop(columns='count')\\\n",
    "    .rename(columns={'sales_channel_id': 'fav_sales_channel_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min, avg and max product price\n",
    "\n",
    "# Increased the score\n",
    "# 0.02042 -> 0.02094\n",
    "article_prices = transactions[['article_id', 'price']].groupby('article_id').agg(['min', 'max', 'mean']).reset_index()\n",
    "article_prices.columns = ['article_id', 'min_article_price', 'max_article_price', 'mean_article_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min, avg, max purchase price\n",
    "\n",
    "customer_prices = transactions[['customer_id', 'price']].groupby('customer_id').agg(['min', 'max', 'mean']).reset_index()\n",
    "customer_prices.columns = ['customer_id', 'min_customer_price', 'max_customer_price', 'mean_customer_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Remove first week of data, as we don't have bestseller rank for it\n",
    "# (week was shifted by one) and fill missing values with 999 -- really bad rank\n",
    "model_data = model_data[model_data.week != model_data.week.min()]\n",
    "model_data.fillna({'bestseller_rank':999}, inplace=True)\n",
    "\n",
    "# Add customer and article features\n",
    "model_data = pd.merge(model_data, articles, on='article_id', how='left')\n",
    "model_data = pd.merge(model_data, customers, on='customer_id', how='left')\n",
    "\n",
    "# Add bestseller rank for last n weeks\n",
    "model_data = pd.merge(model_data, bestsellers_last_n_weeks, on='article_id', how='left')\n",
    "\n",
    "# Add customer favourite color\n",
    "model_data = pd.merge(model_data, customer_favourite_color, on='customer_id', how='left')\n",
    "\n",
    "# Add customer favourite channel\n",
    "model_data = pd.merge(model_data, customer_favourite_channel, on='customer_id', how='left')\n",
    "\n",
    "# Add most popular postal code for each article\n",
    "model_data = pd.merge(model_data, bestsellers_zipcode, on='article_id', how='left')\n",
    "\n",
    "# Add article price features\n",
    "model_data = pd.merge(model_data, article_prices, on='article_id', how='left')\n",
    "\n",
    "# Add customer price features\n",
    "model_data = pd.merge(model_data, customer_prices, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorganizes the model_data dataframe bsaed on week and customer_id\n",
    "model_data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "#drops current index (maybe 123 - 1 - 943 - 40 - ..) and creates a new one (1 - 2 - 3 - 4)\n",
    "model_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want all data but our test one to train\n",
    "train = model_data[model_data.week != test_week]\n",
    "\n",
    "test = model_data[model_data.week == test_week]\\\n",
    "    .drop_duplicates(['customer_id', 'article_id', 'sales_channel_id'])\\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically how many purchased for each customer week pair -- so lgbm knows its one transaction\n",
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id']\\\n",
    "    .count()\\\n",
    "    .values  \n",
    "# for lightgbm ranker fit method\n",
    "# groupnumpy 1-D array\n",
    "#     Group/query data. Only used in the learning-to-rank task. sum(group) = n_samples. \n",
    "#     For example, if you have a 100-document dataset with group = [10, 20, 40, 10, 10, 10], that means that you have 6 groups, \n",
    "#     where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = [\n",
    "    'article_id', \n",
    "    'product_type_no', \n",
    "    'graphical_appearance_no', \n",
    "    'colour_group_code', \n",
    "    'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id', \n",
    "    'department_no', \n",
    "    'index_code',\n",
    "    'index_group_no', \n",
    "    'section_no', \n",
    "    'garment_group_no', \n",
    "    'FN', \n",
    "    'Active',\n",
    "    'club_member_status', \n",
    "    'fashion_news_frequency', \n",
    "    'age', \n",
    "    'postal_code', \n",
    "    'bestseller_rank', \n",
    "    'bestseller_rank_n_weeks', \n",
    "    'fav_perceived_colour_master_id',\n",
    "    # 'fav_sales_channel_id',\n",
    "    # 'most_popular_postal_code',\n",
    "    # 'min_article_price', 'max_article_price', 'mean_article_price',\n",
    "    # 'min_customer_price', 'max_customer_price', 'mean_customer_price',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.848530\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.192180\n",
      "[LightGBM] [Debug] init for col-wise cost 0.193828 seconds, init for row-wise cost 0.758255 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.519700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1343\n",
      "[LightGBM] [Info] Number of data points in the train set: 11849508, number of used features: 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "CPU times: total: 26.7 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9975670947443732\n",
      "fav_perceived_colour_master_id 0.001178745275527028\n",
      "colour_group_code 0.00032532053061590075\n",
      "perceived_colour_master_id 0.0002543311364503016\n",
      "article_id 0.00024399601970804725\n",
      "age 0.00016456009626360316\n",
      "bestseller_rank_n_weeks 0.00010073233227161269\n",
      "garment_group_no 6.230984900730054e-05\n",
      "postal_code 3.9511089501591246e-05\n",
      "perceived_colour_value_id 3.5539264754624535e-05\n",
      "product_type_no 2.7859661526759114e-05\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Active 0.0\n",
      "FN 0.0\n",
      "index_group_no 0.0\n",
      "index_code 0.0\n",
      "department_no 0.0\n",
      "graphical_appearance_no 0.0\n",
      "section_no 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "c_id2predicted_article_ids = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "# Get bestsellers from last week (test week)\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for c_id in customers.customer_id:\n",
    "    # c_id = idx_to_cust_id[c_id]  # map to original customer id\n",
    "    pred = c_id2predicted_article_ids.get(c_id, [])\n",
    "    pred = pred + bestsellers_last_week\n",
    "    preds.append(pred[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "sub = customers[['customer_id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is due to reduction mapping for customer ids\n",
    "\n",
    "with open('../data/mappings/cust_id_to_idx.json', 'r') as f:\n",
    "    cust_id_to_idx = json.load(f)\n",
    "\n",
    "idx_to_cust_id = {v: k for k, v in cust_id_to_idx.items()}\n",
    "\n",
    "sub['customer_id'] = sub['customer_id'].apply(lambda x: idx_to_cust_id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['prediction'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_name = 'basic_model_submission__best_features'\n",
    "sub.to_csv('./data/submissions/{sub_name}.csv.gz', index=False)\n",
    "!kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f '../data/submissions/{sub_name}.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c h-and-m-personalized-fashion-recommendations | head -n 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
