{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad823629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4862350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRY_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5687e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fc4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.25 s\n",
      "Wall time: 5.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if not DRY_RUN:\n",
    "    transactions = pd.read_parquet('../data/transactions_train/transactions_train.parquet')\n",
    "    customers = pd.read_parquet('../data/customers/customers.parquet')\n",
    "    articles = pd.read_parquet('../data/articles/articles.parquet')\n",
    "else:\n",
    "    sample = 0.05\n",
    "    transactions = pd.read_parquet(f'../data/transactions_train/transactions_train_sample_{sample}.parquet')\n",
    "    customers = pd.read_parquet(f'../data/customers/customers_sample_{sample}.parquet')\n",
    "    articles = pd.read_parquet(f'../data/articles/articles_train_sample_{sample}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a4cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week = transactions.week.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924fbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions[transactions.week > transactions.week.max() - 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56263b7a",
   "metadata": {},
   "source": [
    "# Generating candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06612658",
   "metadata": {},
   "source": [
    "The records I generate below can both be used as candidates for evaluation by our ranker (for the test week) and as negative examples (for training data).\n",
    "\n",
    "I am going with the name candidates for both of these use cases, but that is certainly not ideal. Feel free to refactor the naming to increase the clarity of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd43fcd",
   "metadata": {},
   "source": [
    "### Last purchase candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3b5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23.1 s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "c2weeks = transactions.groupby('customer_id')['week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7fadf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 641 ms\n",
      "Wall time: 631 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "c2weeks2shifted_weeks = {}\n",
    "\n",
    "for c_id, weeks in c2weeks.items():\n",
    "    c2weeks2shifted_weeks[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "    c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba2972df",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_last_purchase = transactions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b16858ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.2 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(transactions['customer_id'], transactions['week'])):\n",
    "    weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "    \n",
    "candidates_last_purchase.week=weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077cf9c",
   "metadata": {},
   "source": [
    "### Bestsellers candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a8af89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2493627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5fad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_transactions = transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd13379",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bestsellers = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22bba3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "test_set_transactions.week = test_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c201014",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bestsellers_test_week = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06c37a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22588375",
   "metadata": {},
   "source": [
    "# Combining transactions and candidates / negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41e61192",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['purchased'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76eb070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14606530579445656"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([transactions, candidates_last_purchase, candidates_bestsellers])\n",
    "data.purchased.fillna(0, inplace=True)\n",
    "\n",
    "data.purchased.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac183274",
   "metadata": {},
   "source": [
    "### Add bestseller information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f28957eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    data,\n",
    "    bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "    on=['week', 'article_id'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e7d3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.week != data.week.min()].copy()\n",
    "data.bestseller_rank.fillna(999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5fdc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, articles, on='article_id', how='left')\n",
    "data = pd.merge(data, customers, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3a737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['week', 'customer_id'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d83b869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.week != test_week]\n",
    "test = data[data.week==test_week].drop_duplicates(['customer_id', 'article_id', 'sales_channel_id']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71d57fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_baskets = train.groupby(['week', 'customer_id'])['article_id'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4c65da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "562146df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 438 ms\n",
      "Wall time: 432 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_X = train[columns_to_use]\n",
    "train_y = train['purchased']\n",
    "\n",
    "test_X = test[columns_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b26b0a",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17079af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00b6186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31408339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.847990\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.152231\n",
      "[LightGBM] [Debug] init for col-wise cost 0.204296 seconds, init for row-wise cost 0.584408 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.448383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1077\n",
      "[LightGBM] [Info] Number of data points in the train set: 10617433, number of used features: 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "CPU times: total: 22 s\n",
      "Wall time: 8.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ranker = ranker.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    group=train_baskets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9455e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestseller_rank 0.9988221008359978\n",
      "article_id 0.00032280530876886384\n",
      "age 0.000292525452583308\n",
      "garment_group_no 0.0001832666983498687\n",
      "postal_code 8.221541378404916e-05\n",
      "product_type_no 7.728522095350483e-05\n",
      "club_member_status 7.102321444967734e-05\n",
      "department_no 6.243632294211845e-05\n",
      "Active 4.033095364965426e-05\n",
      "colour_group_code 2.739073526846399e-05\n",
      "perceived_colour_value_id 1.8619843252697374e-05\n",
      "fashion_news_frequency 0.0\n",
      "FN 0.0\n",
      "section_no 0.0\n",
      "index_code 0.0\n",
      "perceived_colour_master_id 0.0\n",
      "graphical_appearance_no 0.0\n",
      "index_group_no 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "    print(columns_to_use[i], ranker.feature_importances_[i]/ranker.feature_importances_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb34139",
   "metadata": {},
   "source": [
    "# Calculate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fa10874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "test['preds'] = ranker.predict(test_X)\n",
    "\n",
    "c_id2predicted_article_ids = test \\\n",
    "    .sort_values(['customer_id', 'preds'], ascending=False) \\\n",
    "    .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "bestsellers_last_week = ['0' + str(a_id) for a_id in \\\n",
    "                             bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e547eb1",
   "metadata": {},
   "source": [
    "# Create a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51076f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\master\\ai_project\\kaggle\\hm\\personalized_fashion_recs-main\\02_Basic_Model_Redux.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/master/ai_project/kaggle/hm/personalized_fashion_recs-main/02_Basic_Model_Redux.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sub \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/sample_submission.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\Program Files\\Python\\Python3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1d72599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.6 s, sys: 179 ms, total: 3.78 s\n",
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = []\n",
    "for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "    if c_id in c_id2predicted_article_ids:\n",
    "        ps = ['0' + str(p) for p in c_id2predicted_article_ids[c_id]]\n",
    "        preds.append(ps)\n",
    "    else:\n",
    "        preds.append(bestsellers_last_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "274e83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [' '.join(ps) for ps in preds]\n",
    "sub.prediction = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fffe2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_name = 'basic_with_bestseller_information'\n",
    "sub.to_csv(f'data/subs/{sub_name}.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "007bc52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 58.4M/58.4M [00:31<00:00, 1.92MB/s]\n",
      "Successfully submitted to H&M Personalized Fashion Recommendations"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f 'data/subs/{sub_name}.csv.gz' -m {sub_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6776e",
   "metadata": {},
   "source": [
    "# Where to go from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e231d3",
   "metadata": {},
   "source": [
    "This notebook has all the components of a valid solution.\n",
    "\n",
    "We generate negative examples.\n",
    "We generate candidates for the test set.\n",
    "We also enrich transaction records with calculated statistics (bestseller information from previous week).\n",
    "\n",
    "From there on we train a model and use that model to output predictions.\n",
    "\n",
    "But all of this is intentionally very basic. Look how many components we had to get in place to get to this spot!\n",
    "\n",
    "Now the fun part begins.\n",
    "\n",
    "Further work on this should fall into three categories IMHO:\n",
    "* use functionality from this and the `Solution Warmup` notebook to work out a good way of validating the LGBM ranker and end-to-end predictions (all the components for this have been developed, they just need to be piece together)\n",
    "* develop useful features that would describe (Kaggle kernels for this competition already have a lot of code you can reuse, everything by Chris Deotte is gold)\n",
    "    * the customer\n",
    "    * the article\n",
    "    * customer tendencies\n",
    "* train a couple of varied models and figure out how to blend them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
