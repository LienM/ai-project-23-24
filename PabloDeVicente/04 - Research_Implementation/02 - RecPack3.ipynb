{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from recpack.scenarios import WeakGeneralization, Timed\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "from recpack.preprocessing.filters import MinItemsPerUser, MinUsersPerItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has size of : 31788324\n",
      "Created a sample of 0.0005 % with 15894 records\n"
     ]
    }
   ],
   "source": [
    "#1:  Data collection\n",
    "transactions_path = '../../00 - Data/transactions/transactions_train.csv'\n",
    "transactions = pd.read_csv(transactions_path)\n",
    "print(\"Original data has size of : \" + str(len(transactions)))\n",
    "\n",
    "sample = 0.0005\n",
    "transactions_sample = transactions.sample(frac=sample, random_state=40)\n",
    "print(\"Created a sample of \" + str(sample) + \" % with \" + str(len(transactions_sample)) + \" records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31588145/31588145 [00:49<00:00, 643028.37it/s]\n",
      "100%|██████████| 31588145/31588145 [00:41<00:00, 763627.86it/s] \n"
     ]
    }
   ],
   "source": [
    "#2: Data preprocessing\n",
    "\n",
    "#        item1    item2   item3\n",
    "#usr1      x                x\n",
    "#usr2       x       x\n",
    "proc = DataFramePreprocessor(item_ix='article_id', user_ix='customer_id', timestamp_ix='t_dat')\n",
    "# #every user has at least 2 items bought\n",
    "proc.add_filter(MinUsersPerItem(2, item_ix='article_id', user_ix='customer_id'))\n",
    "# #every item is bought at least twice\n",
    "proc.add_filter(MinItemsPerUser(2, item_ix='article_id', user_ix='customer_id'))\n",
    "\n",
    "interaction_matrix = proc.process(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1207280it [06:47, 2961.34it/s]\n",
      "1207280it [08:30, 2364.12it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#3 : Create scenario\n",
    "#divide matrix into test-train (75-25)\n",
    "scenario = WeakGeneralization(0.75, validation=True)\n",
    "# scenario = Timed()\n",
    "scenario.split(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 : Create the builder object\n",
    "from PipelineBuilder_modified import *\n",
    "\n",
    "\n",
    "builder = PipelineBuilder()\n",
    "builder.set_data_from_scenario(scenario)\n",
    "\n",
    "#adds algorithms to use later on. Baseline algorithim, just recommends popular stuff\n",
    "# builder.add_algorithm('Popularity') \n",
    "builder.add_algorithm('ItemKNN', grid={\n",
    "    'K': [100, 200, 500],\n",
    "    'similarity': ['cosine', 'conditional_probability'],\n",
    "})\n",
    "#Set the metric for optimisation of parameters in algorithms. What is NDCGK ??\n",
    "builder.set_optimisation_metric('NDCGK', K=10)\n",
    "\n",
    "#adds metric for evaluation\n",
    "#NDCGK = Normalized Discounted Cumulative Gain at K\n",
    "builder.add_metric('NDCGK', K=[10, 20, 50])\n",
    "builder.add_metric('CoverageK', K=[10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 : Create and run the pipeline\n",
    "pipeline = builder.build()\n",
    "csr = pipeline.run2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserRecommendations:\n",
    "    def __init__(self):\n",
    "        self.user_data = {}\n",
    "\n",
    "    def add_rec(self, user_id, item_id, recommendation_value):\n",
    "        if user_id not in self.user_data:\n",
    "            self.user_data[user_id] = []\n",
    "        self.user_data[user_id].append((item_id, recommendation_value))\n",
    "\n",
    "    def get_rec_user(self, user_id):\n",
    "        return self.user_data.get(user_id, [])\n",
    "\n",
    "# Example usage:\n",
    "user_rec = UserRecommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the list of every user who has been recomended smth\n",
    "user_ids = set()\n",
    "for row in range(csr.shape[0]):\n",
    "    if csr.indptr[row] != csr.indptr[row + 1]:\n",
    "        user_ids.add(row)\n",
    "\n",
    "for user in user_ids:\n",
    "    print(\"User : \" + str(user))\n",
    "    #info sobre las recomendaciones de un usuario\n",
    "    client_row = csr.getrow(user)\n",
    "    # print(client_row)\n",
    "    #indice del item con maxima recomendacion \n",
    "    rec_value_index = np.argmax(client_row.data)\n",
    "    # print(rec_value_index)\n",
    "    #valor asociado a dicha recomendacion\n",
    "    rec_value = client_row.max()\n",
    "    print(\"Max recommendation value : \" + str(rec_value))\n",
    "    #id del articulo recomendado\n",
    "    article_id_rec= client_row.indices[rec_value_index]\n",
    "    print(\"Recommended article id : \" + str(article_id_rec))\n",
    "\n",
    "    user_rec.add_rec(user,article_id_rec,rec_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the `proc` DataFramePreprocessor instance and `interaction_matrix` containing processed data\n",
    "# Get the item and user ID mappings from the DataFramePreprocessor instance\n",
    "item_id_mapping = proc.item_id_mapping.set_index(interaction_matrix.ITEM_IX)[proc.item_ix].to_dict()\n",
    "user_id_mapping = proc.user_id_mapping.set_index(interaction_matrix.USER_IX)[proc.user_ix].to_dict()\n",
    "\n",
    "user_id_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 : Get results\n",
    "\n",
    "pipeline.get_metrics()\n",
    "# pipeline.optimisation_results\n",
    "\n",
    "#pipeline.saveResults()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
