{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries to follow the resources of the following link, although it is unsuccesfull\n",
    "https://blog.tensorflow.org/2020/09/introducing-tensorflow-recommenders.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow_recommenders\n",
    "pip install tensorflow-datasets\n",
    "pip install numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movie_lens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movie_lens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the features available in the dataset, the most useful are user ids and movie titles. While TFRS can use arbitrarily rich features, let's only use those to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerMovielensModel(tfrs.Model):\n",
    "  \"\"\"MovieLens prediction model.\"\"\"\n",
    " \n",
    "  def __init__(self):\n",
    "    # The `__init__` method sets up the model architecture.\n",
    "    super().__init__()\n",
    " \n",
    "    # How large the representation vectors are for inputs: larger vectors make\n",
    "    # for a more expressive model but may cause over-fitting.\n",
    "    embedding_dim = 32\n",
    "    num_unique_users = 1000\n",
    "    num_unique_movies = 1700\n",
    "    eval_batch_size = 128\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = tf.keras.Sequential([\n",
    "      # We first turn the raw user ids into contiguous integers by looking them\n",
    "      # up in a vocabulary.\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "          max_tokens=num_unique_users),\n",
    "      # We then map the result into embedding vectors.\n",
    "      tf.keras.layers.Embedding(num_unique_users, embedding_dim)\n",
    "    ])\n",
    "    self.movie_model = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "          max_tokens=num_unique_movies),\n",
    "      tf.keras.layers.Embedding(num_unique_movies, embedding_dim)\n",
    "    ])\n",
    "\n",
    "    # The `Task` objects has two purposes: (1) it computes the loss and (2)\n",
    "    # keeps track of metrics.\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        # In this case, our metrics are top-k metrics: given a user and a known\n",
    "        # watched movie, how highly would the model rank the true movie out of\n",
    "        # all possible movies?\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(eval_batch_size).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def compute_loss(self, features, training=False):\n",
    "        # The `compute_loss` method determines how loss is computed.\n",
    "    \n",
    "        # Compute user and item embeddings.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    \n",
    "        # Pass them into the task to get the resulting loss. The lower the loss is, the\n",
    "        # better the model is at telling apart true watches from watches that did\n",
    "        # not happen in the training data.\n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowerMovielensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    " \n",
    "model.fit(ratings.batch(4096), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = tfrs.layers.ann.BruteForce(model.user_model)\n",
    "index.index(movies.batch(100).map(model.movie_model), movies)\n",
    " \n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.Model):\n",
    " \n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      movie_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    " \n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.movie_model = movie_model\n",
    " \n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    " \n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    " \n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    " \n",
    "    return self.task(user_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_id_vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10204/973798854.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m users_model = tf.keras.Sequential([user_id_vocabulary,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                    tf.keras.layers.Embedding(user_id_vocabulary.vocab_size(),64)])\n\u001b[1;32m      3\u001b[0m \u001b[0mmovie_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovies_title_vocabulary\u001b[0m\u001b[0;34m,\u001b[0m                                   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_title_vocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_id_vocabulary' is not defined"
     ]
    }
   ],
   "source": [
    "users_model = tf.keras.Sequential([user_id_vocabulary,\n",
    "                                   tf.keras.layers.Embedding(user_id_vocabulary.vocab_size(),64)])\n",
    "movie_model = tf.keras.Sequential([movies_title_vocabulary,                                   tf.keras.layers.Embedding(movies_title_vocabulary.vocab_size(),64)])\n",
    " \n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    movies.batch(128).map(movie_model)))\n",
    "# Now let us create, compile, and train a retrieval model.\n",
    "\n",
    "model = MovieLensModel(users_model,movie_model,task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "model.fit(rating.batch(4096), epochs=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
