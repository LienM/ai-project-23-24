{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second try at this implementation\n",
    "\n",
    "1. Loads csv as pandas dataframe\n",
    "2. Converts each line of the dataframe to tensor\n",
    "3. Creates _MapDataset obj (same as obj recieved when loading sample data (TensorFlow2))\n",
    "4. Preprocess data -> needs to convert to array and back to tensor to make operations -> CHANGE!! preprocess the csv before to simplify\n",
    "5. Embed both towers and train the model\n",
    "6. Obtain results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-14 17:30:53.499590: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-14 17:30:53.499649: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-14 17:30:53.499684: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-14 17:30:53.506726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 17:30:54.496340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tqdm as notebook_tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import pandas as pd\n",
    "import functions as f\n",
    "\n",
    "from typing import Dict, Text\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['customer_id', 'article_id'] \n",
    "column_defaults = [tf.int64, tf.int64]\n",
    "\n",
    "file_path = '../00 - Data/transactions/transactions_train_short2.csv'\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "\n",
    "# Create the dataset\n",
    "transactions = tf.data.experimental.make_csv_dataset(\n",
    "    file_path,\n",
    "    batch_size=batch_size,\n",
    "    column_names=column_names,\n",
    "    column_defaults=column_defaults,\n",
    "    label_name='article_id',  \n",
    "    header=True, \n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "column_names = ['article_id'] \n",
    "column_defaults = [tf.int64]\n",
    "\n",
    "file_path = '../00 - Data/articles/articles2.csv'\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "\n",
    "# Create the dataset\n",
    "articles = tf.data.experimental.make_csv_dataset(\n",
    "    file_path,\n",
    "    batch_size=batch_size,\n",
    "    column_names=column_names,\n",
    "    column_defaults=column_defaults,\n",
    "    header=False, \n",
    "    num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=OrderedDict([('article_id', TensorSpec(shape=(None,), dtype=tf.int64, name=None))])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(OrderedDict([('customer_id', TensorSpec(shape=(None,), dtype=tf.int64, name=None))]), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<_MapDataset element_spec={'movie_title': TensorSpec(shape=(), dtype=tf.string, name=None), 'user_id': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimated_max_elements = 2.2e6 \n",
    "embedding_dim = 32\n",
    "\n",
    "# User tower (embedding for users)\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=int(estimated_max_elements), output_dim=embedding_dim, input_length=1)\n",
    "])\n",
    "\n",
    "# Article tower (embedding for articles)\n",
    "article_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=int(105542), output_dim=embedding_dim, input_length=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `Task` objects has two purposes: (1) it computes the loss and (2)\n",
    "    # keeps track of metrics.\n",
    "eval_batch_size = 128\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=articles.batch(eval_batch_size)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmModel(tfrs.Model):\n",
    " \n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      article_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    " \n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.article_model = article_model\n",
    " \n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    " \n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    " \n",
    "    user_embeddings = self.user_model(features[0]['customer_id'])  # Accessing feature using integer index\n",
    " \n",
    "    return self.task(user_embeddings, article_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in articles.take(1):  # Print the first element for inspection\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmModel(user_model,article_model,task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "model.fit(transactions.batch(4096), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommends = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "recommends.index_from_dataset(articles.batch(100).map(lambda title: (title, model.article_model(title))))\n",
    " \n",
    "id_ = input('Enter the user_id: ')\n",
    "_, titles = recommends(np.array([str(id_)]))\n",
    "print('Top recommendation for user',id_,titles[0, :3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
