from sklearn.base import BaseEstimator, TransformerMixin
import numpy as np
import pandas as pd
from typing import Tuple, List, Dict


def read_parquet_datasets():
    """
    Reads the parquet dataset files that were generated by Radek's warmup routine.

    Parameters
    ----------
    None

    Returns
    -------
    datasets : tuple
            The transactions, customers and articles datasets

    """

    base_path: str = '../../input/'
    transactions: pd.DataFrame = pd.read_parquet(base_path + 'transactions_train.parquet')
    customers: pd.DataFrame = pd.read_parquet(base_path + 'customers.parquet')
    articles: pd.DataFrame = pd.read_parquet(base_path + 'articles.parquet')

    # Replace -1 values in age column with mean age for better candidate generation results
    customers.age.replace(-1, customers.age.mean(), inplace=True)

    return transactions, customers, articles


def apk(actual, predicted, k=10):
    """
    Computes the average precision at k.

    This function computes the average prescision at k between two lists of
    items.

    Parameters
    ----------
    actual : list
             A list of elements that are to be predicted (order doesn't matter)
    predicted : list
                A list of predicted elements (order does matter)
    k : int, optional
        The maximum number of predicted elements

    Returns
    -------
    score : double
            The average precision at k over the input lists

    """
    if len(predicted)>k:
        predicted = predicted[:k]

    score = 0.0
    num_hits = 0.0

    for i,p in enumerate(predicted):
        if p in actual and p not in predicted[:i]:
            num_hits += 1.0
            score += num_hits / (i+1.0)

    if not actual:
        return 0.0

    return score / min(len(actual), k)

def mapk(actual, predicted, k=10):
    """
    Computes the mean average precision at k.

    This function computes the mean average prescision at k between two lists
    of lists of items.

    Parameters
    ----------
    actual : list
             A list of lists of elements that are to be predicted
             (order doesn't matter in the lists)
    predicted : list
                A list of lists of predicted elements
                (order matters in the lists)
    k : int, optional
        The maximum number of predicted elements

    Returns
    -------
    score : double
            The mean average precision at k over the input lists

    """
    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])


# https://www.kaggle.com/c/h-and-m-personalized-fashion-recommendations/discussion/308635
def customer_hex_id_to_int(series):
    return series.str[-16:].apply(hex_id_to_int)


def hex_id_to_int(str):
    return int(str[-16:], 16)


def article_id_str_to_int(series):
    return series.astype('int32')


def article_id_int_to_str(series):
    return '0' + series.astype('str')


class Categorize(BaseEstimator, TransformerMixin):
    def __init__(self, min_examples=0):
        self.min_examples = min_examples
        self.categories = []

    def fit(self, X):
        for i in range(X.shape[1]):
            vc = X.iloc[:, i].value_counts()
            self.categories.append(vc[vc > self.min_examples].index.tolist())
        return self

    def transform(self, X):
        data = {X.columns[i]: pd.Categorical(X.iloc[:, i], categories=self.categories[i]).codes for i in
                range(X.shape[1])}
        return pd.DataFrame(data=data)


### Below is everything related to recall calculation ###

# \/ Copied from NickWils https://github.com/LienM/ai-project-23-24/blob/main/NickWils/Lecture6/candidate-repurchase.ipynb
def recall(actual, predicted, k=12):
    if len(predicted) > k:
        predicted = predicted[:k]
    correct_predictions = [p for p in predicted if p in actual]
    return len(correct_predictions) / len(actual)
def recall12(actual, predicted, k=12):
    return np.mean([recall(a, p, k) for a, p in zip(actual, predicted)])
# /\


def calculateRecall(actual: List[int], predicted: List[int]) -> float:
    """
    Calculates the recall, which is the number of retrieved values
    that are also in expected (True positive)
    divided by the number of expected values that aren't retrieved (False negative).
    R(ecall) = TP/(TP+FN).

    Parameters
    ----------
    actual : list
             A list of elements that are to be predicted (order doesn't matter)
    predicted : list
                A list of predicted elements (order does matter)

    Returns
    -------
    score : float
            The recall of the predicted list over the actual list

    """
    # number of predicted values that are also in actual (True positive)
    tp: int = len([ret for ret in predicted if ret in actual])
    # number of actual values that aren't predicted (False negative)
    fn: int = len([ex for ex in actual if ex not in predicted])
    # recall calculation (by formula)
    recall: float = tp / (tp + fn)
    return recall


def mean_recall(actual: List[List[int]], predicted: List[List[int]]) -> float:
    """
    Calculates the mean recall.

    Parameters
    ----------
    actual : list
             A list of lists of elements that are to be predicted (order doesn't matter)
    predicted : list
                A list of lists of predicted elements (order does matter)

    Returns
    -------
    score : float
            The mean recall.

    """
    recalls: List[float] = [calculateRecall(ex, ret) for ex, ret in zip(actual, predicted)]
    mean_recall: float = np.mean(recalls)
    return mean_recall


def calculate_recall_per_customer_batch(validation: pd.DataFrame, top_candidates_3feat_prev_week: pd.DataFrame, customer_batch: List[int], top_x_age: int = 25) -> float:
    """
    Calculates the mean recall for the candidates of a batch of customers in the last week (104) of transactions.

    Parameters
    ----------
    validation : pandas.DataFrame
                The validation dataset
    top_candidates_3feat_prev_week : pandas.DataFrame
                The candidates dataset
    customer_batch : list
                A list of (unique) customer_ids which are part of the total customer set in our training data
    top_x_age : int, optional
                The number of candidates per customer, used for a sanity check

    Returns
    -------
    score : float
            The mean recall on the candidates for the customer batch for the last week.

    """

    # Filter validation to only contain the customers in the batch
    validation_corresp_customers: pd.DataFrame = validation[validation['customer_id'].isin(customer_batch)]

    # Get the corresponding candidates generated for the customers in the last week
    candidates_last_week: pd.DataFrame = top_candidates_3feat_prev_week[
        (top_candidates_3feat_prev_week['week'] == validation_corresp_customers['week'].max()) &
        (top_candidates_3feat_prev_week['customer_id'].isin(validation_corresp_customers['customer_id'].unique()))
    ]

    # Sort both validation and candidates_last_week by customer_id (and article_id)
    # to make sure that the customer_id values match for the mean recall function
    validation_corresp_customers: pd.DataFrame = validation_corresp_customers.sort_values(['customer_id', 'article_id'])
    candidates_last_week: pd.DataFrame = candidates_last_week.sort_values(['customer_id', 'article_id'])

    # Check if validation and candidates_last_week have the same number of unique customers,
    # this is a little sanity check. Commented out for performance reasons.
    # if validation['customer_id'].nunique() * top_x_age == candidates_last_week.shape[0]:
    #     print("Validation and candidates_last_week have the same number of unique customers (OKAY).")
    # else:
    #     print("Validation and candidates_last_week don't have the same number of unique customers (NOT REALLY OKAY).")

    # Group actual purchases and candidates by customer_id to get the lists of articles
    actual_purchases_last_week: List[List[int]] = validation_corresp_customers.groupby('customer_id')['article_id'].apply(list).tolist()
    predicted_candidates_last_week: List[List[int]] = candidates_last_week.groupby('customer_id')['article_id'].apply(list).tolist()

    # Calculate recall between actual purchases and predicted candidates for the last week
    recall_last_week: float = mean_recall(actual_purchases_last_week, predicted_candidates_last_week)

    print("Recall Score on Candidates for Last Week:", recall_last_week)

    return recall_last_week


def calculate_recall_per_week(validation: pd.DataFrame, top_candidates_3feat_prev_week: pd.DataFrame, customer_batch: List[int], compare_against_bestsellers: bool = False) -> Dict[int, float]:
    """
    Calculates the mean recall for the candidates of a batch of customers in the last 5 weeks of transactions.

    Parameters
    ----------
    validation : pandas.DataFrame
                The validation dataset
    top_candidates_3feat_prev_week : pandas.DataFrame
                The candidates dataset
    customer_batch : list
                A list of (unique) customer_ids which are part of the total customer set in our training data
    compare_against_bestsellers : bool, optional
                Whether to compare the candidates against the bestsellers with intersection (default is False)

    Returns
    -------
    score : dict
            The mean recall on the candidates for the customer batch per week.

    """

    overall_mean_recalls: Dict[int, float] = {}
    max_week: int = validation['week'].max()

    for week in range(max_week, max_week - 5, -1):

        # Filter validation and candidates for the current week
        validation_week: pd.DataFrame = validation[validation['week'] == week]
        validation_corresp_customers: pd.DataFrame = validation_week[validation_week['customer_id'].isin(customer_batch)]

        candidates_last_week: pd.DataFrame = top_candidates_3feat_prev_week[
            (top_candidates_3feat_prev_week['week'] == week) &
            (top_candidates_3feat_prev_week['customer_id'].isin(validation_corresp_customers['customer_id'].unique()))
        ]

        # Sort both validation_corresp_customers and candidates_last_week by customer_id (and article_id)
        # to make sure that the customer_id values match for the mean recall function
        validation_corresp_customers: pd.DataFrame = validation_corresp_customers.sort_values(['customer_id', 'article_id'])
        candidates_last_week: pd.DataFrame = candidates_last_week.sort_values(['customer_id', 'article_id'])

        # Group purchases and candidates by customer_id to get the lists of articles
        actual_purchases_week: List[List[int]] = validation_corresp_customers.groupby('customer_id')['article_id'].apply(list).tolist()
        predicted_candidates_week: List[List[int]] = candidates_last_week.groupby('customer_id')['article_id'].apply(list).tolist()

        # compare against (popularity) bestsellers
        if compare_against_bestsellers:
            bestsellers_per_week: Dict[int, List[int]] = {
                    100: [916468003, 812668001, 866731001, 610776002, 896152002, 923460001, 896152001, 751471001, 938182001, 894668003, 706016003, 870328003],
                    101: [916468003, 896152003, 896152002, 751471001, 706016001, 918292001, 921906003, 751471043, 706016003, 918292004, 915526002, 920610001],
                    102: [898694001, 933706001, 751471001, 915526001, 915529003, 706016001, 918292001, 751471043, 915526002, 915529001, 862970001, 863595006],
                    103: [915526001, 751471043, 751471001, 706016001, 919365008, 915529003, 918292001, 863595006, 896152002, 448509014, 909916001, 762846031],
                    104: [909370001, 865799006, 918522001, 924243001, 448509014, 751471001, 809238001, 918292001, 762846027, 809238005, 673677002, 923758001],
            }
            for customer_id, predicted_candidates in predicted_candidates_week.items():
                intersection = set(bestsellers_per_week[week]).intersection(predicted_candidates)
                if intersection:
                    print(f"Week {week}, Customer {customer_id}: Intersection - {intersection}")

        # Calculate recall between actual purchases and predicted candidates for the current week
        recall_week: float = mean_recall(actual_purchases_week, predicted_candidates_week)
        overall_mean_recalls[week] = recall_week

    return overall_mean_recalls
