{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_transactions_by_weeks(transactions, column=\"article_id_mapped\"):\n",
    "    # Function to filter transactions by training weeks\n",
    "    col = column if column != \"article_id\" else \"article_id_mapped\"\n",
    "    _transactions = transactions[[\"customer_id\", col, \"week\"]]\n",
    "    filtered_transactions = _transactions[_transactions.week.between(MAX_WEEK - N_TRAINING_WEEKS, MAX_WEEK - 1)]\n",
    "    filtered_transactions = filtered_transactions.groupby(\"customer_id\")[col].apply(list).reset_index(name=\"history\")\n",
    "    return filtered_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRecommender(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Recommender model.\n",
    "    A simple LSTM model that takes a sequence of feature values and outputs a probability distribution over the possible values.\n",
    "\n",
    "    Args:\n",
    "        embedding_dim (int): The size of the embedding vector.\n",
    "        input_dim (int): The size of the input vector.\n",
    "        hidden_dim (int): The size of the hidden layer.\n",
    "        n_articles (int): The number of possible values for the feature.\n",
    "        num_layers (int): The number of layers in the LSTM model.\n",
    "        bidirectional (bool): Whether the LSTM model is bidirectional or not.\n",
    "        dropout (float): The dropout probability.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, input_dim, hidden_dim, n_articles, num_layers=2, bidirectional=True, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_articles = n_articles\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Embedding articles to a lower dimension\n",
    "        self.embedding = nn.Embedding(n_articles, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_dim * num_layers, n_articles)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.n_directions * self.num_layers, x.size(0), self.hidden_dim, requires_grad=True, device=device)\n",
    "        c0 = torch.zeros(self.n_directions * self.num_layers, x.size(0), self.hidden_dim, requires_grad=True, device=device)\n",
    "        # Embed\n",
    "        embedded_sequence = self.embedding(x)\n",
    "        # Forward propagate LSTM\n",
    "        out, (hn, cn) = self.lstm(embedded_sequence, (h0.detach(), c0.detach()))\n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Transactions dataset.\n",
    "    Contains the filtered transactions dataframe to be used in the training process. (to use in the dataloader)\n",
    "\n",
    "    Args:\n",
    "        transactions (DataFrame): Filtered transactions dataframe.\n",
    "        padding_value (int): Padding value, not necessarily article id.\n",
    "        num_articles_in_sequence (int): Number of articles in a sequence.\n",
    "    \"\"\"\n",
    "    def __init__(self, transactions, padding_value, num_articles_in_sequence):\n",
    "        self.transactions_df = transactions\n",
    "        self.padding_value = padding_value\n",
    "        self.num_articles_in_sequence = num_articles_in_sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.transactions_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        customer_id, history = self.transactions_df.iloc[idx]\n",
    "        if len(history) < 12:\n",
    "            history = [self.padding_value] * (self.num_articles_in_sequence - len(history)) + history\n",
    "        return torch.tensor(history[-12:], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Sequence dataset.\n",
    "    Contains the sequences and targets of customers\n",
    "\n",
    "    Args:\n",
    "        sequences: List of sequences.\n",
    "        targets: List of targets.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoryDataset(Dataset):\n",
    "    \"\"\"\n",
    "    History dataset.\n",
    "    Contains the histories of customers, like the TransactionsDataset, but uses default values\n",
    "    \"\"\"\n",
    "    def __init__(self, history):\n",
    "        self.histories = history\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.histories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        history = self.histories[idx]\n",
    "        if len(history) < 12:\n",
    "            history = [PADDING_ARTICLE] * (NUM_ARTICLES_IN_SEQUENCE - len(history)) + history\n",
    "        return torch.tensor(history[-12:], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sequences(user_transactions):\n",
    "    combined_sequence_batch = []\n",
    "    combined_target_batch = []\n",
    "    \n",
    "    for idx, (customer, history) in user_transactions.iterrows():\n",
    "        history_batch, target_batch = create_batch(history)\n",
    "        if history_batch is None or target_batch is None:\n",
    "            continue\n",
    "        combined_sequence_batch.extend(history_batch)\n",
    "        combined_target_batch.extend(target_batch)\n",
    "    \n",
    "    sequence_dataset = SequenceDataset(combined_sequence_batch, combined_target_batch)\n",
    "    dataloader = DataLoader(sequence_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(history):\n",
    "    # Create batch of sequences\n",
    "    if len(history) <= 1:\n",
    "        return None, None\n",
    "    history_batch = []\n",
    "    target_batch = []\n",
    "    for i in range(1, len(history)):\n",
    "        if i < 12:\n",
    "            # Add padding to the beginning of the sequence\n",
    "            history_batch.append(torch.tensor([PADDING_ARTICLE] * (NUM_ARTICLES_IN_SEQUENCE - i) + history[:i], dtype=torch.int32))\n",
    "        else:\n",
    "            history_batch.append(torch.tensor(history[i-12:i], dtype=torch.int32))\n",
    "        target_batch.append(torch.tensor(history[i], dtype=torch.float32, requires_grad=True))\n",
    "    return history_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_lstm(logits, temperature=1.0):\n",
    "    # Temperature scaled sampling\n",
    "    scaled = logits / temperature\n",
    "    probabilities = F.softmax(scaled, dim=1)\n",
    "    return torch.multinomial(probabilities, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predictions(predictions, articles_from_column, default_value):\n",
    "    # Most popular article selection from predicted feature values\n",
    "    # i.e. product_type_name -> article_id based on popularity\n",
    "    customer_preds = []\n",
    "    for pred in predictions:\n",
    "        articles = articles_from_column.get(pred, [])\n",
    "        if pred != default_value:\n",
    "            articles += articles_from_column.get(default_value, [])\n",
    "\n",
    "        for article in articles:\n",
    "            if article not in customer_preds:\n",
    "                customer_preds.append(article)\n",
    "                break\n",
    "    \n",
    "    assert len(customer_preds) == 12, f\"Could not generate 12 recommendations with the provided predictions. Only {len(customer_preds)} can be generated\"\n",
    "    \n",
    "    return customer_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mapped_predictions(predictions, inverse_article_id_map, most_popular):\n",
    "    # Translates predicted articles to actual article ids\n",
    "    # note: articles start from 0 to n_articles + 1 (padding) in the model so we need to map them back to the original ids\n",
    "    customer_preds = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        article = inverse_article_id_map.get(pred, None)\n",
    "        if article is not None:\n",
    "            customer_preds.append(article)\n",
    "            continue\n",
    "        for item in most_popular:\n",
    "            if item not in customer_preds:\n",
    "                customer_preds.append(item)\n",
    "                break\n",
    "    \n",
    "    assert len(customer_preds) == 12, f\"Could not generate 12 recommendations with the provided predictions. Only {len(customer_preds)} can be generated\"\n",
    "    \n",
    "    return customer_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_purchases(transactions):\n",
    "    \"\"\"\n",
    "    Convert a dataframe containing transactions to a dataframe where each row has a customer_id and a list of purchases for that customer.\n",
    "\n",
    "    @param transactions: a dataframe of transactions\n",
    "    \"\"\"\n",
    "    return (\n",
    "        transactions.groupby(\"customer_id\", as_index=False)\n",
    "        .article_id.apply(set)\n",
    "        .rename(columns={\"article_id\": \"purchases\"})[[\"customer_id\", \"purchases\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(candidates, features, ranker, k=12):\n",
    "    \"\"\"\n",
    "    Uses a dataframe of candidates, a dataframe of features belonging to the candidates, and a trained ranker to generate k predictions for each customer represented in the candidates.\n",
    "    The candidates dataframe must have the same index as the features dataframe.\n",
    "\n",
    "    The ranker must have a predict method that takes a dataframe of features and returns a series of scores.\n",
    "\n",
    "    @candidates: a dataframe of candidates (customer_id, article_id)\n",
    "    @features: a dataframe of features belonging to the candidates\n",
    "    @ranker: a trained ranker\n",
    "    @k: the number of predictions to generate for each customer\n",
    "    \"\"\"\n",
    "    scored_candidates = candidates.copy()\n",
    "    scored_candidates[\"score\"] = ranker.predict(features)\n",
    "\n",
    "    return (\n",
    "        scored_candidates.sort_values([\"customer_id\", \"score\"], ascending=False)\n",
    "        .groupby(\"customer_id\")\n",
    "        .head(k)\n",
    "        .groupby(\"customer_id\", as_index=False)\n",
    "        .article_id.apply(list)\n",
    "        .rename(columns={\"article_id\": \"prediction\"})[[\"customer_id\", \"prediction\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_predictions(predictions, customers, prediction):\n",
    "    \"\"\"\n",
    "    Add predictions for customers that are not in the predictions dataframe.\n",
    "\n",
    "    @param predictions: the original predictions dataframe\n",
    "    @param customers: a list of customer ids for which the prediction should be added if they are missing\n",
    "    @param prediction: a list of article ids that is to be used as the prediction\n",
    "    \"\"\"\n",
    "    missing_customers = pd.Series(\n",
    "        list(set(customers) - set(predictions.customer_id)),\n",
    "        name=\"customer_id\",\n",
    "    )\n",
    "    missing_predictions = pd.merge(\n",
    "        missing_customers, pd.Series([prediction], name=\"prediction\"), how=\"cross\"\n",
    "    )\n",
    "\n",
    "    return pd.concat((predictions, missing_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(predictions, purchases, k=12):\n",
    "    \"\"\"\n",
    "    Calculates the mean average precision for a set of predictions and purchases.\n",
    "    Each row in the predictions and purchases has a customer_id and a list of purchases or predictions.\n",
    "\n",
    "    @param predictions: a dataframe of predictions\n",
    "    @param purchases: a dataframe of ground truth purchases\n",
    "    \"\"\"\n",
    "\n",
    "    def average_precision(row):\n",
    "        score = 0\n",
    "        num_hits = 0\n",
    "\n",
    "        for i, p in enumerate(row.prediction[:k]):\n",
    "            if p in row.purchases and p not in row.prediction[:i]:\n",
    "                num_hits += 1\n",
    "                score += num_hits / (i + 1)\n",
    "\n",
    "        return score / min(len(row.purchases), k)\n",
    "\n",
    "    result = pd.merge(purchases, predictions, on=\"customer_id\", how=\"inner\")\n",
    "    result[\"average_precision\"] = result.apply(average_precision, axis=1)\n",
    "\n",
    "    return result.average_precision.sum() / len(purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(predictions, sample_submission):\n",
    "    predictions = predictions.set_index(\"customer_id\").prediction.to_dict()\n",
    "    preds = []\n",
    "    result = sample_submission.copy()\n",
    "    for customer_id in customer_hex_id_to_int(result.customer_id):\n",
    "        preds.append(\" \".join(f\"0{x}\" for x in predictions[customer_id]))\n",
    "    result.prediction = preds\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_importance(ranker, features):\n",
    "    for i in ranker.feature_importances_.argsort()[::-1]:\n",
    "        imp = ranker.feature_importances_[i] / ranker.feature_importances_.sum()\n",
    "        print(f\"{features[i]:>30} {imp:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
