{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:27.839690200Z",
     "start_time": "2023-11-18T16:01:27.776245400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os;os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:29.735280400Z",
     "start_time": "2023-11-18T16:01:27.779701200Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:29.735280400Z",
     "start_time": "2023-11-18T16:01:29.731574400Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 20193575\n",
    "SEQUENCE_COLUMN = \"prod_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:29.755887900Z",
     "start_time": "2023-11-18T16:01:29.734280300Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:32.571811400Z",
     "start_time": "2023-11-18T16:01:29.756887600Z"
    }
   },
   "outputs": [],
   "source": [
    "articles = pd.read_parquet('../data/articles.parquet')\n",
    "customers = pd.read_parquet('../data/customers.parquet')\n",
    "transactions = pd.read_parquet('../data/transactions_train.parquet')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.merge(transactions, articles[[\"article_id\", \"prod_name\", \"product_type_name\"]], on=\"article_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:33.865976200Z",
     "start_time": "2023-11-18T16:01:32.572814700Z"
    }
   },
   "outputs": [],
   "source": [
    "article_id_map = {original: (idx + 1) for idx, original in enumerate(articles[\"article_id\"].unique())}\n",
    "inverse_article_id_map = {(idx + 1): original for idx, original in enumerate(articles[\"article_id\"].unique())}\n",
    "articles[\"article_id_mapped\"] = articles[\"article_id\"].map(article_id_map)\n",
    "transactions[\"article_id_mapped\"] = transactions[\"article_id\"].map(article_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:33.894010800Z",
     "start_time": "2023-11-18T16:01:33.866976700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                      105542\n",
       "product_code                     47224\n",
       "prod_name                        45875\n",
       "product_type_no                    132\n",
       "product_type_name                  131\n",
       "product_group_name                  19\n",
       "graphical_appearance_no             30\n",
       "graphical_appearance_name           30\n",
       "colour_group_code                   50\n",
       "colour_group_name                   50\n",
       "perceived_colour_value_id            8\n",
       "perceived_colour_value_name          8\n",
       "perceived_colour_master_id          20\n",
       "perceived_colour_master_name        20\n",
       "department_no                      299\n",
       "department_name                    250\n",
       "index_code                          10\n",
       "index_name                          10\n",
       "index_group_no                       5\n",
       "index_group_name                     5\n",
       "section_no                          57\n",
       "section_name                        56\n",
       "garment_group_no                    21\n",
       "garment_group_name                  21\n",
       "detail_desc                      43405\n",
       "article_id_mapped               105542\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:33.899874300Z",
     "start_time": "2023-11-18T16:01:33.892009400Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMRecommender(nn.Module):\n",
    "    def __init__(self, embedding_dim, input_dim, hidden_dim, n_articles, num_layers=2, bidirectional=True, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_articles = n_articles\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Embedding articles to a lower dimension\n",
    "        self.embedding = nn.Embedding(n_articles, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_dim * num_layers, n_articles)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.n_directions * self.num_layers, x.size(0), self.hidden_dim, requires_grad=True, device=device)\n",
    "        c0 = torch.zeros(self.n_directions * self.num_layers, x.size(0), self.hidden_dim, requires_grad=True, device=device)\n",
    "        # Embed\n",
    "        embedded_sequence = self.embedding(x)\n",
    "        # Forward propagate LSTM\n",
    "        out, (hn, cn) = self.lstm(embedded_sequence, (h0.detach(), c0.detach()))\n",
    "        # Dropout\n",
    "        out = self.dropout(out)\n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "        # out = F.softmax(out, dim=1)\n",
    "        # return torch.max(out, dim=1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:36.406481700Z",
     "start_time": "2023-11-18T16:01:33.898874200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split 80/20 on customer id\n",
    "train_customers, val_customers = train_test_split(transactions.customer_id.unique(), test_size=0.2, random_state=SEED)\n",
    "training_transactions_df = transactions[transactions.customer_id.isin(train_customers)]\n",
    "validation_transactions_df = transactions[transactions.customer_id.isin(val_customers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:36.409939800Z",
     "start_time": "2023-11-18T16:01:36.407480900Z"
    }
   },
   "outputs": [],
   "source": [
    "N_TRAINING_WEEKS = 5\n",
    "MAX_WEEK = 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:36.424677800Z",
     "start_time": "2023-11-18T16:01:36.409939800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_transactions_by_weeks(transactions, column=\"article_id_mapped\"):\n",
    "    _transactions = transactions[[\"customer_id\", column, \"week\"]]\n",
    "    filtered_transactions = _transactions[_transactions.week.between(MAX_WEEK - N_TRAINING_WEEKS, MAX_WEEK - 1)]\n",
    "    filtered_transactions = filtered_transactions.groupby(\"customer_id\")[column].apply(list).reset_index(name=\"history\")\n",
    "    return filtered_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:39.078819600Z",
     "start_time": "2023-11-18T16:01:36.425676900Z"
    }
   },
   "outputs": [],
   "source": [
    "training_transactions = filter_transactions_by_weeks(training_transactions_df, SEQUENCE_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:39.682684300Z",
     "start_time": "2023-11-18T16:01:39.079820900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_transactions = filter_transactions_by_weeks(validation_transactions_df, SEQUENCE_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:40.664591700Z",
     "start_time": "2023-11-18T16:01:39.684684500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.362281e+06\n",
       "mean     2.333463e+01\n",
       "std      3.924225e+01\n",
       "min      1.000000e+00\n",
       "25%      3.000000e+00\n",
       "50%      9.000000e+00\n",
       "75%      2.700000e+01\n",
       "max      1.895000e+03\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.customer_id.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:41.900947600Z",
     "start_time": "2023-11-18T16:01:40.664591700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_transactions_df.customer_id.value_counts().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:42.431461200Z",
     "start_time": "2023-11-18T16:01:41.899540400Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Padding article added to map, actual articles start at 1\n",
    "article_id_map[-1] = 0\n",
    "PADDING_ARTICLE = articles[SEQUENCE_COLUMN].nunique()\n",
    "\n",
    "NUM_ARTICLES_IN_SEQUENCE = 12\n",
    "N_ARTICLES = articles[SEQUENCE_COLUMN].nunique()\n",
    "\n",
    "model = LSTMRecommender(\n",
    "    input_dim=NUM_ARTICLES_IN_SEQUENCE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    # Output dim is only the number of articles while n_articles is for the embedding and has to include the padding\n",
    "    n_articles=N_ARTICLES+1,\n",
    "    bidirectional=False,\n",
    "    num_layers=1,\n",
    "    dropout=0.2\n",
    "    )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:42.442080600Z",
     "start_time": "2023-11-18T16:01:42.432463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    105542.000000\n",
       "mean      13482.907828\n",
       "std       12937.813422\n",
       "min           0.000000\n",
       "25%        2508.000000\n",
       "50%        9172.000000\n",
       "75%       21221.750000\n",
       "max       45874.000000\n",
       "Name: prod_name, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[SEQUENCE_COLUMN].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:42.456433400Z",
     "start_time": "2023-11-18T16:01:42.437978700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45874"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[SEQUENCE_COLUMN].max() - articles[SEQUENCE_COLUMN].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:42.469793800Z",
     "start_time": "2023-11-18T16:01:42.455434Z"
    }
   },
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "   def __init__(self, sequences, targets):\n",
    "       self.sequences = sequences\n",
    "       self.targets = targets\n",
    "\n",
    "   def __len__(self):\n",
    "       return len(self.sequences)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "       return self.sequences[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "def combine_sequences(user_transactions):\n",
    "    combined_sequence_batch = []\n",
    "    combined_target_batch = []\n",
    "    \n",
    "    for idx, (customer, history) in user_transactions.iterrows():\n",
    "        history_batch, target_batch = create_batch(history)\n",
    "        if history_batch is None or target_batch is None:\n",
    "            continue\n",
    "        combined_sequence_batch.extend(history_batch)\n",
    "        combined_target_batch.extend(target_batch)\n",
    "    \n",
    "    sequence_dataset = SequenceDataset(combined_sequence_batch, combined_target_batch)\n",
    "    dataloader = DataLoader(sequence_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def create_batch(history):\n",
    "    # Create batch of sequences\n",
    "    if len(history) <= 1:\n",
    "        return None, None\n",
    "    history_batch = []\n",
    "    target_batch = []\n",
    "    for i in range(1, len(history)):\n",
    "        if i < 12:\n",
    "            # Add padding to the beginning of the sequence\n",
    "            history_batch.append(torch.tensor([PADDING_ARTICLE] * (NUM_ARTICLES_IN_SEQUENCE - i) + history[:i], dtype=torch.int32))\n",
    "        else:\n",
    "            history_batch.append(torch.tensor(history[i-12:i], dtype=torch.int32))\n",
    "        target_batch.append(torch.tensor(history[i], dtype=torch.float32, requires_grad=True))\n",
    "    return history_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:42.485764Z",
     "start_time": "2023-11-18T16:01:42.460853500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116809474287335</td>\n",
       "      <td>[7046, 19554, 2790, 7546, 4954, 20631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200292573348128</td>\n",
       "      <td>[3732]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329094189075899</td>\n",
       "      <td>[4368, 4368]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>690285180337957</td>\n",
       "      <td>[7046, 7046, 7046]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745180086074610</td>\n",
       "      <td>[28106, 18449, 29373, 195, 126, 8959, 9507, 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id                                            history\n",
       "0  116809474287335             [7046, 19554, 2790, 7546, 4954, 20631]\n",
       "1  200292573348128                                             [3732]\n",
       "2  329094189075899                                       [4368, 4368]\n",
       "3  690285180337957                                 [7046, 7046, 7046]\n",
       "4  745180086074610  [28106, 18449, 29373, 195, 126, 8959, 9507, 22..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:42.487763400Z",
     "start_time": "2023-11-18T16:01:42.467793700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_validation():\n",
    "    y_true, y_pred = [], []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dataloader = combine_sequences(validation_transactions)\n",
    "        for sequences, targets in dataloader:\n",
    "            sequence = sequences.to(device)\n",
    "            target = targets.to(device).long()\n",
    "            \n",
    "            # Predict\n",
    "            out = model(sequence)\n",
    "            loss = criterion(out, target)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = torch.argmax(out, dim=1)\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "        \n",
    "    val_loss /= len(dataloader)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    return accuracy, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T15:45:57.864590900Z",
     "start_time": "2023-11-18T15:21:26.725958300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218069\n",
      "Training start: Sat Nov 18 21:33:16 2023\n",
      "+-------+---------------------+-------------------+-------------------------+--------------------+----------------------+------------+\n",
      "| Epoch | Validation Accuracy | Training Accuracy |     Validation Loss     |     Epoch Loss     |     Running Loss     | Epoch Time |\n",
      "+-------+---------------------+-------------------+-------------------------+--------------------+----------------------+------------+\n",
      "| 1     | 1.8206%             | 1.1803%           | 7.8700                  | 8.0609             | 8.0609               | 38.72s     |\n",
      "| 2     | 4.0604%             | 2.8340%           | 7.7144                  | 7.7604             | 15.8213              | 37.58s     |\n",
      "| 3     | 5.8974%             | 5.2185%           | 7.5467                  | 7.5636             | 23.3849              | 37.68s     |\n",
      "| 4     | 7.2531%             | 6.8546%           | 7.4053                  | 7.3781             | 30.7630              | 36.90s     |\n",
      "| 5     | 8.3788%             | 8.1738%           | 7.2940                  | 7.2234             | 37.9863              | 37.77s     |\n",
      "| 6     | 9.3452%             | 9.3191%           | 7.2059                  | 7.0961             | 45.0825              | 38.55s     |\n",
      "| 7     | 10.0940%            | 10.2605%          | 7.1373                  | 6.9894             | 52.0718              | 35.43s     |\n",
      "| 8     | 10.6889%            | 10.9321%          | 7.0778                  | 6.9011             | 58.9729              | 37.55s     |\n",
      "| 9     | 11.1778%            | 11.5037%          | 7.0311                  | 6.8256             | 65.7985              | 36.74s     |\n",
      "| 10    | 11.5542%            | 11.9818%          | 6.9927                  | 6.7596             | 72.5581              | 38.25s     |\n",
      "| 11    | 11.8738%            | 12.3591%          | 6.9610                  | 6.7024             | 79.2604              | 37.88s     |\n",
      "| 12    | 12.1096%            | 12.7108%          | 6.9317                  | 6.6505             | 85.9110              | 37.81s     |\n",
      "| 13    | 12.3112%            | 12.9773%          | 6.9076                  | 6.6046             | 92.5156              | 39.02s     |\n",
      "| 14    | 12.4344%            | 13.2365%          | 6.8896                  | 6.5625             | 99.0781              | 37.63s     |\n",
      "| 15    | 12.6245%            | 13.4320%          | 6.8712                  | 6.5243             | 105.6024             | 38.59s     |\n",
      "| 16    | 12.7266%            | 13.6206%          | 6.8557                  | 6.4892             | 112.0916             | 37.95s     |\n",
      "| 17    | 12.8632%            | 13.7969%          | 6.8435                  | 6.4571             | 118.5487             | 36.51s     |\n",
      "| 18    | 12.9667%            | 13.9272%          | 6.8325                  | 6.4264             | 124.9751             | 36.80s     |\n",
      "| 19    | 13.0923%            | 14.0866%          | 6.8196                  | 6.3984             | 131.3735             | 35.57s     |\n",
      "| 20    | 13.0731%            | 14.2144%          | 6.8138                  | 6.3721             | 137.7455             | 37.03s     |\n",
      "| 21    | 13.1477%            | 14.3077%          | 6.8047                  | 6.3472             | 144.0927             | 37.36s     |\n",
      "| 22    | 13.2256%            | 14.4022%          | 6.7987                  | 6.3238             | 150.4165             | 36.54s     |\n",
      "| 23    | 13.2381%            | 14.5217%          | 6.7928                  | 6.3008             | 156.7173             | 37.26s     |\n",
      "| 24    | 13.3036%            | 14.6122%          | 6.7874                  | 6.2809             | 162.9982             | 35.53s     |\n",
      "| 25    | 13.3681%            | 14.7090%          | 6.7835                  | 6.2599             | 169.2581             | 38.12s     |\n",
      "| 26    | 13.3585%            | 14.7687%          | 6.7805                  | 6.2423             | 175.5004             | 36.68s     |\n",
      "| 27    | 13.4023%            | 14.8554%          | 6.7772                  | 6.2234             | 181.7237             | 35.46s     |\n",
      "| 28    | 13.3560%            | 14.9198%          | 6.7755                  | 6.2065             | 187.9303             | 37.12s     |\n",
      "| 29    | 13.4711%            | 14.9942%          | 6.7713                  | 6.1885             | 194.1188             | 36.31s     |\n",
      "| 30    | 13.4499%            | 15.0520%          | 6.7691                  | 6.1735             | 200.2924             | 36.74s     |\n",
      "| 31    | 13.4205%            | 15.1250%          | 6.7678                  | 6.1581             | 206.4505             | 38.99s     |\n",
      "| 32    | 13.4706%            | 15.1954%          | 6.7690                  | 6.1439             | 212.5944             | 36.67s     |\n",
      "| 33    | 13.4321%            | 15.2435%          | 6.7688                  | 6.1288             | 218.7232             | 35.94s     |\n",
      "| 34    | 13.4263%            | 15.3098%          | 6.7692                  | 6.1137             | 224.8369             | 36.41s     |\n",
      "| 35    | 13.4918%            | 15.3402%          | 6.7665                  | 6.1017             | 230.9386             | 35.55s     |\n",
      "| 36    | 13.4918%            | 15.3854%          | 6.7677                  | 6.0889             | 237.0275             | 36.96s     |\n",
      "| 37    | 13.4114%            | 15.4345%          | 6.7675                  | 6.0763             | 243.1038             | 41.51s     |\n",
      "| 38    | 13.4980%            | 15.4903%          | 6.7676                  | 6.0643             | 249.1681             | 37.13s     |\n",
      "| 39    | 13.5004%            | 15.5363%          | 6.7674                  | 6.0522             | 255.2203             | 37.16s     |\n",
      "| 40    | 13.4648%            | 15.5740%          | 6.7712                  | 6.0407             | 261.2610             | 35.95s     |\n",
      "| 41    | 13.4383%            | 15.6021%          | 6.7698                  | 6.0314             | 267.2924             | 37.14s     |\n",
      "| 42    | 13.4711%            | 15.6534%          | 6.7720                  | 6.0193             | 273.3117             | 36.86s     |\n",
      "| 43    | 13.4768%            | 15.6950%          | 6.7746                  | 6.0090             | 279.3207             | 35.90s     |\n",
      "| 44    | 13.5149%            | 15.7253%          | 6.7743                  | 5.9991             | 285.3198             | 35.19s     |\n",
      "| 45    | 13.4595%            | 15.7668%          | 6.7752                  | 5.9889             | 291.3087             | 35.51s     |\n",
      "| 46    | 13.4018%            | 15.8142%          | 6.7780                  | 5.9792             | 297.2879             | 35.69s     |\n",
      "| 47    | 13.4701%            | 15.8404%          | 6.7772                  | 5.9688             | 303.2567             | 37.04s     |\n",
      "| 48    | 13.3979%            | 15.8626%          | 6.7800                  | 5.9614             | 309.2181             | 35.63s     |\n",
      "| 49    | 13.4513%            | 15.9140%          | 6.7833                  | 5.9525             | 315.1706             | 34.89s     |\n",
      "| 50    | 13.4186%            | 15.9836%          | 6.7870                  | 5.9431             | 321.1137             | 35.95s     |\n",
      "Training time: 1867.65s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "print(len(training_transactions))\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "print(\"Training start:\", time.asctime(time.localtime()))\n",
    "\n",
    "header_printed = False\n",
    "col_widths = []\n",
    "table_seperator = \"\"\n",
    "\n",
    "running_loss = 0.0\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "model.to(device)\n",
    "dataloader = combine_sequences(training_transactions)\n",
    "len(dataloader)\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start_time = time.perf_counter()\n",
    "    \n",
    "    training_accuracy = 0\n",
    "    epoch_loss = 0.0\n",
    "    for idx, (sequence, target) in enumerate(dataloader):\n",
    "        sequence = sequence.to(device)\n",
    "        target = target.to(device).long()\n",
    "        # Predict\n",
    "        out = model(sequence)\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(\n",
    "            # torch.tensor(out, dtype=torch.float32, requires_grad=True), torch.tensor(target[0], dtype=torch.float32, requires_grad=True)\n",
    "            # out.to(torch.float32).clone().detach().requires_grad_(True), target\n",
    "            out, target\n",
    "        )\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        predicted = torch.argmax(out, dim=1)\n",
    "        epoch_loss += loss.item()\n",
    "        training_accuracy += (predicted == target).sum().item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    running_loss += epoch_loss\n",
    "    training_accuracy /= len(dataloader.dataset)\n",
    "    \n",
    "    val_accuracy, val_loss = run_validation()\n",
    "    \n",
    "    train_losses.append(epoch_loss)\n",
    "    val_losses.append(float(val_loss))\n",
    "    \n",
    "    if not header_printed:\n",
    "        header_printed = True\n",
    "        header_text = \"| Epoch | Validation Accuracy | Training Accuracy |     Validation Loss     |     Epoch Loss     |     Running Loss     | Epoch Time |\"\n",
    "        col_widths = [len(s)-2 for s in header_text.split(\"|\")[1:-1]]\n",
    "        table_seperator = f\"+{'+'.join(['-' * (x + 2) for x in col_widths])}+\"\n",
    "        print(table_seperator)\n",
    "        print(header_text)\n",
    "        print(table_seperator)\n",
    "    \n",
    "    print(f\"| {str(epoch + 1):<{col_widths[0]}} | \"\n",
    "              f\"{f'{val_accuracy:.4%}':<{col_widths[1]}} | \"\n",
    "              f\"{f'{training_accuracy:.4%}':<{col_widths[2]}} | \"\n",
    "              f\"{f'{val_loss:.4f}':<{col_widths[3]}} | \"\n",
    "              f\"{f'{epoch_loss:.4f}':<{col_widths[4]}} | \"\n",
    "              f\"{f'{running_loss:.4f}':<{col_widths[5]}} | \"\n",
    "              f\"{f'{time.perf_counter() - epoch_start_time:.2f}s':<{col_widths[6]}} |\")\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"./models/LSTM_Model_Epoch_{epoch + 1}.pt\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Training time: {end_time - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:42.487763400Z",
     "start_time": "2023-11-18T16:01:42.471853Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:01:44.497680500Z",
     "start_time": "2023-11-18T16:01:42.474962Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:02:22.848548400Z",
     "start_time": "2023-11-18T16:02:22.670128800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LSTMRecommender(\n",
    "    input_dim=NUM_ARTICLES_IN_SEQUENCE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    # Output dim is only the number of articles while n_articles is for the embedding and has to include the padding\n",
    "    n_articles=N_ARTICLES+1,\n",
    "    bidirectional=False,\n",
    "    num_layers=1,\n",
    "    dropout=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:02:28.680832900Z",
     "start_time": "2023-11-18T16:02:26.797893300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./models/LSTM_Model_Epoch_25.pt\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:02:30.801553700Z",
     "start_time": "2023-11-18T16:02:30.787153600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:02:32.757889700Z",
     "start_time": "2023-11-18T16:02:32.736819200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HistoryDataset(Dataset):\n",
    "    def __init__(self, history):\n",
    "        self.histories = history\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.histories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        history = self.histories[idx]\n",
    "        if len(history) < 12:\n",
    "            history = [PADDING_ARTICLE] * (NUM_ARTICLES_IN_SEQUENCE - len(history)) + history\n",
    "        return torch.tensor(history[-12:], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:03:00.350668500Z",
     "start_time": "2023-11-18T16:02:35.170346700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe by \"customer_id\" and \"t_dat\" in descending order\n",
    "df = transactions.sort_values(by=['customer_id', 't_dat'], ascending=[True, True])\n",
    "\n",
    "# Group by \"customer_id\" and get the last 12 transactions for each customer\n",
    "df_grouped = df.groupby('customer_id')['article_id_mapped'].apply(list)\n",
    "transactions_filtered = pd.DataFrame({\"customer_id\": df_grouped.index, \"sequence\": df_grouped.apply(lambda x: x[-12:])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:03:00.867631700Z",
     "start_time": "2023-11-18T16:03:00.350668500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert customer ids to integers\n",
    "customer_ids = sub.customer_id.apply(hex_id_to_int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:03:01.305242600Z",
     "start_time": "2023-11-18T16:03:00.867631700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_customer_ids = list(set(customer_ids).difference(set(transactions_filtered.customer_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:03:01.343808Z",
     "start_time": "2023-11-18T16:03:01.305242600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with the missing customer_ids and an empty list as the sequence\n",
    "df_missing = pd.DataFrame({\n",
    "  'customer_id': missing_customer_ids,\n",
    "  'sequence': [[] for _ in range(len(missing_customer_ids))]\n",
    "})\n",
    "\n",
    "# Concatenate df_result and df_missing\n",
    "transactions_filtered = pd.concat([transactions_filtered, df_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:03:01.888163800Z",
     "start_time": "2023-11-18T16:03:01.344807300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sorting based on customer_ids in submission\n",
    "transactions_df = transactions_filtered.copy()\n",
    "transactions_df['customer_id'] = pd.Categorical(transactions_df['customer_id'], categories=customer_ids, ordered=True)\n",
    "transactions_df_sorted = transactions_df.sort_values(\"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:03:43.167978100Z",
     "start_time": "2023-11-18T16:03:43.152727500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "history_dataset = HistoryDataset(transactions_df_sorted.sequence.tolist())\n",
    "history_dataloader = DataLoader(history_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "counter = 0\n",
    "history_batches = []\n",
    "history_batch = []\n",
    "\n",
    "for idx, batch in enumerate(history_dataloader):\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    for i in range(12):\n",
    "        # Pass padded batches to the model\n",
    "        with torch.no_grad():\n",
    "            out = model(batch[:, -12:])\n",
    "            out = torch.argmax(out, dim=1).unsqueeze(1)\n",
    "\n",
    "        # Append model's output to each transaction in the batch\n",
    "        batch = torch.cat((batch, out), dim=1)\n",
    "    for i in range(batch.shape[0]):\n",
    "        preds.append(batch[i, -12:].tolist())\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-08T00:37:22.710732400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"rec_list.bin\", \"wb\") as f:\n",
    "    pickle.dump(preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-08T00:37:22.711733200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"rec_list.bin\", \"rb\") as f:\n",
    "    some_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T00:37:22.726754600Z",
     "start_time": "2023-11-08T00:37:22.712733100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(preds), len(some_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-08T00:37:22.713733700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions[\"article_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T01:32:25.419889300Z",
     "start_time": "2023-11-08T01:32:21.863104600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_preds = [' '.join(['0' + str(inverse_article_id_map.get(p, 706016001)) for p in ps]) for ps in preds]\n",
    "sub.prediction = _preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T01:33:06.418490400Z",
     "start_time": "2023-11-08T01:32:36.509053500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_name = 'lstm_model_submission_e25_fix1'\n",
    "sub.to_csv(f'{sub_name}.csv.gz', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
