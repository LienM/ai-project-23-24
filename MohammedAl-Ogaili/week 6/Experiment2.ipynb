{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd011469-040b-46ae-b0c7-ca57c682a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "\n",
    "# make external scripts auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from experiment_template import *\n",
    "from LSTMRecommender import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ba89dec-cb25-4243-b9d7-a857d770e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../data/'\n",
    "\n",
    "# make sure the same data preprocessing as in the radek notebook have been performed\n",
    "# (see 02 FE/DataProcessingRadek.ipynb)\n",
    "transactions = pd.read_parquet(BASE_PATH + 'transactions_train.parquet')\n",
    "customers = pd.read_parquet(BASE_PATH + 'customers.parquet')\n",
    "articles = pd.read_parquet(BASE_PATH + 'articles.parquet')\n",
    "sample_submission = pd.read_csv(BASE_PATH + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c72811db-7994-4aa4-ac87-e90fa7275b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate generation of Radek notebook\n",
    "def get_data(data, test_week):\n",
    "    ### repurchase\n",
    "    # each week is seen as a basket\n",
    "    # the items bought in one basket, will be example for the next basket\n",
    "    # the items bought in the last basket, will be candidates for the test basket\n",
    "    c2weeks = data.groupby('customer_id')['week'].unique()\n",
    "    c2weeks2shifted_weeks = {}\n",
    "    for c_id, weeks in c2weeks.items():\n",
    "        c2weeks2shifted_weeks[c_id] = {}\n",
    "        for i in range(weeks.shape[0]-1):\n",
    "            c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "        c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week\n",
    "    candidates_last_purchase = data.copy()\n",
    "    weeks = []\n",
    "    for i, (c_id, week) in enumerate(zip(data['customer_id'], data['week'])):\n",
    "        weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "    candidates_last_purchase.week=weeks\n",
    "\n",
    "    ### bestseller\n",
    "    # if a user bought an item in a given week, the 12 most popular items in the previous week are example for that week\n",
    "    # the best selling items in the last week are candidates for all users\n",
    "    mean_price = data \\\n",
    "        .groupby(['week', 'article_id'])['price'].mean()\n",
    "    \n",
    "    sales = data \\\n",
    "        .groupby('week')['article_id'].value_counts() \\\n",
    "        .groupby('week').rank(method='dense', ascending=False) \\\n",
    "        .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "\n",
    "    bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "    bestsellers_previous_week.week += 1\n",
    "    unique_transactions = data \\\n",
    "        .groupby(['week', 'customer_id']) \\\n",
    "        .head(1) \\\n",
    "        .drop(columns=['article_id', 'price']) \\\n",
    "        .copy()\n",
    "    candidates_bestsellers = pd.merge(\n",
    "        unique_transactions,\n",
    "        bestsellers_previous_week,\n",
    "        on='week',\n",
    "    )\n",
    "    test_set_transactions = unique_transactions.drop_duplicates('customer_id').reset_index(drop=True)\n",
    "    test_set_transactions.week = test_week\n",
    "    candidates_bestsellers_test_week = pd.merge(\n",
    "        test_set_transactions,\n",
    "        bestsellers_previous_week,\n",
    "        on='week'\n",
    "    )\n",
    "    candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "    candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)\n",
    "\n",
    "    ### combine\n",
    "    d = data.copy()\n",
    "    d['purchased'] = True\n",
    "    \n",
    "    result = pd.concat([\n",
    "        d, candidates_last_purchase, candidates_bestsellers\n",
    "    ])\n",
    "    result.purchased.fillna(False, inplace=True)\n",
    "    result.drop_duplicates(['customer_id', 'article_id', 'week'], inplace=True)\n",
    "\n",
    "    result = pd.merge(\n",
    "        result,\n",
    "        bestsellers_previous_week[['week', 'article_id', 'bestseller_rank']],\n",
    "        on=['week', 'article_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    result = result[result.week != result.week.min()]\n",
    "    result.bestseller_rank.fillna(999, inplace=True)\n",
    "\n",
    "    result.sort_values(['week', 'customer_id'], inplace=True)\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "    return result\n",
    "\n",
    "def get_examples(data, test_week):\n",
    "    data = get_data(data, test_week)\n",
    "    return data[data.week != test_week]\n",
    "\n",
    "def get_candidates(data, test_week):\n",
    "    data = get_data(data, test_week)\n",
    "    return data[data.week == test_week]\n",
    "\n",
    "def add_features(data):\n",
    "    columns_to_use = [\n",
    "        'article_id', \n",
    "        'prod_name',\n",
    "        'product_type_name',\n",
    "        'product_type_no', \n",
    "        'graphical_appearance_no', \n",
    "        'colour_group_code', \n",
    "        'perceived_colour_value_id',\n",
    "        'perceived_colour_master_id', \n",
    "        'department_no', \n",
    "        'index_code',\n",
    "        'index_group_no', \n",
    "        'section_no', \n",
    "        'garment_group_no', \n",
    "        'FN', \n",
    "        'Active',\n",
    "        'club_member_status', \n",
    "        'fashion_news_frequency', \n",
    "        'age', \n",
    "        'postal_code',\n",
    "        'bestseller_rank',\n",
    "        'discount',\n",
    "        'price',\n",
    "        'price_sensitivity'\n",
    "    ]\n",
    "\n",
    "    result = data\n",
    "    result = pd.merge(result, customers, how='left', on='customer_id')\n",
    "    result = pd.merge(result, articles, how='left', on='article_id')\n",
    "\n",
    "    # features from assignment 2 could go here\n",
    "\n",
    "    # Clipping price\n",
    "    result[\"price\"] = result[\"price\"].clip(0, 0.17)\n",
    "\n",
    "    customer_avg_price = transactions.groupby('customer_id')['price'].mean().to_frame('preferred_price')\n",
    "    result = pd.merge(result, customer_avg_price, how=\"left\", on=\"customer_id\")\n",
    "\n",
    "    # Customer price senstivity\n",
    "    customer_data = result.groupby('customer_id')\n",
    "    price_sensitivity = customer_data['price'].std() / customer_data['price'].mean()\n",
    "    price_sensitivity_df = pd.DataFrame({'customer_id': price_sensitivity.index, 'price_sensitivity': price_sensitivity.values})\n",
    "    result = pd.merge(result, price_sensitivity_df, on='customer_id', how='left')\n",
    "\n",
    "    max_price = result.groupby(\"article_id\")[\"price\"].max().reset_index().rename(columns={\"price\": \"max_price\"})\n",
    "    result[\"discount\"] = 1 - result[\"price\"] / result.merge(max_price, on=\"article_id\", how=\"left\")[\"max_price\"]\n",
    "\n",
    "    \n",
    "    return result[columns_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split into training and testing\n",
    "# one week is used for testing\n",
    "# a number of weeks leading up to the test week are used to train the ranker\n",
    "test_week = 105\n",
    "num_training_weeks = 10\n",
    "testing_weeks = np.arange(test_week-num_training_weeks, test_week)\n",
    "train_data = transactions[transactions.week.isin(testing_weeks)].reset_index(drop=True)\n",
    "\n",
    "### assemble training data (positive + negative examples)\n",
    "# each example has at least a customer_id, article_id and whether it was purchased or not (positive/negative)\n",
    "# add_features extracts and adds features to the examples\n",
    "train_examples = get_examples(train_data, test_week)\n",
    "X_train = add_features(train_examples)\n",
    "Y_train = train_examples['purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.137543\n",
      "[LightGBM] [Info] Total Bins 2182\n",
      "[LightGBM] [Info] Number of data points in the train set: 11381612, number of used features: 23\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "               bestseller_rank 0.96428\n",
      "                      discount 0.02922\n",
      "             price_sensitivity 0.00193\n",
      "               product_type_no 0.00161\n",
      "             product_type_name 0.00134\n",
      "                    section_no 0.00051\n",
      "                         price 0.00047\n",
      "                    article_id 0.00027\n",
      "             colour_group_code 0.00023\n",
      "                           age 0.00011\n",
      "                     prod_name 0.00002\n",
      "                   postal_code 0.00002\n",
      "    perceived_colour_master_id 0.00000\n",
      "       graphical_appearance_no 0.00000\n",
      "     perceived_colour_value_id 0.00000\n",
      "        fashion_news_frequency 0.00000\n",
      "            club_member_status 0.00000\n",
      "                    index_code 0.00000\n",
      "                index_group_no 0.00000\n",
      "              garment_group_no 0.00000\n",
      "                            FN 0.00000\n",
      "                        Active 0.00000\n",
      "                 department_no 0.00000\n"
     ]
    }
   ],
   "source": [
    "### fit ranker\n",
    "# training_groups tells LGBM that each (week, customer_id) combination is a seperate basket\n",
    "# !!! it is important that the training_examples are sorted according to week, customer_id for this to work\n",
    "ranker = LGBMRanker(\n",
    "    force_row_wise=True,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=10\n",
    ")\n",
    "train_groups = train_examples.groupby(['week', 'customer_id'])['article_id'].count().values\n",
    "ranker.fit(X_train, Y_train, group=train_groups)\n",
    "print_importance(ranker, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "# candidates are generated similarly to the examples, only we don't know whether they are purchased\n",
    "# the same features are extracted and added\n",
    "# each candidate is scored by the ranker and predictions are generated using the highest scoring candidates\n",
    "test_candidates = get_candidates(train_data, test_week)\n",
    "X_test = add_features(test_candidates)\n",
    "predictions = get_predictions(test_candidates, X_test, ranker, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMRecommender(\n",
       "  (embedding): Embedding(45876, 64)\n",
       "  (lstm): LSTM(64, 100, batch_first=True)\n",
       "  (fc): Linear(in_features=100, out_features=45876, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEQUENCE_COLUMN = \"prod_name\"\n",
    "# SEQUENCE_COLUMN = \"product_type_name\"\n",
    "N_PREDICTIONS = 6\n",
    "MOST_POPULAR_VALUE = articles[articles[\"article_id\"] == transactions[\"article_id\"] \\\n",
    "                              .value_counts().index[0]][SEQUENCE_COLUMN].item()\n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "PADDING_ARTICLE = articles[SEQUENCE_COLUMN].nunique()\n",
    "\n",
    "NUM_ARTICLES_IN_SEQUENCE = 12\n",
    "N_ARTICLES = articles[SEQUENCE_COLUMN].nunique()\n",
    "\n",
    "model = LSTMRecommender(\n",
    "    input_dim=NUM_ARTICLES_IN_SEQUENCE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    # Output dim is only the number of articles while n_articles is for the embedding and has to include the padding\n",
    "    n_articles=N_ARTICLES+1,\n",
    "    bidirectional=False,\n",
    "    num_layers=1,\n",
    "    dropout=0.2\n",
    "    )\n",
    "\n",
    "model.load_state_dict(torch.load(f\"./models/{SEQUENCE_COLUMN}_model/LSTM_Model_Epoch_19.pt\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get purchases in testing weeks as a list sorted by date\n",
    "# Merge articles into transactions\n",
    "df = pd.merge(transactions, articles, how='left', on='article_id')\n",
    "df = df.sort_values(by=['customer_id', 't_dat'], ascending=[True, True])\n",
    "\n",
    "# Group by \"customer_id\" and get the last 12 transactions for each customer\n",
    "df_grouped = df.groupby('customer_id')[SEQUENCE_COLUMN].apply(list)\n",
    "transactions_filtered = pd.DataFrame({\"customer_id\": df_grouped.index, \"sequence\": df_grouped.apply(lambda x: x[-12:])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataset = TransactionsDataset(transactions_filtered, PADDING_ARTICLE, NUM_ARTICLES_IN_SEQUENCE)\n",
    "history_dataloader = DataLoader(history_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_lstm(logits, temperature=1.0):\n",
    "    scaled = logits / temperature\n",
    "    probabilities = F.softmax(scaled, dim=1)\n",
    "    return torch.multinomial(probabilities, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a952a882a78a431ea51cfbd00674c7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "counter = 0\n",
    "history_batches = []\n",
    "history_batch = []\n",
    "\n",
    "for idx, sequences in enumerate(tqdm(history_dataloader)):\n",
    "    sequences = sequences.to(device)\n",
    "    \n",
    "    for i in range(N_PREDICTIONS):\n",
    "        # Pass padded batches to the model\n",
    "        with torch.no_grad():\n",
    "            out = model(sequences[:, -12:])\n",
    "            out = sample_lstm(out, temperature=0.1)\n",
    "            # out = torch.argmax(out, dim=1).unsqueeze(1)\n",
    "\n",
    "        # Append model's output to each transaction in the batch\n",
    "        sequences = torch.cat((sequences, out), dim=1)\n",
    "    for i in range(sequences.shape[0]):\n",
    "        preds.append(sequences[i, -N_PREDICTIONS:].tolist())\n",
    "transactions_filtered[\"preds\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_last_k(predictions, k):\n",
    "    most_popular_filtered = df.groupby([SEQUENCE_COLUMN, \"article_id\"]).size().reset_index(name=\"count\").sort_values([SEQUENCE_COLUMN, \"count\"], ascending=[True, False])\n",
    "    most_popular_filtered = most_popular_filtered.groupby(SEQUENCE_COLUMN)[\"article_id\"].apply(list).reset_index(name=\"articles\")\n",
    "    popular_articles_dict = dict(zip(most_popular_filtered[SEQUENCE_COLUMN], most_popular_filtered[\"articles\"]))\n",
    "\n",
    "    # lstm preds to dict\n",
    "    lstm_prediction_dict = transactions_filtered.set_index(\"customer_id\")[\"preds\"].to_dict()\n",
    "\n",
    "    for idx, (customer_id, prediction) in tqdm(predictions.iterrows(), total=predictions.shape[0]):\n",
    "        new_preds = prediction[:-k]\n",
    "        lstm_preds = lstm_prediction_dict.get(customer_id, [])\n",
    "\n",
    "        for i in range(k):\n",
    "            cat_value = lstm_preds[i] if i < len(lstm_preds) and lstm_preds[i] != PADDING_ARTICLE else MOST_POPULAR_VALUE\n",
    "            for article in popular_articles_dict.get(cat_value, []):\n",
    "                if article not in new_preds:\n",
    "                    new_preds.append(article)\n",
    "                    break\n",
    "\n",
    "        if len(new_preds) != 12:\n",
    "            new_preds += prediction[-k:]\n",
    "            new_preds = new_preds[:12]\n",
    "        predictions.at[idx, \"prediction\"] = new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28847241659200</td>\n",
       "      <td>[925246001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41318098387474</td>\n",
       "      <td>[868879003, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116809474287335</td>\n",
       "      <td>[906305002, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200292573348128</td>\n",
       "      <td>[903861001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248294615847351</td>\n",
       "      <td>[720504008, 471714002, 878987003, 337991001, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id                                         prediction\n",
       "0   28847241659200  [925246001, 924243001, 924243002, 918522001, 9...\n",
       "1   41318098387474  [868879003, 924243001, 924243002, 918522001, 9...\n",
       "2  116809474287335  [906305002, 924243001, 924243002, 918522001, 9...\n",
       "3  200292573348128  [903861001, 924243001, 924243002, 918522001, 9...\n",
       "4  248294615847351  [720504008, 471714002, 878987003, 337991001, 9..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4909e9b9bdc4043b6d3acc27583b6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/437365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace_most_popular(predictions, 5)\n",
    "replace_last_k(predictions, N_PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28847241659200</td>\n",
       "      <td>[925246001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41318098387474</td>\n",
       "      <td>[868879003, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116809474287335</td>\n",
       "      <td>[906305002, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200292573348128</td>\n",
       "      <td>[903861001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248294615847351</td>\n",
       "      <td>[720504008, 471714002, 878987003, 337991001, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id                                         prediction\n",
       "0   28847241659200  [925246001, 924243001, 924243002, 918522001, 9...\n",
       "1   41318098387474  [868879003, 924243001, 924243002, 918522001, 9...\n",
       "2  116809474287335  [906305002, 924243001, 924243002, 918522001, 9...\n",
       "3  200292573348128  [903861001, 924243001, 924243002, 918522001, 9...\n",
       "4  248294615847351  [720504008, 471714002, 878987003, 337991001, 9..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28847241659200</td>\n",
       "      <td>[925246001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41318098387474</td>\n",
       "      <td>[868879003, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116809474287335</td>\n",
       "      <td>[906305002, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200292573348128</td>\n",
       "      <td>[903861001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248294615847351</td>\n",
       "      <td>[720504008, 471714002, 878987003, 337991001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437360</th>\n",
       "      <td>18446624797007271432</td>\n",
       "      <td>[832482004, 556539027, 805308003, 832482001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437361</th>\n",
       "      <td>18446630855572834764</td>\n",
       "      <td>[568601045, 898713001, 886966002, 924243001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437362</th>\n",
       "      <td>18446662237889060501</td>\n",
       "      <td>[845790006, 915526002, 924243001, 924243002, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437363</th>\n",
       "      <td>18446705133201055310</td>\n",
       "      <td>[875784002, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437364</th>\n",
       "      <td>18446737527580148316</td>\n",
       "      <td>[547780001, 763988001, 763988003, 547780040, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_id  \\\n",
       "0             28847241659200   \n",
       "1             41318098387474   \n",
       "2            116809474287335   \n",
       "3            200292573348128   \n",
       "4            248294615847351   \n",
       "...                      ...   \n",
       "437360  18446624797007271432   \n",
       "437361  18446630855572834764   \n",
       "437362  18446662237889060501   \n",
       "437363  18446705133201055310   \n",
       "437364  18446737527580148316   \n",
       "\n",
       "                                               prediction  \n",
       "0       [925246001, 924243001, 924243002, 918522001, 9...  \n",
       "1       [868879003, 924243001, 924243002, 918522001, 9...  \n",
       "2       [906305002, 924243001, 924243002, 918522001, 9...  \n",
       "3       [903861001, 924243001, 924243002, 918522001, 9...  \n",
       "4       [720504008, 471714002, 878987003, 337991001, 9...  \n",
       "...                                                   ...  \n",
       "437360  [832482004, 556539027, 805308003, 832482001, 9...  \n",
       "437361  [568601045, 898713001, 886966002, 924243001, 9...  \n",
       "437362  [845790006, 915526002, 924243001, 924243002, 9...  \n",
       "437363  [875784002, 924243001, 924243002, 918522001, 9...  \n",
       "437364  [547780001, 763988001, 763988003, 547780040, 9...  \n",
       "\n",
       "[437365 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28847241659200</td>\n",
       "      <td>[925246001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41318098387474</td>\n",
       "      <td>[868879003, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116809474287335</td>\n",
       "      <td>[906305002, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200292573348128</td>\n",
       "      <td>[903861001, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248294615847351</td>\n",
       "      <td>[720504008, 471714002, 878987003, 337991001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437360</th>\n",
       "      <td>18446624797007271432</td>\n",
       "      <td>[832482004, 556539027, 805308003, 832482001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437361</th>\n",
       "      <td>18446630855572834764</td>\n",
       "      <td>[568601045, 898713001, 886966002, 924243001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437362</th>\n",
       "      <td>18446662237889060501</td>\n",
       "      <td>[845790006, 915526002, 924243001, 924243002, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437363</th>\n",
       "      <td>18446705133201055310</td>\n",
       "      <td>[875784002, 924243001, 924243002, 918522001, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437364</th>\n",
       "      <td>18446737527580148316</td>\n",
       "      <td>[547780001, 763988001, 763988003, 547780040, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_id  \\\n",
       "0             28847241659200   \n",
       "1             41318098387474   \n",
       "2            116809474287335   \n",
       "3            200292573348128   \n",
       "4            248294615847351   \n",
       "...                      ...   \n",
       "437360  18446624797007271432   \n",
       "437361  18446630855572834764   \n",
       "437362  18446662237889060501   \n",
       "437363  18446705133201055310   \n",
       "437364  18446737527580148316   \n",
       "\n",
       "                                               prediction  \n",
       "0       [925246001, 924243001, 924243002, 918522001, 9...  \n",
       "1       [868879003, 924243001, 924243002, 918522001, 9...  \n",
       "2       [906305002, 924243001, 924243002, 918522001, 9...  \n",
       "3       [903861001, 924243001, 924243002, 918522001, 9...  \n",
       "4       [720504008, 471714002, 878987003, 337991001, 9...  \n",
       "...                                                   ...  \n",
       "437360  [832482004, 556539027, 805308003, 832482001, 9...  \n",
       "437361  [568601045, 898713001, 886966002, 924243001, 9...  \n",
       "437362  [845790006, 915526002, 924243001, 924243002, 9...  \n",
       "437363  [875784002, 924243001, 924243002, 918522001, 9...  \n",
       "437364  [547780001, 763988001, 763988003, 547780040, 9...  \n",
       "\n",
       "[437365 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(preds, purchases, k=12):\n",
    "    df = pd.merge(preds, purchases, how='left', on='customer_id')\n",
    "    # Recall = TP / (TP + FN) => TP / 12\n",
    "    return df.apply(lambda x: len(set(x[\"prediction\"][:k]).intersection(x[\"purchases\"])) / k, axis=1).mean()\n",
    "\n",
    "def hits(preds, purchases, k=12):\n",
    "    df = pd.merge(preds, purchases, how='left', on='customer_id')\n",
    "    # Hits = TP / (TP + FP) => TP / 12\n",
    "    return df.apply(lambda x: len(set(x[\"prediction\"][:k]).intersection(x[\"purchases\"])), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e22bfaf-d1dd-4ea8-9afc-6f4332be82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate\n",
    "if test_week < transactions.week.max() + 1:\n",
    "    # get ground truth data for test week\n",
    "    purchases = get_purchases(transactions[transactions.week == test_week])\n",
    "    \n",
    "    # fill missing prediction for customers in test set with popular items in last week\n",
    "    # only for customers in test set because only those are evaluated\n",
    "    popular = transactions[transactions.week == test_week-1].article_id.value_counts().head(12).index.values\n",
    "    predictions = fill_missing_predictions(predictions, purchases.customer_id, popular)\n",
    "    \n",
    "    # calculate score\n",
    "    score = mean_average_precision(predictions, purchases, 12)\n",
    "    print(f\"MAP@12: {score:.4f}    Recall@12: {recall(purchases, predictions):.4f}    Hits@12: {hits(purchases, predictions):.4f}\")\n",
    "\n",
    "### submit\n",
    "else:\n",
    "    # fill missing predictions for all customers with popular items in last week\n",
    "    # all customers because we don't know which ones will be evaluated\n",
    "    popular = transactions[transactions.week == test_week-1].article_id.value_counts().head(12).index.values\n",
    "    predictions = fill_missing_predictions(predictions, customers.customer_id, popular)\n",
    "\n",
    "    # write submission\n",
    "    sub = create_submission(predictions, sample_submission)\n",
    "    sub.to_csv(BASE_PATH + 'sub1.csv.gz', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
