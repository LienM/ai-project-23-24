{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for producing Kaggle submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook is just used for producing Kaggle predictions - not many comments because explanations are in other notebooks with the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PrepareData import prepare_data\n",
    "from lightgbm.sklearn import LGBMRanker\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from rankers.Stacker import Stacker\n",
    "from rankers.Ranker import Ranker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 weeks in total for training, validation is done on last 5 weeks\n",
    "#this is due to memory contstraints. Ideally, nr_validation_weeks would equal nr_training_weeks so validation scores represent abilities of ranker when trained.\n",
    "nr_training_weeks = 10\n",
    "nr_validation_weeks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/PrepareData.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transactions['purchased'] = 1                                   #this cell produces a warning, but can be ignored as we use \"transactions\" slice to produce the returned dataframe\n"
     ]
    }
   ],
   "source": [
    "train, test, train_baskets, bestsellers_previous_week = prepare_data(kaggle_submission=True, nr_training_weeks=nr_training_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id',\n",
    "'perceived_colour_master_id', 'department_no', 'index_code',\n",
    "'index_group_no', 'section_no', 'garment_group_no', 'FN', 'Active',\n",
    "'club_member_status', 'fashion_news_frequency', 'age', 'postal_code', 'bestseller_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test#[columns_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    boosting_type=\"dart\",\n",
    "    n_estimators=1,\n",
    "    importance_type='gain',\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_ranker = Ranker(AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_ranker = Ranker(GaussianNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metamodel (using AdaBoost ranker as metamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker = Stacker([lgbm_ranker, gnb_ranker, adaboost_ranker], Ranker(AdaBoostClassifier()), use_groups=[True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing validation predictions for each of the base rankers...\n",
      "training metamodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n",
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n",
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metamodel training shape: (5049557, 3)\n",
      "Computing scores on validatation...\n",
      "retraining base rankers on full training set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rankers.Stacker.Stacker at 0x7fc0b07bfbb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker.fit(train, columns_to_use, nr_validation_weeks=nr_validation_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with metamodel\n",
      "Prediction matrix shape: (6610150, 3)\n",
      "prediction matrix:\n",
      "[[ 1.   6.   1. ]\n",
      " [ 3.5  9.   2. ]\n",
      " [ 3.5  8.   4. ]\n",
      " ...\n",
      " [12.5  1.  15. ]\n",
      " [12.5  8.  13. ]\n",
      " [12.5  4.  16. ]]\n"
     ]
    }
   ],
   "source": [
    "test['ranker_meta_model'] = stacker.predict(test_X, columns_to_use, weighting=\"metamodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metamodel using AdaBoost Regressor as metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker = Stacker([lgbm_ranker, gnb_ranker, adaboost_ranker], AdaBoostRegressor(), use_groups=[True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing validation predictions for each of the base rankers...\n",
      "training metamodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n",
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n",
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metamodel training shape: (5049557, 3)\n",
      "Computing scores on validatation...\n",
      "retraining base rankers on full training set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rankers.Stacker.Stacker at 0x7fbf5f26b5b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker.fit(train, columns_to_use, nr_validation_weeks=nr_validation_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with metamodel\n",
      "Prediction matrix shape: (6610150, 3)\n",
      "prediction matrix:\n",
      "[[ 1.   6.   1. ]\n",
      " [ 3.5  9.   2. ]\n",
      " [ 3.5  8.   4. ]\n",
      " ...\n",
      " [12.5  1.  15. ]\n",
      " [12.5  8.  13. ]\n",
      " [12.5  4.  16. ]]\n"
     ]
    }
   ],
   "source": [
    "test['regressor_meta_model'] = stacker.predict(test_X, columns_to_use, weighting=\"metamodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted rank aggregation (no metamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with None weighting\n"
     ]
    }
   ],
   "source": [
    "#predicting with rankers, unweighted (all rankers considered equally)\n",
    "test['unweighted'] = stacker.predict(test_X, columns_to_use, weighting=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with MRR weighting\n"
     ]
    }
   ],
   "source": [
    "test['MRR_weighted'] = stacker.predict(test_X, columns_to_use, weighting=\"MRR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with MAPk weighting\n"
     ]
    }
   ],
   "source": [
    "test['MAPk_weighted'] = stacker.predict(test_X, columns_to_use, weighting=\"MAPk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['naive_bayes'] = gnb_ranker.predict(test_X[columns_to_use])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without GNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metamodel (using AdaBoost ranker as metamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker = Stacker([lgbm_ranker, adaboost_ranker], Ranker(AdaBoostClassifier()), use_groups=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing validation predictions for each of the base rankers...\n",
      "training metamodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n",
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metamodel training shape: (5049557, 2)\n",
      "Computing scores on validatation...\n",
      "retraining base rankers on full training set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rankers.Stacker.Stacker at 0x7fbf90d007f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker.fit(train, columns_to_use, nr_validation_weeks=nr_validation_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with metamodel\n",
      "Prediction matrix shape: (6610150, 2)\n",
      "prediction matrix:\n",
      "[[ 1.   1. ]\n",
      " [ 3.5  2. ]\n",
      " [ 3.5  4. ]\n",
      " ...\n",
      " [12.5 15. ]\n",
      " [12.5 13. ]\n",
      " [12.5 16. ]]\n"
     ]
    }
   ],
   "source": [
    "test['no_GNB_ranker_meta_model'] = stacker.predict(test_X, columns_to_use, weighting=\"metamodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metamodel (using AdaBoost ranker as metamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker = Stacker([lgbm_ranker, adaboost_ranker], AdaBoostRegressor(), use_groups=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing validation predictions for each of the base rankers...\n",
      "training metamodel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n",
      "/home/peter/data_science/Year2/AI Project/Project/ai-project-23-24/PeterKirby/rankers/Stacker.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_no_val[f\"train{i}\"] = train.groupby(['week', 'customer_id'])[f\"ranker{i}\"].rank(ascending=False)              #ascending so \"best rank\" is always the same number (1) - same done when predicting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metamodel training shape: (5049557, 2)\n",
      "Computing scores on validatation...\n",
      "retraining base rankers on full training set...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rankers.Stacker.Stacker at 0x7fbf7420d840>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker.fit(train, columns_to_use, nr_validation_weeks=nr_validation_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with None weighting\n"
     ]
    }
   ],
   "source": [
    "test['no_GNB_unweighted'] = stacker.predict(test_X, columns_to_use, weighting=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with metamodel\n",
      "Prediction matrix shape: (6610150, 2)\n",
      "prediction matrix:\n",
      "[[ 1.   1. ]\n",
      " [ 3.5  2. ]\n",
      " [ 3.5  4. ]\n",
      " ...\n",
      " [12.5 15. ]\n",
      " [12.5 13. ]\n",
      " [12.5 16. ]]\n"
     ]
    }
   ],
   "source": [
    "test['no_GNB_regressor_meta_model'] = stacker.predict(test_X, columns_to_use, weighting=\"metamodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with MRR weighting\n"
     ]
    }
   ],
   "source": [
    "test['no_GNB_MRR_weighted'] = stacker.predict(test_X, columns_to_use, weighting=\"MRR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with MAPk weighting\n"
     ]
    }
   ],
   "source": [
    "test['no_GNB_MAPk_weighted'] = stacker.predict(test_X, columns_to_use, weighting=\"MAPk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['unweighted', 'MRR_weighted', 'MAPk_weighted', 'ranker_meta_model', 'regressor_meta_model']\n",
    "pred_cols = pred_cols + [f'no_GNB_{i}' for i in pred_cols] + ['naive_bayes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week.week == bestsellers_previous_week.week.max()]['article_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_hex_id_to_int(series):\n",
    "    return series.str[-16:].apply(hex_id_to_int)\n",
    "\n",
    "def hex_id_to_int(str):\n",
    "    return int(str[-16:], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for preds_name in pred_cols:\n",
    "    sub = pd.read_csv('../../../Data/sample_submission.csv')\n",
    "\n",
    "    c_id2predicted_article_ids = test \\\n",
    "        .sort_values(['customer_id', preds_name], ascending=False) \\\n",
    "        .groupby('customer_id')['article_id'].apply(list).to_dict()\n",
    "\n",
    "    preds = []\n",
    "    for c_id in customer_hex_id_to_int(sub.customer_id):\n",
    "        pred = c_id2predicted_article_ids.get(c_id, [])\n",
    "        pred = pred + bestsellers_last_week\n",
    "        preds.append(pred[:12])\n",
    "\n",
    "    preds = [' '.join(['0' + str(p) for p in ps]) for ps in preds]\n",
    "    sub.prediction = preds\n",
    "\n",
    "    sub_name = f'../../Submissions_EnsembleOfEnsembles/stacker/{preds_name}'\n",
    "    sub.to_csv(f'{sub_name}.csv.gz', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 59.0M/59.0M [02:19<00:00, 443kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 58.6M/58.6M [02:22<00:00, 431kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 58.4M/58.4M [02:17<00:00, 445kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 58.4M/58.4M [02:17<00:00, 444kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 57.9M/57.9M [02:17<00:00, 441kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 57.8M/57.8M [02:17<00:00, 439kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 57.8M/57.8M [02:21<00:00, 428kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 57.8M/57.8M [02:22<00:00, 426kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 57.8M/57.8M [02:16<00:00, 443kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 57.9M/57.9M [02:16<00:00, 445kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion RecommendationsWarning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/peter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 58.3M/58.3M [02:15<00:00, 451kB/s]\n",
      "Successfully submitted to H&M Personalized Fashion Recommendations"
     ]
    }
   ],
   "source": [
    "for preds_name in pred_cols:\n",
    "    !kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f '../../Submissions_EnsembleOfEnsembles/stacker/{preds_name}.csv.gz' -m {preds_name}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
