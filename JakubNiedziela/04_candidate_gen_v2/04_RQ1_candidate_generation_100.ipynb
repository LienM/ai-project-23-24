{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "os.chdir('../../../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook I want to generate 100 candidates for each of strategies, to then calculate recall@100 to evaluate them. This is mostly a tweak from candidate generation notebook in lecture_3 folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_cols = [\n",
    "    'article_id', \n",
    "    'product_code',\n",
    "    'product_type_no', \n",
    "    'graphical_appearance_no', \n",
    "    'colour_group_code', \n",
    "    'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id', \n",
    "    'department_no', \n",
    "    'index_code',\n",
    "    'index_group_no', \n",
    "    'section_no', \n",
    "    'garment_group_no'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First week num:  0 \n",
      "Last week num:  104 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read compressed data\n",
    "transactions = pd.read_pickle('../data/compressed_data/transactions_train.pkl')\n",
    "customers = pd.read_pickle('../data/compressed_data/customers.pkl')\n",
    "articles = pd.read_pickle('../data/compressed_data/articles.pkl')[articles_cols]\n",
    "\n",
    "# Calculate week, where 0 is first week of data and 104 is last week of data\n",
    "transactions['week'] = 104 - (transactions.t_dat.max() - transactions.t_dat).dt.days // 7\n",
    "\n",
    "print('First week num: ', transactions.week.min(), '\\nLast week num: ', transactions.week.max(), '\\n')\n",
    "\n",
    "avg_age = np.mean(customers['age'].astype('float32'))\n",
    "customers['age'].fillna(avg_age.astype(np.float16), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week = transactions.week.max()\n",
    "\n",
    "train_weeks = range(test_week - 10, test_week)\n",
    "\n",
    "transactions_train = transactions[transactions.week.isin(train_weeks)]\n",
    "transaction_test = transactions[transactions.week == test_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radek's candidates\n",
    "\n",
    "Only bestsellers as it might be impossible to get 100 candidates in last purchase, as we are looking at weeks for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestseller\n",
    "mean_price = transactions_train.groupby(['week', 'article_id'])['price'].mean()\n",
    "sales = transactions_train \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(100).rename('bestseller_rank').astype('int8')\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1\n",
    "\n",
    "unique_transactions = transactions_train \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()\n",
    "\n",
    "candidates_bestsellers = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")\n",
    "\n",
    "test_set_transactions = unique_transactions\\\n",
    "    .drop_duplicates('customer_id')\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "test_set_transactions.week = test_week\n",
    "\n",
    "candidates_bestsellers_test_week = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bestsellers_test_week.to_csv('../data/candidates_100/radek_bestsellers.csv', index=False)\n",
    "bestsellers_previous_week.to_csv('../data/candidates_100/radek_bestsellers_previous_week.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal candidates -- items bought in previous years during similar period to test week (mid september)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/9gp9vcnj7tb2g040j_v9z31r0000gn/T/ipykernel_34033/553317469.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seasonal_trans['year'] = transactions['t_dat'].dt.year\n"
     ]
    }
   ],
   "source": [
    "seasonal_trans = transactions[(transactions.t_dat.dt.month == 9) & (transactions.t_dat.dt.year.isin([2019, 2018]))]\n",
    "seasonal_trans['year'] = transactions['t_dat'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>year</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672597</th>\n",
       "      <td>573628</td>\n",
       "      <td>2018</td>\n",
       "      <td>391772001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801072</th>\n",
       "      <td>683469</td>\n",
       "      <td>2018</td>\n",
       "      <td>634013022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177798</th>\n",
       "      <td>1006441</td>\n",
       "      <td>2019</td>\n",
       "      <td>772773002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562941</th>\n",
       "      <td>480060</td>\n",
       "      <td>2019</td>\n",
       "      <td>803315001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524164</th>\n",
       "      <td>446950</td>\n",
       "      <td>2018</td>\n",
       "      <td>372860001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_id  year  article_id\n",
       "672597        573628  2018   391772001\n",
       "801072        683469  2018   634013022\n",
       "1177798      1006441  2019   772773002\n",
       "562941        480060  2019   803315001\n",
       "524164        446950  2018   372860001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonal_candidates = seasonal_trans.groupby(['customer_id', 'year'])['article_id'].value_counts()\\\n",
    "    .groupby(['customer_id', 'year']).rank(method='dense', ascending=False) \\\n",
    "    .groupby(['customer_id', 'year']).head(100)\\\n",
    "    .reset_index()\\\n",
    "    .drop(columns=['count'])\n",
    "\n",
    "seasonal_candidates.to_csv('../data/candidates_100/baskets_seasonal.csv')\n",
    "\n",
    "seasonal_candidates.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>article_id</th>\n",
       "      <th>seasonal_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>539723005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687004</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2019</td>\n",
       "      <td>677930023</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2019</td>\n",
       "      <td>563519008</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2019</td>\n",
       "      <td>803757001</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2019</td>\n",
       "      <td>715624011</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2019</td>\n",
       "      <td>794575001</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  article_id  seasonal_rank\n",
       "0    2018   539723005              1\n",
       "1    2018   685687003              2\n",
       "2    2018   685687002              3\n",
       "3    2018   685687004              4\n",
       "4    2018   685687001              5\n",
       "..    ...         ...            ...\n",
       "195  2019   677930023             93\n",
       "196  2019   563519008             94\n",
       "197  2019   803757001             95\n",
       "198  2019   715624011             96\n",
       "199  2019   794575001             97\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_seasonal_items = seasonal_trans.groupby(['year'])['article_id'].value_counts()\\\n",
    "    .groupby('year').rank(method='dense', ascending=False)\\\n",
    "    .groupby('year').head(100).rename('seasonal_rank').astype('int8')\\\n",
    "    .reset_index()\n",
    "\n",
    "best_seasonal_items.to_csv('../data/candidates_100/best_seasonal.csv')\n",
    "\n",
    "best_seasonal_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity based -- select items from categories user has not interacted with\n",
    "\n",
    "Merely a function to create candidates, for later use in evaluation notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to create candidates based on the most popular items in the given category\n",
    "def not_interacted_with_candidates(t, a, articles_col, k=2):\n",
    "\n",
    "    # Get unique values of given category\n",
    "    group_unique_values = a[articles_col].unique()\n",
    "    group_df = pd.merge(t, a[['article_id', articles_col]])\n",
    "\n",
    "    # Get k most popular articles in given category\n",
    "    popular_by_group = group_df.groupby(articles_col)['article_id'].value_counts()\\\n",
    "        .groupby(articles_col).head(k).reset_index()\n",
    "    popular_by_group = popular_by_group[['article_id', articles_col]]\n",
    "\n",
    "    # Not interacted category for each customer\n",
    "    not_interacted_with = group_df.groupby('customer_id')[articles_col].unique()\\\n",
    "        .apply(lambda x: np.setdiff1d(group_unique_values, x))\\\n",
    "        .explode().reset_index()\n",
    "    \n",
    "    # Join to create recommendation based on lack of interaction\n",
    "    candidates = pd.merge(not_interacted_with, popular_by_group, on=articles_col)\n",
    "\n",
    "    return candidates[['customer_id', 'article_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_interacted_with_candidates_v2(t, a, articles_col, k=10):\n",
    "    \n",
    "    # Get unique values of given category\n",
    "    group_unique_values = a[articles_col].unique()\n",
    "    group_df = pd.merge(t, a[['article_id', articles_col]])\n",
    "\n",
    "    # Not interacted category for each customer\n",
    "    not_interacted_with = group_df\\\n",
    "        .groupby('customer_id')[articles_col]\\\n",
    "        .apply(lambda x: np.array(list(set(x))))\\\n",
    "        .apply(lambda x: np.setdiff1d(group_unique_values, x))\n",
    "    \n",
    "    # Get k most popular articles in given category\n",
    "    items_popularity = group_df\\\n",
    "        .groupby(articles_col)['article_id']\\\n",
    "        .value_counts()\\\n",
    "        .groupby(articles_col)\\\n",
    "        .head(k)\\\n",
    "        .reset_index()\n",
    "\n",
    "    # Rank items by popularity (number of purchases)\n",
    "    items_popularity['not_interacted_rank'] = items_popularity['count']\\\n",
    "        .rank(method='dense', ascending=False)\\\n",
    "        .astype('int16')\n",
    "    \n",
    "    items_popularity = items_popularity\\\n",
    "        .filter(items=['article_id', articles_col, 'not_interacted_rank'])\\\n",
    "        .sort_values(by=['not_interacted_rank'])\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    # For each customer get k most popular articles in categories that customer did not interact with\n",
    "    for cid in tqdm(not_interacted_with.index.values):\n",
    "        groups = not_interacted_with.loc[cid]\n",
    "\n",
    "        cid_candidates = items_popularity\\\n",
    "            [items_popularity[articles_col].isin(groups)]\\\n",
    "            .head(k)\\\n",
    "            .drop(columns=[articles_col])\n",
    "        \n",
    "        cid_candidates['customer_id'] = cid\n",
    "\n",
    "        candidates.append(cid_candidates)\n",
    "\n",
    "    return pd.concat(candidates)[['customer_id', 'article_id', 'not_interacted_rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item similarities\n",
    " \n",
    "Run this only once, because it takes a long time to calculate similarity loop as there is a lot of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for cosine similarities\n",
    "df = articles.set_index('article_id')\n",
    "df = df.drop(columns=['index_code'])\n",
    "df = (df - df.mean()) / df.std()\n",
    "\n",
    "# Calculate cosine similarities only for articles that are in transactions_train, to reduce the size of the matrix\n",
    "articles_ids = transactions_train.article_id.unique() \n",
    "df = df[df.index.isin(articles_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38540it [03:08, 204.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# # For each item, get top 100 most similar items\n",
    "X = df.to_numpy()\n",
    "articles_arr = df.index.values\n",
    "sims = {}\n",
    "for i, row in tqdm(zip(articles_arr, X)):\n",
    "    top_n_sim = cosine_similarity(row.reshape(1, -1), X).argsort()[:, -102:-1]\n",
    "    article_ids = articles_arr[top_n_sim].reshape(-1)\n",
    "    sims[i] = article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This needed to be dony only once, so I commented it out after running, not to overwrite saved data \n",
    "# sims = {int(i):[int(x) for x in v] for i,v in sims.items()}\n",
    "# with open('../data/item_similarities_100.json', 'w') as f:\n",
    "#     json.dump(sims, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/item_similarities_100.json', 'r') as f:\n",
    "    sims = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items similar to purchased but not actually purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchased_by_user = transactions_train.groupby('customer_id')['article_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "439368it [00:35, 12485.72it/s]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for cid, bought in tqdm(purchased_by_user.items()):\n",
    "    similar_to_bought = []\n",
    "    for bought_item in bought:\n",
    "        similar_to_bought += sims[bought_item]\n",
    "    sim_not_bought = [i for i in similar_to_bought if i not in bought][:100]\n",
    "    result.append(sim_not_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>sim_not_bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>629381012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>568456018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>495884013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>584298026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>557908018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>665477011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>628813001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>620573006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>658298002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>658030009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43936800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer_id sim_not_bought\n",
       "0                 0      629381012\n",
       "0                 0      568456018\n",
       "0                 0      495884013\n",
       "0                 0      584298026\n",
       "0                 0      557908018\n",
       "...             ...            ...\n",
       "439367      1371977      665477011\n",
       "439367      1371977      628813001\n",
       "439367      1371977      620573006\n",
       "439367      1371977      658298002\n",
       "439367      1371977      658030009\n",
       "\n",
       "[43936800 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_not_bought = pd.DataFrame({\n",
    "    'customer_id':purchased_by_user.index.values,\n",
    "    'sim_not_bought':result\n",
    "}).explode('sim_not_bought')\n",
    "sim_not_bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_not_bought.to_csv('../data/candidates_100/similar_not_bought.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
