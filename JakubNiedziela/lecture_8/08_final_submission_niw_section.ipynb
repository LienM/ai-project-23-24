{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "os.chdir('../')\n",
    "from model import *\n",
    "os.chdir('../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First week num:  0 \n",
      "Last week num:  104 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions = pd.read_pickle('../data/compressed_data/transactions_train.pkl')\n",
    "customers = pd.read_pickle('../data/compressed_data/customers.pkl')\n",
    "articles = pd.read_pickle('../data/compressed_data/articles.pkl')\n",
    "\n",
    "transactions['week'] = 104 - (transactions.t_dat.max() - transactions.t_dat).dt.days // 7\n",
    "\n",
    "print('First week num: ', transactions.week.min(), '\\nLast week num: ', transactions.week.max(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test week is week after last week in train data\n",
    "test_week = transactions.week.max() + 1\n",
    "\n",
    "# Filter transactions to last 10 weeks (most recent data)\n",
    "transactions = transactions[transactions.week > transactions.week.max() - 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id',\n",
       "       'week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load radek's candidates\n",
    "candidates_last_purchase = pd.read_csv('candidates/radek_last_purchase.csv')\n",
    "candidates_bestsellers = pd.read_csv('candidates/radek_bestsellers.csv')\n",
    "bestsellers_previous_week = pd.read_csv('candidates/radek_bestsellers_previous_week.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load my candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load my candidates\n",
    "candidates_niw_loaded = pd.read_csv('candidates_200_ranks/niw_candidates_section_name.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Loop -- check best k for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = [\n",
    "    'article_id', \n",
    "    'product_type_no', \n",
    "    'graphical_appearance_no', \n",
    "    'colour_group_code', \n",
    "    'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id', \n",
    "    'department_no', \n",
    "    'index_code',\n",
    "    'index_group_no', \n",
    "    'section_no', \n",
    "    'garment_group_no', \n",
    "    'FN', \n",
    "    'Active',\n",
    "    'club_member_status', \n",
    "    'fashion_news_frequency', \n",
    "    'age', \n",
    "    'postal_code', \n",
    "    'bestseller_rank',\n",
    "    'not_interacted_weekly_rank'\n",
    "]\n",
    "\n",
    "model_params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'boosting_type': 'dart',\n",
    "    'n_estimators': 1,\n",
    "    'importance_type': 'gain'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  20\n",
      "Percentage of real transactions:  0.07133558463571564\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.551514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1136\n",
      "[LightGBM] [Info] Number of data points in the train set: 25049081, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.7737461027124181\n",
      "index_code 0.10011008184810608\n",
      "section_no 0.0410900291955935\n",
      "not_interacted_weekly_rank 0.03132290179463009\n",
      "department_no 0.0236466871853341\n",
      "garment_group_no 0.01416555140250633\n",
      "article_id 0.0069660100041246\n",
      "colour_group_code 0.004031911630184649\n",
      "perceived_colour_value_id 0.002042528216514337\n",
      "product_type_no 0.001973662714289394\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58.1M/58.1M [00:26<00:00, 2.26MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  30\n",
      "Percentage of real transactions:  0.05794373586438516\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.668405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1133\n",
      "[LightGBM] [Info] Number of data points in the train set: 31746801, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.7631142918704261\n",
      "index_code 0.10218001794564067\n",
      "not_interacted_weekly_rank 0.0520242998617583\n",
      "section_no 0.04225860935804258\n",
      "garment_group_no 0.013901337951552042\n",
      "department_no 0.010008765537056468\n",
      "article_id 0.009598280410928991\n",
      "perceived_colour_master_id 0.004503394848790901\n",
      "product_type_no 0.0014927286901852339\n",
      "colour_group_code 0.0009182735256186657\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58.0M/58.0M [00:27<00:00, 2.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  40\n",
      "Percentage of real transactions:  0.04867600705824384\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.061042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1121\n",
      "[LightGBM] [Info] Number of data points in the train set: 38462608, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.7441741108831169\n",
      "index_code 0.1089384458629217\n",
      "not_interacted_weekly_rank 0.05967289084974744\n",
      "section_no 0.04747837237303363\n",
      "article_id 0.01024505552961392\n",
      "garment_group_no 0.010080585441331507\n",
      "department_no 0.009346844030581716\n",
      "product_type_no 0.003544275224060407\n",
      "perceived_colour_master_id 0.002370333654259739\n",
      "index_group_no 0.0016973671061467287\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.9M/57.9M [00:27<00:00, 2.23MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  50\n",
      "Percentage of real transactions:  0.04208851514514964\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.635913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1124\n",
      "[LightGBM] [Info] Number of data points in the train set: 45175053, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.7290233177014933\n",
      "not_interacted_weekly_rank 0.13234882822262992\n",
      "index_code 0.05256493280134237\n",
      "section_no 0.035103517242760285\n",
      "department_no 0.018650902124775704\n",
      "article_id 0.012026716373167119\n",
      "garment_group_no 0.011121480288921811\n",
      "product_type_no 0.003984748129507246\n",
      "graphical_appearance_no 0.0028861674724106386\n",
      "perceived_colour_master_id 0.0022893896429916185\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58.1M/58.1M [00:32<00:00, 1.89MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  60\n",
      "Percentage of real transactions:  0.036901200840682075\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.653170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1131\n",
      "[LightGBM] [Info] Number of data points in the train set: 52021359, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.7063856448955516\n",
      "not_interacted_weekly_rank 0.1418470329033318\n",
      "index_code 0.06146962850997953\n",
      "section_no 0.03270279132163902\n",
      "department_no 0.02283910944078543\n",
      "garment_group_no 0.013975371477742837\n",
      "article_id 0.011224853782810821\n",
      "graphical_appearance_no 0.007307680981799356\n",
      "colour_group_code 0.0022478866863596386\n",
      "fashion_news_frequency 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58.0M/58.0M [00:27<00:00, 2.23MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  70\n",
      "Percentage of real transactions:  0.03287844992089311\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.945964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 58814404, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.7068315322229878\n",
      "not_interacted_weekly_rank 0.14290502164551508\n",
      "index_code 0.061719850384069345\n",
      "section_no 0.035816436664660244\n",
      "department_no 0.022851900062292638\n",
      "garment_group_no 0.020318629176727897\n",
      "article_id 0.004675587495941168\n",
      "perceived_colour_value_id 0.002467753877420801\n",
      "graphical_appearance_no 0.0024132884703850577\n",
      "fashion_news_frequency 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:33<00:00, 1.83MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  80\n",
      "Percentage of real transactions:  0.02965845423569696\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.005641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1117\n",
      "[LightGBM] [Info] Number of data points in the train set: 65602476, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6960688354038678\n",
      "not_interacted_weekly_rank 0.14686997326170687\n",
      "index_code 0.0570879065508245\n",
      "section_no 0.04042620115154184\n",
      "department_no 0.027997860758439214\n",
      "garment_group_no 0.02413873893694923\n",
      "article_id 0.005843228480598045\n",
      "product_type_no 0.0015672554560724886\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:27<00:00, 2.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  90\n",
      "Percentage of real transactions:  0.026983899332463278\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.908901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 72453751, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.681395857605419\n",
      "not_interacted_weekly_rank 0.1400822923820002\n",
      "index_code 0.07169316988996768\n",
      "section_no 0.04626176127391261\n",
      "department_no 0.02518940514475606\n",
      "garment_group_no 0.025057751336459128\n",
      "article_id 0.0066859391192173835\n",
      "product_type_no 0.0036338232482679648\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.7M/57.7M [00:27<00:00, 2.23MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  100\n",
      "Percentage of real transactions:  0.024752579487796054\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.941169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1115\n",
      "[LightGBM] [Info] Number of data points in the train set: 79301894, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6690266724025672\n",
      "index_code 0.1480603701590057\n",
      "not_interacted_weekly_rank 0.08799666164115308\n",
      "section_no 0.041961746560001775\n",
      "garment_group_no 0.02906708401035407\n",
      "department_no 0.018419647616624773\n",
      "product_type_no 0.0028268909052204215\n",
      "article_id 0.0026409267050730334\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:26<00:00, 2.28MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  110\n",
      "Percentage of real transactions:  0.02286115180244589\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.179127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 86154564, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6561668459802396\n",
      "index_code 0.15970775672418205\n",
      "not_interacted_weekly_rank 0.08763218141422109\n",
      "section_no 0.040811648220416614\n",
      "garment_group_no 0.03218917755693602\n",
      "department_no 0.017457955419681905\n",
      "product_type_no 0.003239547653903609\n",
      "article_id 0.0027948870304191605\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:26<00:00, 2.25MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  120\n",
      "Percentage of real transactions:  0.021242070539289316\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.258707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 92986307, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6495543416367907\n",
      "index_code 0.1703300580547263\n",
      "not_interacted_weekly_rank 0.08618881564297017\n",
      "section_no 0.041470106231559535\n",
      "garment_group_no 0.028092569906480142\n",
      "department_no 0.013948099670323639\n",
      "article_id 0.00544819910454082\n",
      "product_type_no 0.0029325272170532416\n",
      "graphical_appearance_no 0.0020352825355554405\n",
      "fashion_news_frequency 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:27<00:00, 2.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  130\n",
      "Percentage of real transactions:  0.019835914529306244\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.382003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1115\n",
      "[LightGBM] [Info] Number of data points in the train set: 99825848, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6450931587564114\n",
      "index_code 0.17262737512110624\n",
      "not_interacted_weekly_rank 0.08647339050510638\n",
      "section_no 0.04437729970353204\n",
      "garment_group_no 0.025266780264812137\n",
      "department_no 0.013378383373097595\n",
      "article_id 0.00512679644559151\n",
      "product_type_no 0.004440689662384067\n",
      "graphical_appearance_no 0.0021018944299833592\n",
      "colour_group_code 0.0011142317379752807\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:27<00:00, 2.23MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  140\n",
      "Percentage of real transactions:  0.01860517924829067\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.301949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1122\n",
      "[LightGBM] [Info] Number of data points in the train set: 106659778, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6388041326534306\n",
      "index_code 0.17172708909765705\n",
      "not_interacted_weekly_rank 0.08602921883047568\n",
      "section_no 0.047316551904939816\n",
      "garment_group_no 0.032909981506981364\n",
      "department_no 0.018206604425211017\n",
      "article_id 0.0034358905077950834\n",
      "product_type_no 0.001570531073509354\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:28<00:00, 2.10MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  150\n",
      "Percentage of real transactions:  0.017517771793850893\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.499625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1124\n",
      "[LightGBM] [Info] Number of data points in the train set: 113506492, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6344860085533296\n",
      "index_code 0.16510128854503475\n",
      "not_interacted_weekly_rank 0.08691494337777479\n",
      "section_no 0.050787906340017695\n",
      "garment_group_no 0.037629882239579165\n",
      "department_no 0.016389400272081654\n",
      "article_id 0.0058641624762724226\n",
      "product_type_no 0.0018282998894219213\n",
      "perceived_colour_value_id 0.0009981083064879975\n",
      "fashion_news_frequency 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:27<00:00, 2.22MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  160\n",
      "Percentage of real transactions:  0.01655250040786595\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.549824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1128\n",
      "[LightGBM] [Info] Number of data points in the train set: 120358757, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6313450818304165\n",
      "index_code 0.15999577232606146\n",
      "not_interacted_weekly_rank 0.08542398767608418\n",
      "section_no 0.05427031430558597\n",
      "garment_group_no 0.043399907099750376\n",
      "department_no 0.01666849029947991\n",
      "article_id 0.005498939824692964\n",
      "product_type_no 0.0023001894720807623\n",
      "perceived_colour_value_id 0.0010973171658478832\n",
      "fashion_news_frequency 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:27<00:00, 2.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  170\n",
      "Percentage of real transactions:  0.015684186513823768\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.633464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1131\n",
      "[LightGBM] [Info] Number of data points in the train set: 127216808, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6261724014874006\n",
      "index_code 0.16462435135321504\n",
      "not_interacted_weekly_rank 0.08002379773681328\n",
      "section_no 0.06175506357305541\n",
      "garment_group_no 0.042631488675281916\n",
      "department_no 0.015921807438534476\n",
      "article_id 0.004257563162183203\n",
      "product_type_no 0.0034542847303541146\n",
      "perceived_colour_value_id 0.001159241843162003\n",
      "fashion_news_frequency 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:26<00:00, 2.26MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  180\n",
      "Percentage of real transactions:  0.014903051542621358\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.897618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1129\n",
      "[LightGBM] [Info] Number of data points in the train set: 134067880, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6205840889580685\n",
      "index_code 0.16933775990644007\n",
      "not_interacted_weekly_rank 0.07828266216418757\n",
      "section_no 0.0654272819813149\n",
      "garment_group_no 0.04499756986829082\n",
      "department_no 0.014895351048406811\n",
      "article_id 0.004323362781206925\n",
      "product_type_no 0.00215192329208437\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:27<00:00, 2.22MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  190\n",
      "Percentage of real transactions:  0.014194768617083485\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.748705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1131\n",
      "[LightGBM] [Info] Number of data points in the train set: 140934526, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6172941368558952\n",
      "index_code 0.17625329797651354\n",
      "not_interacted_weekly_rank 0.07738263564327567\n",
      "section_no 0.05932731469149443\n",
      "garment_group_no 0.042545388143398685\n",
      "department_no 0.020307688140165654\n",
      "article_id 0.003913248330308298\n",
      "product_type_no 0.002976290218948518\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:29<00:00, 2.08MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n",
      "k =  200\n",
      "Percentage of real transactions:  0.013550908453973344\n",
      "Mergining features...\n",
      "Done.\n",
      "Sorting data...\n",
      "Done.\n",
      "Preparing for training...\n",
      "Done.\n",
      "Training model...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.693680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1136\n",
      "[LightGBM] [Info] Number of data points in the train set: 147799230, number of used features: 19\n",
      "Feature importance:\n",
      "bestseller_rank 0.6128826762680097\n",
      "index_code 0.18347574470605216\n",
      "not_interacted_weekly_rank 0.07498537955485089\n",
      "section_no 0.05947789450547934\n",
      "garment_group_no 0.04249278331822098\n",
      "department_no 0.021439950378755856\n",
      "product_type_no 0.0028751209111924267\n",
      "article_id 0.0023704503574386616\n",
      "fashion_news_frequency 0.0\n",
      "club_member_status 0.0\n",
      "Starting submission process...\n",
      "Calculating predictions...\n",
      "Done.\n",
      "Creating submission...\n",
      "Done.\n",
      "Saving submission...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57.8M/57.8M [00:27<00:00, 2.23MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to H&M Personalized Fashion RecommendationsSubmission saved and submitted to Kaggle.\n"
     ]
    }
   ],
   "source": [
    "# Get bestsellers from previous week\n",
    "bestsellers_last_week = \\\n",
    "    bestsellers_previous_week[bestsellers_previous_week['week'] == bestsellers_previous_week['week'].max()]['article_id'].tolist()\n",
    "\n",
    "niw_ranks = candidates_niw_loaded[['week', 'article_id', 'not_interacted_weekly_rank']].drop_duplicates()\n",
    "\n",
    "for k in range(20, 201, 10):\n",
    "    print('k = ', k)\n",
    "\n",
    "    # Get top k similar not bought articles for each customer\n",
    "    candidates_niw = candidates_niw_loaded.groupby(['week', 'customer_id']).head(k)\\\n",
    "        .drop(columns=['strategy', 'not_interacted_weekly_rank'])\n",
    "\n",
    "    candidates_niw['week'] = candidates_niw['week'] + 1\n",
    "\n",
    "    candidates_niw['t_dat'] = '2020-07-15'\n",
    "    candidates_niw['price'] = 0\n",
    "    candidates_niw['sales_channel_id'] = 2\n",
    "\n",
    "    # Prepare data for model\n",
    "    train_X, train_y, test_X, test, train_baskets = prepare_data(\n",
    "        transactions,\n",
    "        bestsellers_previous_week,\n",
    "        candidates=[candidates_last_purchase, candidates_bestsellers, candidates_niw], \n",
    "        features=[customers, articles, niw_ranks], \n",
    "        cols_to_use=columns_to_use\n",
    "        )\n",
    "    \n",
    "    del candidates_niw\n",
    "    gc.collect()\n",
    "    \n",
    "    # Train model\n",
    "    ranker = train_model(\n",
    "        train_X, \n",
    "        train_y, \n",
    "        train_baskets, \n",
    "        model_params, \n",
    "        columns_to_use, \n",
    "        show_importance=10\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Make submission\n",
    "    make_submission(customers, test, test_X, ranker, bestsellers_last_week, f'submission_niw_section_name_{k}')\n",
    "\n",
    "    del train_X, train_y, test_X, test, train_baskets, ranker\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName                                 date                 description                       status    publicScore  privateScore  \n",
      "---------------------------------------  -------------------  --------------------------------  --------  -----------  ------------  \n",
      "submission_niw_section_name_200.csv.gz   2023-12-15 00:39:35  submission_niw_section_name_200   complete  0.01349      0.01333       \n",
      "submission_niw_section_name_190.csv.gz   2023-12-15 00:27:56  submission_niw_section_name_190   complete  0.01348      0.01333       \n",
      "submission_niw_section_name_180.csv.gz   2023-12-15 00:16:49  submission_niw_section_name_180   complete  0.01109      0.01124       \n",
      "submission_niw_section_name_170.csv.gz   2023-12-15 00:06:04  submission_niw_section_name_170   complete  0.01112      0.01127       \n",
      "submission_niw_section_name_160.csv.gz   2023-12-14 23:56:06  submission_niw_section_name_160   complete  0.01351      0.01334       \n",
      "submission_niw_section_name_150.csv.gz   2023-12-14 23:46:22  submission_niw_section_name_150   complete  0.01351      0.01334       \n",
      "submission_niw_section_name_140.csv.gz   2023-12-14 23:37:08  submission_niw_section_name_140   complete  0.01351      0.01334       \n",
      "submission_niw_section_name_130.csv.gz   2023-12-14 23:28:12  submission_niw_section_name_130   complete  0.01345      0.0133        \n",
      "submission_niw_section_name_120.csv.gz   2023-12-14 23:19:56  submission_niw_section_name_120   complete  0.01346      0.0133        \n",
      "submission_niw_section_name_110.csv.gz   2023-12-14 23:12:23  submission_niw_section_name_110   complete  0.01358      0.01344       \n",
      "submission_niw_section_name_100.csv.gz   2023-12-14 23:06:24  submission_niw_section_name_100   complete  0.01217      0.01215       \n",
      "submission_niw_section_name_90.csv.gz    2023-12-14 23:02:23  submission_niw_section_name_90    complete  0.01605      0.01574       \n",
      "submission_niw_section_name_80.csv.gz    2023-12-14 22:58:50  submission_niw_section_name_80    complete  0.01359      0.0134        \n",
      "submission_niw_section_name_70.csv.gz    2023-12-14 22:55:40  submission_niw_section_name_70    complete  0.01349      0.0133        \n",
      "submission_niw_section_name_60.csv.gz    2023-12-14 22:52:38  submission_niw_section_name_60    complete  0.01487      0.01475       \n",
      "submission_niw_section_name_50.csv.gz    2023-12-14 22:49:57  submission_niw_section_name_50    complete  0.01198      0.01226       \n",
      "submission_niw_section_name_40.csv.gz    2023-12-14 22:47:18  submission_niw_section_name_40    complete  0.01916      0.01874       \n",
      "submission_niw_section_name_30.csv.gz    2023-12-14 22:45:08  submission_niw_section_name_30    complete  0.01201      0.01202       \n",
      "submission_niw_section_name_20.csv.gz    2023-12-14 22:43:02  submission_niw_section_name_20    complete  0.01231      0.01243       \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c h-and-m-personalized-fashion-recommendations | head -n 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
