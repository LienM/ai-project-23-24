{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.chdir('../../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_cols = [\n",
    "    'article_id', \n",
    "    'product_code',\n",
    "    'product_type_no', \n",
    "    'graphical_appearance_no', \n",
    "    'colour_group_code', \n",
    "    'perceived_colour_value_id',\n",
    "    'perceived_colour_master_id', \n",
    "    'department_no', \n",
    "    'index_code',\n",
    "    'index_group_no', \n",
    "    'section_no', \n",
    "    'garment_group_no'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First week num:  0 \n",
      "Last week num:  104 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read compressed data\n",
    "transactions = pd.read_pickle('compressed_data/transactions_train.pkl')\n",
    "customers = pd.read_pickle('compressed_data/customers.pkl')\n",
    "articles = pd.read_pickle('compressed_data/articles.pkl')[articles_cols]\n",
    "\n",
    "# Calculate week, where 0 is first week of data and 104 is last week of data\n",
    "transactions['week'] = 104 - (transactions.t_dat.max() - transactions.t_dat).dt.days // 7\n",
    "\n",
    "print('First week num: ', transactions.week.min(), '\\nLast week num: ', transactions.week.max(), '\\n')\n",
    "\n",
    "avg_age = np.mean(customers['age'].astype('float32'))\n",
    "customers['age'].fillna(avg_age.astype(np.float16), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_week = transactions.week.max() + 1\n",
    "\n",
    "train_weeks = range(test_week - 10, test_week)\n",
    "\n",
    "transactions_train = transactions[transactions.week.isin(train_weeks)]\n",
    "transaction_test = transactions[transactions.week == test_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radek's candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "radek_transactions = transactions[transactions.week > transactions.week.max() - 10]\n",
    "\n",
    "c2weeks = radek_transactions.groupby('customer_id')['week'].unique()\n",
    "\n",
    "c2weeks2shifted_weeks = {}\n",
    "\n",
    "for c_id, weeks in c2weeks.items():\n",
    "    c2weeks2shifted_weeks[c_id] = {}\n",
    "    for i in range(weeks.shape[0]-1):\n",
    "        c2weeks2shifted_weeks[c_id][weeks[i]] = weeks[i+1]\n",
    "    c2weeks2shifted_weeks[c_id][weeks[-1]] = test_week\n",
    "\n",
    "candidates_last_purchase = radek_transactions.copy()\n",
    "\n",
    "weeks = []\n",
    "for i, (c_id, week) in enumerate(zip(radek_transactions['customer_id'], radek_transactions['week'])):\n",
    "    weeks.append(c2weeks2shifted_weeks[c_id][week])\n",
    "    \n",
    "candidates_last_purchase.week=weeks\n",
    "\n",
    "# bestseller\n",
    "mean_price = radek_transactions.groupby(['week', 'article_id'])['price'].mean()\n",
    "sales = radek_transactions \\\n",
    "    .groupby('week')['article_id'].value_counts() \\\n",
    "    .groupby('week').rank(method='dense', ascending=False) \\\n",
    "    .groupby('week').head(12).rename('bestseller_rank').astype('int8')\n",
    "bestsellers_previous_week = pd.merge(sales, mean_price, on=['week', 'article_id']).reset_index()\n",
    "bestsellers_previous_week.week += 1\n",
    "\n",
    "unique_transactions = radek_transactions \\\n",
    "    .groupby(['week', 'customer_id']) \\\n",
    "    .head(1) \\\n",
    "    .drop(columns=['article_id', 'price']) \\\n",
    "    .copy()\n",
    "\n",
    "candidates_bestsellers = pd.merge(\n",
    "    unique_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week',\n",
    ")\n",
    "\n",
    "test_set_transactions = unique_transactions\\\n",
    "    .drop_duplicates('customer_id')\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "test_set_transactions.week = test_week\n",
    "\n",
    "candidates_bestsellers_test_week = pd.merge(\n",
    "    test_set_transactions,\n",
    "    bestsellers_previous_week,\n",
    "    on='week'\n",
    ")\n",
    "\n",
    "# Concatenate data with test data\n",
    "candidates_bestsellers = pd.concat([candidates_bestsellers, candidates_bestsellers_test_week])\n",
    "candidates_bestsellers.drop(columns='bestseller_rank', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_bestsellers.to_csv('candidates/radek_bestsellers.csv', index=False)\n",
    "bestsellers_previous_week.to_csv('candidates/radek_bestsellers_previous_week.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_last_purchase.to_csv('candidates/radek_last_purchase.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal candidates -- items bought in previous years during similar period to test week (mid september)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/9gp9vcnj7tb2g040j_v9z31r0000gn/T/ipykernel_8568/553317469.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seasonal_trans['year'] = transactions['t_dat'].dt.year\n"
     ]
    }
   ],
   "source": [
    "seasonal_trans = transactions[(transactions.t_dat.dt.month == 9) & (transactions.t_dat.dt.year.isin([2019, 2018]))]\n",
    "seasonal_trans['year'] = transactions['t_dat'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>year</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>966940</th>\n",
       "      <td>882764</td>\n",
       "      <td>2019</td>\n",
       "      <td>782451007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627637</th>\n",
       "      <td>573121</td>\n",
       "      <td>2018</td>\n",
       "      <td>597763001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696181</th>\n",
       "      <td>636208</td>\n",
       "      <td>2019</td>\n",
       "      <td>532578028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478954</th>\n",
       "      <td>436933</td>\n",
       "      <td>2019</td>\n",
       "      <td>806617001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299094</th>\n",
       "      <td>1187924</td>\n",
       "      <td>2019</td>\n",
       "      <td>728162002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer_id  year  article_id\n",
       "966940        882764  2019   782451007\n",
       "627637        573121  2018   597763001\n",
       "696181        636208  2019   532578028\n",
       "478954        436933  2019   806617001\n",
       "1299094      1187924  2019   728162002"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonal_candidates = seasonal_trans.groupby(['customer_id', 'year'])['article_id'].value_counts()\\\n",
    "    .groupby(['customer_id', 'year']).rank(method='dense', ascending=False) \\\n",
    "    .groupby(['customer_id', 'year']).head(12)\\\n",
    "    .reset_index()\\\n",
    "    .drop(columns=['count'])\n",
    "\n",
    "seasonal_candidates.to_csv('candidates/baskets_seasonal.csv')\n",
    "\n",
    "seasonal_candidates.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>article_id</th>\n",
       "      <th>seasonal_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>539723005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687004</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>685687001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>399223001</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>573716012</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>692454002</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>562245001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>610776002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>591334003</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>683662005</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019</td>\n",
       "      <td>706016001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>772902001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019</td>\n",
       "      <td>706016002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019</td>\n",
       "      <td>673677002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>752814004</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019</td>\n",
       "      <td>673677010</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>743630007</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>751471018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019</td>\n",
       "      <td>714790003</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019</td>\n",
       "      <td>562245046</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019</td>\n",
       "      <td>574109011</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019</td>\n",
       "      <td>796210008</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  article_id  seasonal_rank\n",
       "0   2018   539723005              1\n",
       "1   2018   685687003              2\n",
       "2   2018   685687002              3\n",
       "3   2018   685687004              4\n",
       "4   2018   685687001              5\n",
       "5   2018   399223001              6\n",
       "6   2018   573716012              7\n",
       "7   2018   692454002              8\n",
       "8   2018   562245001              9\n",
       "9   2018   610776002             10\n",
       "10  2018   591334003             11\n",
       "11  2018   683662005             12\n",
       "12  2019   706016001              1\n",
       "13  2019   772902001              2\n",
       "14  2019   706016002              3\n",
       "15  2019   673677002              4\n",
       "16  2019   752814004              5\n",
       "17  2019   673677010              6\n",
       "18  2019   743630007              7\n",
       "19  2019   751471018              8\n",
       "20  2019   714790003              9\n",
       "21  2019   562245046             10\n",
       "22  2019   574109011             11\n",
       "23  2019   796210008             12"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_seasonal_items = seasonal_trans.groupby(['year'])['article_id'].value_counts()\\\n",
    "    .groupby('year').rank(method='dense', ascending=False)\\\n",
    "    .groupby('year').head(12).rename('seasonal_rank').astype('int8')\\\n",
    "    .reset_index()\n",
    "\n",
    "best_seasonal_items.to_csv('candidates/best_seasonal.csv')\n",
    "\n",
    "best_seasonal_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity based -- select items from categories user has not interacted with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to create candidates based on the most popular items in the given category\n",
    "def not_interacted_with_candidates(t, a, articles_col, k=2):\n",
    "\n",
    "    # Get unique values of given category\n",
    "    group_unique_values = a[articles_col].unique()\n",
    "    group_df = pd.merge(t, a[['article_id', articles_col]])\n",
    "\n",
    "    # Get k most popular articles in given category\n",
    "    popular_by_group = group_df.groupby(articles_col)['article_id'].value_counts()\\\n",
    "        .groupby(articles_col).head(k).reset_index()\n",
    "    popular_by_group = popular_by_group[['article_id', articles_col]]\n",
    "\n",
    "    # Not interacted category for each customer\n",
    "    not_interacted_with = group_df.groupby('customer_id')[articles_col].unique()\\\n",
    "        .apply(lambda x: np.setdiff1d(group_unique_values, x))\\\n",
    "        .explode().reset_index()\n",
    "    \n",
    "    # Join to create recommendation based on lack of interaction\n",
    "    candidates = pd.merge(not_interacted_with, popular_by_group, on=articles_col)\n",
    "\n",
    "    return candidates[['customer_id', 'article_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item similarities\n",
    " \n",
    "Run this only once, because it takes a long time to calculate similarity loop as there is a lot of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for cosine similarities\n",
    "df = articles.set_index('article_id')\n",
    "df = df.drop(columns=['index_code'])\n",
    "df = (df - df.mean()) / df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105542it [32:09, 54.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# # # For each item, get top 5 most similar items\n",
    "# # # Only 5, because full matrix was too much data for kernel to handle\n",
    "# X = df.to_numpy()\n",
    "# articles_arr = df.index.values\n",
    "# sims = {}\n",
    "# for i, row in tqdm(zip(articles_arr, X)):\n",
    "#     top_n_sim = cosine_similarity(row.reshape(1, -1), X).argsort()[:, -6:-1]\n",
    "#     article_ids = articles_arr[top_n_sim].reshape(-1)\n",
    "#     sims[i] = article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sims = {int(i):[int(x) for x in v] for i,v in sims.items()}\n",
    "# with open('../../../data/item_similarities.json', 'w') as f:\n",
    "#     json.dump(sims, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('item_similarities.json', 'r') as f:\n",
    "    sims = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items similar to purchased but not actually purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchased_by_user = transactions_train.groupby('customer_id')['article_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "439368it [00:03, 124024.79it/s]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for cid, bought in tqdm(purchased_by_user.items()):\n",
    "    similar_to_bought = []\n",
    "    for bought_item in bought:\n",
    "        similar_to_bought += sims[str(bought_item)]\n",
    "    sim_not_bought = [i for i in similar_to_bought if i not in bought][:10]\n",
    "    result.append(sim_not_bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>sim_not_bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>568808003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>560183001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>578487015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>565668003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>565788005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>851108003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>834021003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>824764009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>824764007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439367</th>\n",
       "      <td>1371977</td>\n",
       "      <td>845031001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4042017 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        customer_id sim_not_bought\n",
       "0                 0      568808003\n",
       "0                 0      560183001\n",
       "0                 0      578487015\n",
       "0                 0      565668003\n",
       "0                 0      565788005\n",
       "...             ...            ...\n",
       "439367      1371977      851108003\n",
       "439367      1371977      834021003\n",
       "439367      1371977      824764009\n",
       "439367      1371977      824764007\n",
       "439367      1371977      845031001\n",
       "\n",
       "[4042017 rows x 2 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_not_bought = pd.DataFrame({\n",
    "    'customer_id':purchased_by_user.index.values,\n",
    "    'sim_not_bought':result\n",
    "}).explode('sim_not_bought')\n",
    "sim_not_bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_not_bought.to_csv('candidates/similar_not_bought.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User based collaborative filtering\n",
    "Did not work due to the size of data -- tried many combinations but all of them were crashing as it was too much to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_articles = transactions_train.article_id.value_counts().reset_index()\n",
    "# agg_articles_top = agg_articles[agg_articles['count']>=2000]\n",
    "# agg_articles_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions_train_top = transactions_train[transactions_train.article_id.isin(agg_articles_top.article_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = transactions_train_top\\\n",
    "#     .groupby(['customer_id', 'article_id']).agg(num_purchased=('article_id', 'count'))\\\n",
    "#     .reset_index()\\\n",
    "#     .pivot_table(index='customer_id', columns='article_id', values='num_purchased')\\\n",
    "#     .fillna(0)\n",
    "# matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator\n",
    "\n",
    "# def similar_users(user_id, matrix, k=10):\n",
    "#     # create a df of just the current user\n",
    "#     user = matrix[matrix.index == user_id]\n",
    "    \n",
    "#     # and a df of all other users\n",
    "#     other_users = matrix[matrix.index != user_id]\n",
    "    \n",
    "#     # calc cosine similarity between user and each other user\n",
    "#     similarities = cosine_similarity(user,other_users)[0].tolist()\n",
    "    \n",
    "#     # create list of indices of these users\n",
    "#     indices = other_users.index.tolist()\n",
    "    \n",
    "#     # create key/values pairs of user index and their similarity\n",
    "#     index_similarity = dict(zip(indices, similarities))\n",
    "    \n",
    "#     # sort by similarity\n",
    "#     index_similarity_sorted = sorted(index_similarity.items(), key=operator.itemgetter(1))\n",
    "#     index_similarity_sorted.reverse()\n",
    "    \n",
    "#     # grab k users off the top\n",
    "#     top_users_similarities = index_similarity_sorted[:k]\n",
    "#     users = [u[0] for u in top_users_similarities]\n",
    "    \n",
    "#     return users\n",
    "\n",
    "# def recommend_item(user_index, similar_user_indices, matrix, items=5):\n",
    "    \n",
    "#     # load vectors for similar users\n",
    "#     similar_users = matrix[matrix.index.isin(similar_user_indices)]\n",
    "#     # calc avg ratings across the 3 similar users\n",
    "#     similar_users = similar_users.sum(axis=0)\n",
    "#     # convert to dataframe so its easy to sort and filter\n",
    "#     similar_users_df = pd.DataFrame(similar_users, columns=['mean'])\n",
    "    \n",
    "    \n",
    "#     # load vector for the current user\n",
    "#     user_df = matrix[matrix.index == user_index]\n",
    "#     # transpose it so its easier to filter\n",
    "#     user_df_transposed = user_df.transpose()\n",
    "#     # rename the column as 'rating'\n",
    "#     user_df_transposed.columns = ['rating']\n",
    "#     # remove any rows without a 0 value. item not watched yet\n",
    "#     user_df_transposed = user_df_transposed[user_df_transposed['rating']==0]\n",
    "#     # generate a list of items the user has not seen\n",
    "#     items_unseen = user_df_transposed.index.tolist()\n",
    "    \n",
    "#     # filter avg ratings of similar users for only item the current user has not seen\n",
    "#     similar_users_df_filtered = similar_users_df[similar_users_df.index.isin(items_unseen)]\n",
    "#     # order the dataframe\n",
    "#     similar_users_df_ordered = similar_users_df_filtered.sort_values(by=['mean'], ascending=False)\n",
    "#     # grab the top n item   \n",
    "#     top_n_item = similar_users_df_ordered.head(items)\n",
    "#     top_n_item_indices = top_n_item.index.tolist()\n",
    "#     # lookup these item in the other dataframe to find names\n",
    "#     item_information = articles[articles['article_id'].isin(top_n_item_indices)]\n",
    "    \n",
    "#     return top_n_item_indices #items\n",
    "    \n",
    "# user_candidates = {}\n",
    "# for user in tqdm(transactions_train_top.customer_id.unique()):\n",
    "#     user_candidates[user] = recommend_item(4, similar_users(4, matrix), matrix, items=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_candidates = {int(k):v for k, v in user_candidates.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../../../data/candidates/user_based_cf_candidates_v1.json', 'w') as f:\n",
    "#     json.dump(user_candidates, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPRO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
