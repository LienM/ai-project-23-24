{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Read input files","metadata":{}},{"cell_type":"code","source":"%%time\nimport pandas as pd\n\npad = \"/kaggle/input/makeparquet\"\ntransactions = pd.read_parquet(pad+'/transactions_train.parquet')\ncustomers = pd.read_parquet(pad+'/customers.parquet')\narticles = pd.read_parquet(pad+'/articles.parquet')","metadata":{"execution":{"iopub.status.busy":"2023-11-06T23:15:56.405154Z","iopub.execute_input":"2023-11-06T23:15:56.405603Z","iopub.status.idle":"2023-11-06T23:16:02.175233Z","shell.execute_reply.started":"2023-11-06T23:15:56.405566Z","shell.execute_reply":"2023-11-06T23:16:02.172920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Merge the transactions and articles dataframes on 'article_id'\nmerged_df = transactions.merge(articles[['article_id', 'product_code']], on='article_id', how='inner')\n\n# Step 2: Group by 'customer_id' and 'product_code', and count unique articles\ncustomer_product_counts = merged_df.groupby(['customer_id', 'product_code'])['article_id'].nunique().reset_index()\n\n# Step 3: Filter customers who bought multiple articles with the same product code\ncustomers_with_multiple_purchases = customer_product_counts[customer_product_counts['article_id'] > 1]\n\n# Display the result\nprint(customers_with_multiple_purchases)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T23:16:02.177270Z","iopub.execute_input":"2023-11-06T23:16:02.177699Z","iopub.status.idle":"2023-11-06T23:16:47.150356Z","shell.execute_reply.started":"2023-11-06T23:16:02.177663Z","shell.execute_reply":"2023-11-06T23:16:47.147212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Merge the transactions and articles dataframes on 'article_id'\nmerged_df2 = transactions.merge(articles[['article_id', 'product_code']], on='article_id', how='inner')\n\n# Step 2: Group by 'customer_id', 'product_code', and aggregate lists of article_ids and dates\ngrouped = merged_df2.groupby(['customer_id', 'product_code']).agg({\n    'article_id': list,\n    't_dat': list\n}).reset_index()\n\n# Display the result\nprint(grouped)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-06T23:16:47.152669Z","iopub.execute_input":"2023-11-06T23:16:47.154680Z","iopub.status.idle":"2023-11-06T23:44:52.096028Z","shell.execute_reply.started":"2023-11-06T23:16:47.154626Z","shell.execute_reply":"2023-11-06T23:44:52.095014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter the grouped dataset to include only entries with at least 2 articles\nfiltered_grouped = grouped[grouped['article_id'].apply(len) >= 2]\n\n# Display the filtered result\nprint(filtered_grouped)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T23:53:19.442404Z","iopub.execute_input":"2023-11-06T23:53:19.442771Z","iopub.status.idle":"2023-11-06T23:53:24.649369Z","shell.execute_reply.started":"2023-11-06T23:53:19.442739Z","shell.execute_reply":"2023-11-06T23:53:24.648043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(grouped))\nprint(len(filtered_grouped))","metadata":{"execution":{"iopub.status.busy":"2023-11-06T23:54:58.063252Z","iopub.execute_input":"2023-11-06T23:54:58.063633Z","iopub.status.idle":"2023-11-06T23:54:58.068653Z","shell.execute_reply.started":"2023-11-06T23:54:58.063604Z","shell.execute_reply":"2023-11-06T23:54:58.067204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to check if there are at least two different dates in the list\ndef has_at_least_two_different_dates(date_list):\n    unique_dates = set(date_list)\n    return len(unique_dates) >= 2\n\n# Filter the dataset to include only entries with at least two different dates\nfiltered_grouped_with_diff_dates = filtered_grouped[filtered_grouped['t_dat'].apply(has_at_least_two_different_dates)]\n\n# Display the result\nprint(filtered_grouped_with_diff_dates)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T00:24:09.925812Z","iopub.execute_input":"2023-11-07T00:24:09.926149Z","iopub.status.idle":"2023-11-07T00:24:15.404442Z","shell.execute_reply.started":"2023-11-07T00:24:09.926123Z","shell.execute_reply":"2023-11-07T00:24:15.403158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"All used combinations of customer_id and product_code:\")\nprint(len(grouped))\nprint(\"Filtered at least 2 different article_ids in these combinations: \")\nprint(len(filtered_grouped))\nprint(\"Filtered 2 different article_ids in at least 2 different dates: \")\nprint(len(filtered_grouped_with_diff_dates))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T00:24:46.532770Z","iopub.execute_input":"2023-11-07T00:24:46.533104Z","iopub.status.idle":"2023-11-07T00:24:46.537586Z","shell.execute_reply.started":"2023-11-07T00:24:46.533075Z","shell.execute_reply":"2023-11-07T00:24:46.536898Z"},"trusted":true},"execution_count":null,"outputs":[]}]}